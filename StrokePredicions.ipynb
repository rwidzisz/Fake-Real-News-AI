{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as ms\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\rafal\\\\OneDrive\\\\Pulpit\\\\PSI\\\\TheStrokes.csv\")\n",
    "df.describe()\n",
    "df = df.fillna(df.mean())\n",
    "df=df.rename(columns={\"stroke\":\"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56669</td>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53882</td>\n",
       "      <td>Male</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>70.09</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10434</td>\n",
       "      <td>Female</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>94.39</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27419</td>\n",
       "      <td>Female</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>76.15</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60491</td>\n",
       "      <td>Female</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>58.57</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "5  56669    Male  81.0             0              0          Yes   \n",
       "6  53882    Male  74.0             1              1          Yes   \n",
       "7  10434  Female  69.0             0              0           No   \n",
       "8  27419  Female  59.0             0              0          Yes   \n",
       "9  60491  Female  78.0             0              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level        bmi  \\\n",
       "0        Private          Urban             228.69  36.600000   \n",
       "1  Self-employed          Rural             202.21  28.893237   \n",
       "2        Private          Rural             105.92  32.500000   \n",
       "3        Private          Urban             171.23  34.400000   \n",
       "4  Self-employed          Rural             174.12  24.000000   \n",
       "5        Private          Urban             186.21  29.000000   \n",
       "6        Private          Rural              70.09  27.400000   \n",
       "7        Private          Urban              94.39  22.800000   \n",
       "8        Private          Rural              76.15  28.893237   \n",
       "9        Private          Urban              58.57  24.200000   \n",
       "\n",
       "    smoking_status  target  \n",
       "0  formerly smoked       1  \n",
       "1     never smoked       1  \n",
       "2     never smoked       1  \n",
       "3           smokes       1  \n",
       "4     never smoked       1  \n",
       "5  formerly smoked       1  \n",
       "6     never smoked       1  \n",
       "7     never smoked       1  \n",
       "8          Unknown       1  \n",
       "9          Unknown       1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'id'}>,\n",
       "        <AxesSubplot:title={'center':'age'}>,\n",
       "        <AxesSubplot:title={'center':'hypertension'}>],\n",
       "       [<AxesSubplot:title={'center':'heart_disease'}>,\n",
       "        <AxesSubplot:title={'center':'avg_glucose_level'}>,\n",
       "        <AxesSubplot:title={'center':'bmi'}>],\n",
       "       [<AxesSubplot:title={'center':'target'}>, <AxesSubplot:>,\n",
       "        <AxesSubplot:>]], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"target\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"id\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'work_type': {'children': 0, 'Never_worked': 1, 'Self-employed': 2, 'Private': 3, 'Govt_job': 4}}\n"
     ]
    }
   ],
   "source": [
    "replace_map={'work_type':{'children': 0,'Never_worked': 1, 'Self-employed': 2, 'Private': 3, 'Govt_job': 4}}\n",
    "labels = df['work_type'].astype('category').cat.categories.tolist()\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ever_married': {'Yes': 1, 'No': 0}}\n"
     ]
    }
   ],
   "source": [
    "replace_map={'ever_married':{'Yes': 1, 'No': 0}}\n",
    "labels = df['ever_married'].astype('category').cat.categories.tolist()\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Residence_type': {'Urban': 1, 'Rural': 0}}\n"
     ]
    }
   ],
   "source": [
    "replace_map={'Residence_type':{'Urban': 1, 'Rural': 0}}\n",
    "labels = df['Residence_type'].astype('category').cat.categories.tolist()\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'smoking_status': {'never smoked': 0, 'Unknown': 1, 'formerly smoked': 2, 'smokes': 3}}\n"
     ]
    }
   ],
   "source": [
    "replace_map={'smoking_status':{'never smoked': 0, 'Unknown': 1, 'formerly smoked': 2, 'smokes': 3}}\n",
    "labels = df['smoking_status'].astype('category').cat.categories.tolist()\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': {'Male': 1, 'Other': 0, 'Female': -1}}\n"
     ]
    }
   ],
   "source": [
    "replace_map={'gender':{'Male': 1, 'Other': 0, 'Female': -1,}}\n",
    "labels = df['gender'].astype('category').cat.categories.tolist()\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"target\",axis=1).copy()\n",
    "y=df[\"target\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, stratify= y, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 400)               4400      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 145,102\n",
      "Trainable params: 145,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.models.Sequential([\n",
    "                    keras.layers.Input(shape=X_train.shape[1], name='input'),\n",
    "                    keras.layers.Dense(400, activation='relu'),\n",
    "                    keras.layers.Dense(200, activation='relu'),\n",
    "                    keras.layers.Dense(200, activation='relu'),\n",
    "                    keras.layers.Dense(100, activation='relu'),\n",
    "                    keras.layers.Dense(2, activation='softmax', name='output')\n",
    "                    ])\n",
    "\n",
    "model1.compile(\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics= ['accuracy']\n",
    "            )\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "120/120 [==============================] - 1s 3ms/step - loss: 0.5133 - accuracy: 0.8988 - val_loss: 0.4045 - val_accuracy: 0.9515\n",
      "Epoch 2/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9535 - val_loss: 0.1836 - val_accuracy: 0.9515\n",
      "Epoch 3/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9461 - val_loss: 0.1875 - val_accuracy: 0.9515\n",
      "Epoch 4/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9489 - val_loss: 0.1719 - val_accuracy: 0.9515\n",
      "Epoch 5/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9559 - val_loss: 0.1778 - val_accuracy: 0.9515\n",
      "Epoch 6/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9602 - val_loss: 0.1698 - val_accuracy: 0.9515\n",
      "Epoch 7/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9530 - val_loss: 0.1823 - val_accuracy: 0.9515\n",
      "Epoch 8/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9511 - val_loss: 0.1817 - val_accuracy: 0.9515\n",
      "Epoch 9/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9489 - val_loss: 0.1745 - val_accuracy: 0.9515\n",
      "Epoch 10/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9509 - val_loss: 0.1679 - val_accuracy: 0.9515\n",
      "Epoch 11/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.9555 - val_loss: 0.1756 - val_accuracy: 0.9515\n",
      "Epoch 12/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9482 - val_loss: 0.1656 - val_accuracy: 0.9515\n",
      "Epoch 13/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9558 - val_loss: 0.1622 - val_accuracy: 0.9515\n",
      "Epoch 14/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9487 - val_loss: 0.1749 - val_accuracy: 0.9515\n",
      "Epoch 15/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9481 - val_loss: 0.1684 - val_accuracy: 0.9515\n",
      "Epoch 16/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9502 - val_loss: 0.1665 - val_accuracy: 0.9515\n",
      "Epoch 17/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9523 - val_loss: 0.1605 - val_accuracy: 0.9515\n",
      "Epoch 18/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9494 - val_loss: 0.1657 - val_accuracy: 0.9515\n",
      "Epoch 19/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9448 - val_loss: 0.1607 - val_accuracy: 0.9515\n",
      "Epoch 20/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9535 - val_loss: 0.1631 - val_accuracy: 0.9515\n",
      "Epoch 21/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9522 - val_loss: 0.1660 - val_accuracy: 0.9515\n",
      "Epoch 22/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9486 - val_loss: 0.1613 - val_accuracy: 0.9515\n",
      "Epoch 23/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9553 - val_loss: 0.1691 - val_accuracy: 0.9515\n",
      "Epoch 24/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.9510 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 25/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9574 - val_loss: 0.1577 - val_accuracy: 0.9515\n",
      "Epoch 26/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9498 - val_loss: 0.1656 - val_accuracy: 0.9515\n",
      "Epoch 27/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9508 - val_loss: 0.1617 - val_accuracy: 0.9515\n",
      "Epoch 28/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9539 - val_loss: 0.1663 - val_accuracy: 0.9515\n",
      "Epoch 29/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9509 - val_loss: 0.1617 - val_accuracy: 0.9515\n",
      "Epoch 30/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.9478 - val_loss: 0.1593 - val_accuracy: 0.9515\n",
      "Epoch 31/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9494 - val_loss: 0.1617 - val_accuracy: 0.9515\n",
      "Epoch 32/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9486 - val_loss: 0.1587 - val_accuracy: 0.9515\n",
      "Epoch 33/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9504 - val_loss: 0.1610 - val_accuracy: 0.9515\n",
      "Epoch 34/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9540 - val_loss: 0.1794 - val_accuracy: 0.9515\n",
      "Epoch 35/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9534 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 36/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9511 - val_loss: 0.1622 - val_accuracy: 0.9515\n",
      "Epoch 37/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9511 - val_loss: 0.1599 - val_accuracy: 0.9515\n",
      "Epoch 38/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.9475 - val_loss: 0.1534 - val_accuracy: 0.9515\n",
      "Epoch 39/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9570 - val_loss: 0.1609 - val_accuracy: 0.9515\n",
      "Epoch 40/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9544 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 41/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.9505 - val_loss: 0.1574 - val_accuracy: 0.9515\n",
      "Epoch 42/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9536 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 43/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1563 - accuracy: 0.9537 - val_loss: 0.1587 - val_accuracy: 0.9515\n",
      "Epoch 44/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9511 - val_loss: 0.1632 - val_accuracy: 0.9515\n",
      "Epoch 45/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9460 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 46/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9442 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 47/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9563 - val_loss: 0.1691 - val_accuracy: 0.9515\n",
      "Epoch 48/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9522 - val_loss: 0.1581 - val_accuracy: 0.9515\n",
      "Epoch 49/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9468 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 50/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9441 - val_loss: 0.1587 - val_accuracy: 0.9515\n",
      "Epoch 51/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9505 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 52/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9465 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 53/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9489 - val_loss: 0.1615 - val_accuracy: 0.9515\n",
      "Epoch 54/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9483 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 55/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9517 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 56/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9479 - val_loss: 0.1619 - val_accuracy: 0.9515\n",
      "Epoch 57/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9569 - val_loss: 0.1573 - val_accuracy: 0.9515\n",
      "Epoch 58/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9552 - val_loss: 0.1536 - val_accuracy: 0.9515\n",
      "Epoch 59/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9495 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 60/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9503 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 61/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9423 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 62/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9501 - val_loss: 0.1609 - val_accuracy: 0.9515\n",
      "Epoch 63/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9535 - val_loss: 0.1531 - val_accuracy: 0.9515\n",
      "Epoch 64/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9495 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 65/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9451 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 66/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9519 - val_loss: 0.1627 - val_accuracy: 0.9515\n",
      "Epoch 67/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9540 - val_loss: 0.1527 - val_accuracy: 0.9515\n",
      "Epoch 68/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9561 - val_loss: 0.1531 - val_accuracy: 0.9515\n",
      "Epoch 69/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9491 - val_loss: 0.1524 - val_accuracy: 0.9515\n",
      "Epoch 70/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9550 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 71/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9489 - val_loss: 0.1525 - val_accuracy: 0.9515\n",
      "Epoch 72/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9535 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 73/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9528 - val_loss: 0.1574 - val_accuracy: 0.9515\n",
      "Epoch 74/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9531 - val_loss: 0.1520 - val_accuracy: 0.9515\n",
      "Epoch 75/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9460 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 76/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9496 - val_loss: 0.1525 - val_accuracy: 0.9515\n",
      "Epoch 77/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9486 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 78/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9537 - val_loss: 0.1515 - val_accuracy: 0.9515\n",
      "Epoch 79/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9476 - val_loss: 0.1517 - val_accuracy: 0.9515\n",
      "Epoch 80/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9539 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 81/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9533 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 82/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9473 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 83/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9578 - val_loss: 0.1508 - val_accuracy: 0.9515\n",
      "Epoch 84/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1588 - accuracy: 0.9494 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 85/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9462 - val_loss: 0.1528 - val_accuracy: 0.9515\n",
      "Epoch 86/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.9498 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 87/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9486 - val_loss: 0.1520 - val_accuracy: 0.9515\n",
      "Epoch 88/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9426 - val_loss: 0.1533 - val_accuracy: 0.9515\n",
      "Epoch 89/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9545 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 90/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9546 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 91/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9489 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 92/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.9505 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 93/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9501 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 94/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9554 - val_loss: 0.1535 - val_accuracy: 0.9515\n",
      "Epoch 95/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9512 - val_loss: 0.1678 - val_accuracy: 0.9515\n",
      "Epoch 96/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9599 - val_loss: 0.1516 - val_accuracy: 0.9515\n",
      "Epoch 97/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9536 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 98/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9474 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 99/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9517 - val_loss: 0.1532 - val_accuracy: 0.9515\n",
      "Epoch 100/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9543 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 101/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9560 - val_loss: 0.1529 - val_accuracy: 0.9515\n",
      "Epoch 102/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9491 - val_loss: 0.1533 - val_accuracy: 0.9515\n",
      "Epoch 103/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9517 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 104/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9499 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 105/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9494 - val_loss: 0.1520 - val_accuracy: 0.9515\n",
      "Epoch 106/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9539 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 107/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9483 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 108/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9502 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 109/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9505 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 110/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1681 - accuracy: 0.9450 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 111/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9502 - val_loss: 0.1535 - val_accuracy: 0.9515\n",
      "Epoch 112/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9479 - val_loss: 0.1559 - val_accuracy: 0.9507\n",
      "Epoch 113/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9498 - val_loss: 0.1513 - val_accuracy: 0.9515\n",
      "Epoch 114/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9459 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 115/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9521 - val_loss: 0.1520 - val_accuracy: 0.9515\n",
      "Epoch 116/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9520 - val_loss: 0.1645 - val_accuracy: 0.9515\n",
      "Epoch 117/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9482 - val_loss: 0.1528 - val_accuracy: 0.9515\n",
      "Epoch 118/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.9511 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 119/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9526 - val_loss: 0.1525 - val_accuracy: 0.9515\n",
      "Epoch 120/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9479 - val_loss: 0.1631 - val_accuracy: 0.9515\n",
      "Epoch 121/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9520 - val_loss: 0.1633 - val_accuracy: 0.9460\n",
      "Epoch 122/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9529 - val_loss: 0.1578 - val_accuracy: 0.9515\n",
      "Epoch 123/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9541 - val_loss: 0.1608 - val_accuracy: 0.9515\n",
      "Epoch 124/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9523 - val_loss: 0.1597 - val_accuracy: 0.9515\n",
      "Epoch 125/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9492 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 126/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9466 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 127/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9497 - val_loss: 0.1558 - val_accuracy: 0.9507\n",
      "Epoch 128/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9496 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 129/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9532 - val_loss: 0.1582 - val_accuracy: 0.9499\n",
      "Epoch 130/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9500 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 131/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9565 - val_loss: 0.1532 - val_accuracy: 0.9515\n",
      "Epoch 132/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9495 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 133/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1449 - accuracy: 0.9536 - val_loss: 0.1528 - val_accuracy: 0.9515\n",
      "Epoch 134/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9474 - val_loss: 0.1549 - val_accuracy: 0.9507\n",
      "Epoch 135/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9501 - val_loss: 0.1574 - val_accuracy: 0.9515\n",
      "Epoch 136/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9522 - val_loss: 0.1553 - val_accuracy: 0.9499\n",
      "Epoch 137/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9549 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 138/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9496 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 139/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9476 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 140/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9523 - val_loss: 0.1563 - val_accuracy: 0.9499\n",
      "Epoch 141/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9499 - val_loss: 0.1516 - val_accuracy: 0.9515\n",
      "Epoch 142/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9573 - val_loss: 0.1536 - val_accuracy: 0.9515\n",
      "Epoch 143/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1563 - accuracy: 0.9471 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 144/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9516 - val_loss: 0.1536 - val_accuracy: 0.9515\n",
      "Epoch 145/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9531 - val_loss: 0.1553 - val_accuracy: 0.9507\n",
      "Epoch 146/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9549 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 147/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9491 - val_loss: 0.1632 - val_accuracy: 0.9484\n",
      "Epoch 148/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9565 - val_loss: 0.1552 - val_accuracy: 0.9507\n",
      "Epoch 149/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9525 - val_loss: 0.1570 - val_accuracy: 0.9507\n",
      "Epoch 150/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9517 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 151/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9438 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 152/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1523 - accuracy: 0.9507 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 153/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9522 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 154/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9551 - val_loss: 0.1568 - val_accuracy: 0.9507\n",
      "Epoch 155/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9508 - val_loss: 0.1541 - val_accuracy: 0.9507\n",
      "Epoch 156/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9576 - val_loss: 0.1644 - val_accuracy: 0.9460\n",
      "Epoch 157/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9488 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 158/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9530 - val_loss: 0.1568 - val_accuracy: 0.9507\n",
      "Epoch 159/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9503 - val_loss: 0.1583 - val_accuracy: 0.9491\n",
      "Epoch 160/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9502 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 161/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1685 - accuracy: 0.9436 - val_loss: 0.1538 - val_accuracy: 0.9507\n",
      "Epoch 162/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9472 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 163/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9486 - val_loss: 0.1560 - val_accuracy: 0.9499\n",
      "Epoch 164/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9576 - val_loss: 0.1508 - val_accuracy: 0.9515\n",
      "Epoch 165/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9574 - val_loss: 0.1561 - val_accuracy: 0.9491\n",
      "Epoch 166/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9577 - val_loss: 0.1526 - val_accuracy: 0.9507\n",
      "Epoch 167/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9525 - val_loss: 0.1575 - val_accuracy: 0.9491\n",
      "Epoch 168/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9518 - val_loss: 0.1536 - val_accuracy: 0.9515\n",
      "Epoch 169/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9539 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 170/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9464 - val_loss: 0.1616 - val_accuracy: 0.9507\n",
      "Epoch 171/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9513 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 172/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9516 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 173/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9560 - val_loss: 0.1527 - val_accuracy: 0.9515\n",
      "Epoch 174/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.9519 - val_loss: 0.1555 - val_accuracy: 0.9507\n",
      "Epoch 175/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9525 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 176/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9496 - val_loss: 0.1567 - val_accuracy: 0.9507\n",
      "Epoch 177/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9529 - val_loss: 0.1543 - val_accuracy: 0.9507\n",
      "Epoch 178/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.9533 - val_loss: 0.1532 - val_accuracy: 0.9507\n",
      "Epoch 179/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9474 - val_loss: 0.1514 - val_accuracy: 0.9507\n",
      "Epoch 180/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9570 - val_loss: 0.1563 - val_accuracy: 0.9491\n",
      "Epoch 181/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9546 - val_loss: 0.1561 - val_accuracy: 0.9507\n",
      "Epoch 182/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9558 - val_loss: 0.1545 - val_accuracy: 0.9507\n",
      "Epoch 183/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9542 - val_loss: 0.1547 - val_accuracy: 0.9507\n",
      "Epoch 184/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9504 - val_loss: 0.1578 - val_accuracy: 0.9484\n",
      "Epoch 185/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9521 - val_loss: 0.1562 - val_accuracy: 0.9507\n",
      "Epoch 186/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9530 - val_loss: 0.1542 - val_accuracy: 0.9507\n",
      "Epoch 187/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.9479 - val_loss: 0.1588 - val_accuracy: 0.9499\n",
      "Epoch 188/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9572 - val_loss: 0.1529 - val_accuracy: 0.9507\n",
      "Epoch 189/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9523 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 190/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9485 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 191/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9509 - val_loss: 0.1558 - val_accuracy: 0.9507\n",
      "Epoch 192/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1422 - accuracy: 0.9574 - val_loss: 0.1592 - val_accuracy: 0.9491\n",
      "Epoch 193/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9539 - val_loss: 0.1569 - val_accuracy: 0.9491\n",
      "Epoch 194/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9522 - val_loss: 0.1583 - val_accuracy: 0.9491\n",
      "Epoch 195/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9523 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 196/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9477 - val_loss: 0.1590 - val_accuracy: 0.9507\n",
      "Epoch 197/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9557 - val_loss: 0.1571 - val_accuracy: 0.9515\n",
      "Epoch 198/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9501 - val_loss: 0.1556 - val_accuracy: 0.9507\n",
      "Epoch 199/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9522 - val_loss: 0.1532 - val_accuracy: 0.9499\n",
      "Epoch 200/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9495 - val_loss: 0.1546 - val_accuracy: 0.9491\n",
      "Epoch 201/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9504 - val_loss: 0.1701 - val_accuracy: 0.9452\n",
      "Epoch 202/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9560 - val_loss: 0.1573 - val_accuracy: 0.9499\n",
      "Epoch 203/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9485 - val_loss: 0.1540 - val_accuracy: 0.9507\n",
      "Epoch 204/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9532 - val_loss: 0.1565 - val_accuracy: 0.9507\n",
      "Epoch 205/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.9462 - val_loss: 0.1600 - val_accuracy: 0.9499\n",
      "Epoch 206/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9543 - val_loss: 0.1595 - val_accuracy: 0.9507\n",
      "Epoch 207/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9463 - val_loss: 0.1562 - val_accuracy: 0.9507\n",
      "Epoch 208/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9529 - val_loss: 0.1550 - val_accuracy: 0.9507\n",
      "Epoch 209/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9514 - val_loss: 0.1639 - val_accuracy: 0.9491\n",
      "Epoch 210/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9517 - val_loss: 0.1585 - val_accuracy: 0.9507\n",
      "Epoch 211/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9525 - val_loss: 0.1560 - val_accuracy: 0.9507\n",
      "Epoch 212/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9475 - val_loss: 0.1570 - val_accuracy: 0.9507\n",
      "Epoch 213/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9529 - val_loss: 0.1603 - val_accuracy: 0.9499\n",
      "Epoch 214/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9506 - val_loss: 0.1540 - val_accuracy: 0.9499\n",
      "Epoch 215/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9509 - val_loss: 0.1592 - val_accuracy: 0.9499\n",
      "Epoch 216/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9527 - val_loss: 0.1596 - val_accuracy: 0.9507\n",
      "Epoch 217/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9518 - val_loss: 0.1542 - val_accuracy: 0.9507\n",
      "Epoch 218/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9559 - val_loss: 0.1552 - val_accuracy: 0.9507\n",
      "Epoch 219/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9540 - val_loss: 0.1555 - val_accuracy: 0.9507\n",
      "Epoch 220/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9561 - val_loss: 0.1557 - val_accuracy: 0.9507\n",
      "Epoch 221/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9518 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 222/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9538 - val_loss: 0.1523 - val_accuracy: 0.9515\n",
      "Epoch 223/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9533 - val_loss: 0.1588 - val_accuracy: 0.9491\n",
      "Epoch 224/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9568 - val_loss: 0.1557 - val_accuracy: 0.9507\n",
      "Epoch 225/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9530 - val_loss: 0.1536 - val_accuracy: 0.9499\n",
      "Epoch 226/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9580 - val_loss: 0.1555 - val_accuracy: 0.9507\n",
      "Epoch 227/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9468 - val_loss: 0.1548 - val_accuracy: 0.9507\n",
      "Epoch 228/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9519 - val_loss: 0.1566 - val_accuracy: 0.9491\n",
      "Epoch 229/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9487 - val_loss: 0.1608 - val_accuracy: 0.9491\n",
      "Epoch 230/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9570 - val_loss: 0.1580 - val_accuracy: 0.9507\n",
      "Epoch 231/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9500 - val_loss: 0.1579 - val_accuracy: 0.9507\n",
      "Epoch 232/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9529 - val_loss: 0.1611 - val_accuracy: 0.9476\n",
      "Epoch 233/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9522 - val_loss: 0.1536 - val_accuracy: 0.9507\n",
      "Epoch 234/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9510 - val_loss: 0.1565 - val_accuracy: 0.9507\n",
      "Epoch 235/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9586 - val_loss: 0.1551 - val_accuracy: 0.9507\n",
      "Epoch 236/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9492 - val_loss: 0.1638 - val_accuracy: 0.9515\n",
      "Epoch 237/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9557 - val_loss: 0.1591 - val_accuracy: 0.9476\n",
      "Epoch 238/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9534 - val_loss: 0.1569 - val_accuracy: 0.9499\n",
      "Epoch 239/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9583 - val_loss: 0.1561 - val_accuracy: 0.9499\n",
      "Epoch 240/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9462 - val_loss: 0.1558 - val_accuracy: 0.9499\n",
      "Epoch 241/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9495 - val_loss: 0.1575 - val_accuracy: 0.9491\n",
      "Epoch 242/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9496 - val_loss: 0.1563 - val_accuracy: 0.9499\n",
      "Epoch 243/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1449 - accuracy: 0.9536 - val_loss: 0.1553 - val_accuracy: 0.9507\n",
      "Epoch 244/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9556 - val_loss: 0.1527 - val_accuracy: 0.9507\n",
      "Epoch 245/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9558 - val_loss: 0.1582 - val_accuracy: 0.9507\n",
      "Epoch 246/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9505 - val_loss: 0.1588 - val_accuracy: 0.9499\n",
      "Epoch 247/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9497 - val_loss: 0.1587 - val_accuracy: 0.9499\n",
      "Epoch 248/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9559 - val_loss: 0.1625 - val_accuracy: 0.9476\n",
      "Epoch 249/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9497 - val_loss: 0.1619 - val_accuracy: 0.9507\n",
      "Epoch 250/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9526 - val_loss: 0.1546 - val_accuracy: 0.9507\n",
      "Epoch 251/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9527 - val_loss: 0.1569 - val_accuracy: 0.9499\n",
      "Epoch 252/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9597 - val_loss: 0.1611 - val_accuracy: 0.9507\n",
      "Epoch 253/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9506 - val_loss: 0.1570 - val_accuracy: 0.9499\n",
      "Epoch 254/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9515 - val_loss: 0.1603 - val_accuracy: 0.9499\n",
      "Epoch 255/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9547 - val_loss: 0.1547 - val_accuracy: 0.9507\n",
      "Epoch 256/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.9452 - val_loss: 0.1587 - val_accuracy: 0.9491\n",
      "Epoch 257/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9577 - val_loss: 0.1556 - val_accuracy: 0.9507\n",
      "Epoch 258/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9521 - val_loss: 0.1585 - val_accuracy: 0.9499\n",
      "Epoch 259/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9540 - val_loss: 0.1534 - val_accuracy: 0.9507\n",
      "Epoch 260/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9536 - val_loss: 0.1568 - val_accuracy: 0.9484\n",
      "Epoch 261/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9536 - val_loss: 0.1559 - val_accuracy: 0.9507\n",
      "Epoch 262/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9519 - val_loss: 0.1538 - val_accuracy: 0.9499\n",
      "Epoch 263/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9518 - val_loss: 0.1547 - val_accuracy: 0.9507\n",
      "Epoch 264/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9506 - val_loss: 0.1586 - val_accuracy: 0.9499\n",
      "Epoch 265/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9523 - val_loss: 0.1560 - val_accuracy: 0.9507\n",
      "Epoch 266/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9501 - val_loss: 0.1604 - val_accuracy: 0.9499\n",
      "Epoch 267/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9483 - val_loss: 0.1610 - val_accuracy: 0.9499\n",
      "Epoch 268/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9526 - val_loss: 0.1578 - val_accuracy: 0.9507\n",
      "Epoch 269/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9441 - val_loss: 0.1544 - val_accuracy: 0.9507\n",
      "Epoch 270/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9533 - val_loss: 0.1613 - val_accuracy: 0.9491\n",
      "Epoch 271/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9508 - val_loss: 0.1571 - val_accuracy: 0.9507\n",
      "Epoch 272/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9486 - val_loss: 0.1529 - val_accuracy: 0.9507\n",
      "Epoch 273/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9541 - val_loss: 0.1627 - val_accuracy: 0.9476\n",
      "Epoch 274/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9483 - val_loss: 0.1540 - val_accuracy: 0.9507\n",
      "Epoch 275/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9523 - val_loss: 0.1585 - val_accuracy: 0.9499\n",
      "Epoch 276/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9519 - val_loss: 0.1555 - val_accuracy: 0.9507\n",
      "Epoch 277/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9567 - val_loss: 0.1597 - val_accuracy: 0.9499\n",
      "Epoch 278/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9497 - val_loss: 0.1551 - val_accuracy: 0.9499\n",
      "Epoch 279/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9541 - val_loss: 0.1580 - val_accuracy: 0.9507\n",
      "Epoch 280/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9529 - val_loss: 0.1583 - val_accuracy: 0.9499\n",
      "Epoch 281/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9541 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 282/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9550 - val_loss: 0.1567 - val_accuracy: 0.9507\n",
      "Epoch 283/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9605 - val_loss: 0.1579 - val_accuracy: 0.9507\n",
      "Epoch 284/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.9491 - val_loss: 0.1646 - val_accuracy: 0.9484\n",
      "Epoch 285/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9559 - val_loss: 0.1585 - val_accuracy: 0.9484\n",
      "Epoch 286/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9534 - val_loss: 0.1537 - val_accuracy: 0.9507\n",
      "Epoch 287/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9526 - val_loss: 0.1546 - val_accuracy: 0.9507\n",
      "Epoch 288/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9503 - val_loss: 0.1564 - val_accuracy: 0.9507\n",
      "Epoch 289/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9510 - val_loss: 0.1588 - val_accuracy: 0.9507\n",
      "Epoch 290/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9563 - val_loss: 0.1552 - val_accuracy: 0.9507\n",
      "Epoch 291/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9606 - val_loss: 0.1585 - val_accuracy: 0.9491\n",
      "Epoch 292/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9578 - val_loss: 0.1544 - val_accuracy: 0.9507\n",
      "Epoch 293/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9527 - val_loss: 0.1553 - val_accuracy: 0.9507\n",
      "Epoch 294/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9539 - val_loss: 0.1589 - val_accuracy: 0.9499\n",
      "Epoch 295/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9506 - val_loss: 0.1553 - val_accuracy: 0.9499\n",
      "Epoch 296/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1422 - accuracy: 0.9533 - val_loss: 0.1615 - val_accuracy: 0.9507\n",
      "Epoch 297/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9489 - val_loss: 0.1601 - val_accuracy: 0.9507\n",
      "Epoch 298/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9510 - val_loss: 0.1576 - val_accuracy: 0.9507\n",
      "Epoch 299/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9515 - val_loss: 0.1630 - val_accuracy: 0.9484\n",
      "Epoch 300/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1555 - accuracy: 0.9472 - val_loss: 0.1584 - val_accuracy: 0.9507\n",
      "Epoch 301/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9460 - val_loss: 0.1558 - val_accuracy: 0.9507\n",
      "Epoch 302/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9512 - val_loss: 0.1556 - val_accuracy: 0.9507\n",
      "Epoch 303/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9564 - val_loss: 0.1597 - val_accuracy: 0.9499\n",
      "Epoch 304/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9486 - val_loss: 0.1568 - val_accuracy: 0.9507\n",
      "Epoch 305/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1449 - accuracy: 0.9498 - val_loss: 0.1567 - val_accuracy: 0.9507\n",
      "Epoch 306/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9507 - val_loss: 0.1571 - val_accuracy: 0.9507\n",
      "Epoch 307/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9482 - val_loss: 0.1582 - val_accuracy: 0.9491\n",
      "Epoch 308/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9489 - val_loss: 0.1569 - val_accuracy: 0.9499\n",
      "Epoch 309/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9476 - val_loss: 0.1608 - val_accuracy: 0.9515\n",
      "Epoch 310/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9563 - val_loss: 0.1565 - val_accuracy: 0.9507\n",
      "Epoch 311/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9539 - val_loss: 0.1573 - val_accuracy: 0.9507\n",
      "Epoch 312/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9477 - val_loss: 0.1562 - val_accuracy: 0.9507\n",
      "Epoch 313/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9466 - val_loss: 0.1564 - val_accuracy: 0.9507\n",
      "Epoch 314/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9530 - val_loss: 0.1581 - val_accuracy: 0.9507\n",
      "Epoch 315/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9564 - val_loss: 0.1603 - val_accuracy: 0.9499\n",
      "Epoch 316/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.9528 - val_loss: 0.1563 - val_accuracy: 0.9499\n",
      "Epoch 317/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9469 - val_loss: 0.1598 - val_accuracy: 0.9499\n",
      "Epoch 318/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9513 - val_loss: 0.1590 - val_accuracy: 0.9507\n",
      "Epoch 319/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9485 - val_loss: 0.1599 - val_accuracy: 0.9507\n",
      "Epoch 320/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9536 - val_loss: 0.1550 - val_accuracy: 0.9507\n",
      "Epoch 321/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9495 - val_loss: 0.1578 - val_accuracy: 0.9499\n",
      "Epoch 322/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9521 - val_loss: 0.1574 - val_accuracy: 0.9507\n",
      "Epoch 323/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9478 - val_loss: 0.1563 - val_accuracy: 0.9507\n",
      "Epoch 324/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9561 - val_loss: 0.1549 - val_accuracy: 0.9507\n",
      "Epoch 325/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9590 - val_loss: 0.1866 - val_accuracy: 0.9476\n",
      "Epoch 326/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9492 - val_loss: 0.1581 - val_accuracy: 0.9499\n",
      "Epoch 327/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9548 - val_loss: 0.1549 - val_accuracy: 0.9507\n",
      "Epoch 328/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9552 - val_loss: 0.1566 - val_accuracy: 0.9507\n",
      "Epoch 329/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9551 - val_loss: 0.1607 - val_accuracy: 0.9499\n",
      "Epoch 330/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.9492 - val_loss: 0.1538 - val_accuracy: 0.9507\n",
      "Epoch 331/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9400 - val_loss: 0.1596 - val_accuracy: 0.9507\n",
      "Epoch 332/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9520 - val_loss: 0.1542 - val_accuracy: 0.9507\n",
      "Epoch 333/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9536 - val_loss: 0.1586 - val_accuracy: 0.9507\n",
      "Epoch 334/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9529 - val_loss: 0.1574 - val_accuracy: 0.9499\n",
      "Epoch 335/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9514 - val_loss: 0.1572 - val_accuracy: 0.9507\n",
      "Epoch 336/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9532 - val_loss: 0.1576 - val_accuracy: 0.9507\n",
      "Epoch 337/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9580 - val_loss: 0.1565 - val_accuracy: 0.9507\n",
      "Epoch 338/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9529 - val_loss: 0.1694 - val_accuracy: 0.9460\n",
      "Epoch 339/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9544 - val_loss: 0.1634 - val_accuracy: 0.9484\n",
      "Epoch 340/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9536 - val_loss: 0.1623 - val_accuracy: 0.9484\n",
      "Epoch 341/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9530 - val_loss: 0.1560 - val_accuracy: 0.9484\n",
      "Epoch 342/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9402 - val_loss: 0.1649 - val_accuracy: 0.9484\n",
      "Epoch 343/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9553 - val_loss: 0.1563 - val_accuracy: 0.9507\n",
      "Epoch 344/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9534 - val_loss: 0.1579 - val_accuracy: 0.9491\n",
      "Epoch 345/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9564 - val_loss: 0.1578 - val_accuracy: 0.9507\n",
      "Epoch 346/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9557 - val_loss: 0.1576 - val_accuracy: 0.9491\n",
      "Epoch 347/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9564 - val_loss: 0.1619 - val_accuracy: 0.9491\n",
      "Epoch 348/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9533 - val_loss: 0.1586 - val_accuracy: 0.9507\n",
      "Epoch 349/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9539 - val_loss: 0.1598 - val_accuracy: 0.9507\n",
      "Epoch 350/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9560 - val_loss: 0.1624 - val_accuracy: 0.9484\n",
      "Epoch 351/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9489 - val_loss: 0.1621 - val_accuracy: 0.9507\n",
      "Epoch 352/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9528 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 353/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9492 - val_loss: 0.1601 - val_accuracy: 0.9484\n",
      "Epoch 354/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9567 - val_loss: 0.1560 - val_accuracy: 0.9499\n",
      "Epoch 355/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9510 - val_loss: 0.1633 - val_accuracy: 0.9491\n",
      "Epoch 356/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9526 - val_loss: 0.1661 - val_accuracy: 0.9468\n",
      "Epoch 357/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9487 - val_loss: 0.1651 - val_accuracy: 0.9484\n",
      "Epoch 358/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9546 - val_loss: 0.1590 - val_accuracy: 0.9507\n",
      "Epoch 359/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9498 - val_loss: 0.1634 - val_accuracy: 0.9507\n",
      "Epoch 360/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1370 - accuracy: 0.9552 - val_loss: 0.1586 - val_accuracy: 0.9507\n",
      "Epoch 361/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9530 - val_loss: 0.1628 - val_accuracy: 0.9507\n",
      "Epoch 362/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9485 - val_loss: 0.1560 - val_accuracy: 0.9499\n",
      "Epoch 363/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9530 - val_loss: 0.1724 - val_accuracy: 0.9460\n",
      "Epoch 364/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9524 - val_loss: 0.1620 - val_accuracy: 0.9507\n",
      "Epoch 365/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9518 - val_loss: 0.1612 - val_accuracy: 0.9507\n",
      "Epoch 366/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9521 - val_loss: 0.1589 - val_accuracy: 0.9499\n",
      "Epoch 367/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9464 - val_loss: 0.1617 - val_accuracy: 0.9507\n",
      "Epoch 368/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9555 - val_loss: 0.1583 - val_accuracy: 0.9507\n",
      "Epoch 369/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9550 - val_loss: 0.1571 - val_accuracy: 0.9499\n",
      "Epoch 370/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9489 - val_loss: 0.1623 - val_accuracy: 0.9507\n",
      "Epoch 371/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9559 - val_loss: 0.1626 - val_accuracy: 0.9491\n",
      "Epoch 372/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9616 - val_loss: 0.1504 - val_accuracy: 0.9507\n",
      "Epoch 373/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9495 - val_loss: 0.1618 - val_accuracy: 0.9476\n",
      "Epoch 374/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9573 - val_loss: 0.1588 - val_accuracy: 0.9499\n",
      "Epoch 375/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9485 - val_loss: 0.1621 - val_accuracy: 0.9507\n",
      "Epoch 376/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9497 - val_loss: 0.1535 - val_accuracy: 0.9507\n",
      "Epoch 377/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9529 - val_loss: 0.1615 - val_accuracy: 0.9499\n",
      "Epoch 378/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9494 - val_loss: 0.1549 - val_accuracy: 0.9507\n",
      "Epoch 379/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9512 - val_loss: 0.1582 - val_accuracy: 0.9507\n",
      "Epoch 380/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9502 - val_loss: 0.1685 - val_accuracy: 0.9476\n",
      "Epoch 381/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9496 - val_loss: 0.1576 - val_accuracy: 0.9499\n",
      "Epoch 382/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9544 - val_loss: 0.1651 - val_accuracy: 0.9476\n",
      "Epoch 383/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9573 - val_loss: 0.1637 - val_accuracy: 0.9476\n",
      "Epoch 384/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9507 - val_loss: 0.1553 - val_accuracy: 0.9507\n",
      "Epoch 385/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9528 - val_loss: 0.1587 - val_accuracy: 0.9507\n",
      "Epoch 386/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9542 - val_loss: 0.1582 - val_accuracy: 0.9507\n",
      "Epoch 387/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9602 - val_loss: 0.1657 - val_accuracy: 0.9491\n",
      "Epoch 388/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9515 - val_loss: 0.1596 - val_accuracy: 0.9507\n",
      "Epoch 389/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9537 - val_loss: 0.1621 - val_accuracy: 0.9484\n",
      "Epoch 390/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9525 - val_loss: 0.1641 - val_accuracy: 0.9484\n",
      "Epoch 391/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9536 - val_loss: 0.1658 - val_accuracy: 0.9476\n",
      "Epoch 392/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1561 - accuracy: 0.9478 - val_loss: 0.1598 - val_accuracy: 0.9507\n",
      "Epoch 393/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9531 - val_loss: 0.1579 - val_accuracy: 0.9499\n",
      "Epoch 394/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9494 - val_loss: 0.1667 - val_accuracy: 0.9484\n",
      "Epoch 395/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9465 - val_loss: 0.1655 - val_accuracy: 0.9476\n",
      "Epoch 396/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9518 - val_loss: 0.1606 - val_accuracy: 0.9484\n",
      "Epoch 397/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9585 - val_loss: 0.1658 - val_accuracy: 0.9437\n",
      "Epoch 398/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9562 - val_loss: 0.1593 - val_accuracy: 0.9499\n",
      "Epoch 399/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9542 - val_loss: 0.1600 - val_accuracy: 0.9452\n",
      "Epoch 400/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9489 - val_loss: 0.1561 - val_accuracy: 0.9499\n",
      "Epoch 401/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9521 - val_loss: 0.1585 - val_accuracy: 0.9507\n",
      "Epoch 402/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9494 - val_loss: 0.1632 - val_accuracy: 0.9507\n",
      "Epoch 403/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9559 - val_loss: 0.1548 - val_accuracy: 0.9507\n",
      "Epoch 404/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9527 - val_loss: 0.1685 - val_accuracy: 0.9499\n",
      "Epoch 405/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9559 - val_loss: 0.1685 - val_accuracy: 0.9476\n",
      "Epoch 406/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9539 - val_loss: 0.1577 - val_accuracy: 0.9499\n",
      "Epoch 407/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9518 - val_loss: 0.1597 - val_accuracy: 0.9507\n",
      "Epoch 408/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9543 - val_loss: 0.1612 - val_accuracy: 0.9499\n",
      "Epoch 409/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9583 - val_loss: 0.1670 - val_accuracy: 0.9460\n",
      "Epoch 410/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9595 - val_loss: 0.1627 - val_accuracy: 0.9484\n",
      "Epoch 411/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9554 - val_loss: 0.1659 - val_accuracy: 0.9460\n",
      "Epoch 412/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9530 - val_loss: 0.1671 - val_accuracy: 0.9476\n",
      "Epoch 413/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9531 - val_loss: 0.1656 - val_accuracy: 0.9491\n",
      "Epoch 414/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9551 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 415/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9503 - val_loss: 0.1635 - val_accuracy: 0.9491\n",
      "Epoch 416/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9455 - val_loss: 0.1637 - val_accuracy: 0.9499\n",
      "Epoch 417/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9469 - val_loss: 0.1579 - val_accuracy: 0.9507\n",
      "Epoch 418/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9602 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 419/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9511 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 420/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9493 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 421/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9520 - val_loss: 0.1601 - val_accuracy: 0.9507\n",
      "Epoch 422/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1370 - accuracy: 0.9553 - val_loss: 0.1544 - val_accuracy: 0.9499\n",
      "Epoch 423/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9526 - val_loss: 0.1557 - val_accuracy: 0.9476\n",
      "Epoch 424/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9500 - val_loss: 0.1579 - val_accuracy: 0.9491\n",
      "Epoch 425/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9529 - val_loss: 0.1621 - val_accuracy: 0.9499\n",
      "Epoch 426/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9542 - val_loss: 0.1580 - val_accuracy: 0.9515\n",
      "Epoch 427/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9489 - val_loss: 0.1535 - val_accuracy: 0.9515\n",
      "Epoch 428/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9504 - val_loss: 0.1571 - val_accuracy: 0.9507\n",
      "Epoch 429/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9568 - val_loss: 0.1586 - val_accuracy: 0.9491\n",
      "Epoch 430/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9466 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 431/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9520 - val_loss: 0.1626 - val_accuracy: 0.9507\n",
      "Epoch 432/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9523 - val_loss: 0.1548 - val_accuracy: 0.9476\n",
      "Epoch 433/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9525 - val_loss: 0.1600 - val_accuracy: 0.9484\n",
      "Epoch 434/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9587 - val_loss: 0.1625 - val_accuracy: 0.9468\n",
      "Epoch 435/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9533 - val_loss: 0.1593 - val_accuracy: 0.9499\n",
      "Epoch 436/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9550 - val_loss: 0.1644 - val_accuracy: 0.9499\n",
      "Epoch 437/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9558 - val_loss: 0.1590 - val_accuracy: 0.9484\n",
      "Epoch 438/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9540 - val_loss: 0.1602 - val_accuracy: 0.9491\n",
      "Epoch 439/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9515 - val_loss: 0.1577 - val_accuracy: 0.9484\n",
      "Epoch 440/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.9535 - val_loss: 0.1694 - val_accuracy: 0.9484\n",
      "Epoch 441/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1555 - accuracy: 0.9468 - val_loss: 0.1676 - val_accuracy: 0.9515\n",
      "Epoch 442/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9530 - val_loss: 0.1646 - val_accuracy: 0.9484\n",
      "Epoch 443/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9539 - val_loss: 0.1654 - val_accuracy: 0.9484\n",
      "Epoch 444/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9569 - val_loss: 0.1550 - val_accuracy: 0.9507\n",
      "Epoch 445/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9498 - val_loss: 0.1565 - val_accuracy: 0.9491\n",
      "Epoch 446/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9540 - val_loss: 0.1592 - val_accuracy: 0.9491\n",
      "Epoch 447/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9589 - val_loss: 0.1604 - val_accuracy: 0.9499\n",
      "Epoch 448/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9556 - val_loss: 0.1682 - val_accuracy: 0.9444\n",
      "Epoch 449/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9574 - val_loss: 0.1621 - val_accuracy: 0.9499\n",
      "Epoch 450/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9543 - val_loss: 0.1651 - val_accuracy: 0.9484\n",
      "Epoch 451/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9539 - val_loss: 0.1597 - val_accuracy: 0.9499\n",
      "Epoch 452/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9591 - val_loss: 0.1645 - val_accuracy: 0.9491\n",
      "Epoch 453/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9522 - val_loss: 0.1650 - val_accuracy: 0.9491\n",
      "Epoch 454/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9542 - val_loss: 0.1630 - val_accuracy: 0.9476\n",
      "Epoch 455/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9508 - val_loss: 0.1611 - val_accuracy: 0.9491\n",
      "Epoch 456/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9466 - val_loss: 0.1584 - val_accuracy: 0.9499\n",
      "Epoch 457/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9477 - val_loss: 0.1664 - val_accuracy: 0.9476\n",
      "Epoch 458/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9540 - val_loss: 0.1727 - val_accuracy: 0.9499\n",
      "Epoch 459/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9536 - val_loss: 0.1688 - val_accuracy: 0.9491\n",
      "Epoch 460/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9515 - val_loss: 0.1590 - val_accuracy: 0.9507\n",
      "Epoch 461/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9536 - val_loss: 0.1589 - val_accuracy: 0.9507\n",
      "Epoch 462/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9563 - val_loss: 0.1623 - val_accuracy: 0.9491\n",
      "Epoch 463/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9566 - val_loss: 0.1633 - val_accuracy: 0.9476\n",
      "Epoch 464/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9519 - val_loss: 0.1716 - val_accuracy: 0.9515\n",
      "Epoch 465/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9495 - val_loss: 0.1690 - val_accuracy: 0.9491\n",
      "Epoch 466/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9498 - val_loss: 0.1755 - val_accuracy: 0.9499\n",
      "Epoch 467/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9533 - val_loss: 0.1597 - val_accuracy: 0.9499\n",
      "Epoch 468/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9510 - val_loss: 0.1596 - val_accuracy: 0.9507\n",
      "Epoch 469/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9491 - val_loss: 0.1594 - val_accuracy: 0.9499\n",
      "Epoch 470/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9480 - val_loss: 0.1608 - val_accuracy: 0.9484\n",
      "Epoch 471/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9520 - val_loss: 0.1640 - val_accuracy: 0.9484\n",
      "Epoch 472/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9522 - val_loss: 0.1589 - val_accuracy: 0.9491\n",
      "Epoch 473/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9525 - val_loss: 0.1586 - val_accuracy: 0.9515\n",
      "Epoch 474/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9531 - val_loss: 0.1604 - val_accuracy: 0.9499\n",
      "Epoch 475/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9474 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 476/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9547 - val_loss: 0.1588 - val_accuracy: 0.9484\n",
      "Epoch 477/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9552 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 478/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9482 - val_loss: 0.1604 - val_accuracy: 0.9515\n",
      "Epoch 479/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9569 - val_loss: 0.1634 - val_accuracy: 0.9499\n",
      "Epoch 480/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9519 - val_loss: 0.1575 - val_accuracy: 0.9484\n",
      "Epoch 481/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9511 - val_loss: 0.1594 - val_accuracy: 0.9507\n",
      "Epoch 482/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9525 - val_loss: 0.1655 - val_accuracy: 0.9515\n",
      "Epoch 483/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9517 - val_loss: 0.1614 - val_accuracy: 0.9507\n",
      "Epoch 484/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9515 - val_loss: 0.1580 - val_accuracy: 0.9491\n",
      "Epoch 485/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9532 - val_loss: 0.1594 - val_accuracy: 0.9491\n",
      "Epoch 486/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9547 - val_loss: 0.1667 - val_accuracy: 0.9460\n",
      "Epoch 487/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9538 - val_loss: 0.1689 - val_accuracy: 0.9452\n",
      "Epoch 488/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9573 - val_loss: 0.1570 - val_accuracy: 0.9507\n",
      "Epoch 489/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9493 - val_loss: 0.1623 - val_accuracy: 0.9515\n",
      "Epoch 490/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9534 - val_loss: 0.1599 - val_accuracy: 0.9507\n",
      "Epoch 491/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9561 - val_loss: 0.1581 - val_accuracy: 0.9476\n",
      "Epoch 492/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9537 - val_loss: 0.1630 - val_accuracy: 0.9452\n",
      "Epoch 493/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9515 - val_loss: 0.1628 - val_accuracy: 0.9484\n",
      "Epoch 494/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9535 - val_loss: 0.1629 - val_accuracy: 0.9491\n",
      "Epoch 495/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9537 - val_loss: 0.1672 - val_accuracy: 0.9460\n",
      "Epoch 496/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9553 - val_loss: 0.1567 - val_accuracy: 0.9499\n",
      "Epoch 497/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9484 - val_loss: 0.1654 - val_accuracy: 0.9491\n",
      "Epoch 498/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9470 - val_loss: 0.1613 - val_accuracy: 0.9484\n",
      "Epoch 499/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9511 - val_loss: 0.1640 - val_accuracy: 0.9484\n",
      "Epoch 500/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9480 - val_loss: 0.1526 - val_accuracy: 0.9507\n",
      "Epoch 501/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.1606 - val_accuracy: 0.9491\n",
      "Epoch 502/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9531 - val_loss: 0.1626 - val_accuracy: 0.9484\n",
      "Epoch 503/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9525 - val_loss: 0.1601 - val_accuracy: 0.9499\n",
      "Epoch 504/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9585 - val_loss: 0.1655 - val_accuracy: 0.9491\n",
      "Epoch 505/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9530 - val_loss: 0.1641 - val_accuracy: 0.9460\n",
      "Epoch 506/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9527 - val_loss: 0.1588 - val_accuracy: 0.9499\n",
      "Epoch 507/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9478 - val_loss: 0.1598 - val_accuracy: 0.9484\n",
      "Epoch 508/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9561 - val_loss: 0.1552 - val_accuracy: 0.9507\n",
      "Epoch 509/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9508 - val_loss: 0.1614 - val_accuracy: 0.9476\n",
      "Epoch 510/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9557 - val_loss: 0.1540 - val_accuracy: 0.9499\n",
      "Epoch 511/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9556 - val_loss: 0.1707 - val_accuracy: 0.9476\n",
      "Epoch 512/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9548 - val_loss: 0.1749 - val_accuracy: 0.9429\n",
      "Epoch 513/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9512 - val_loss: 0.1674 - val_accuracy: 0.9484\n",
      "Epoch 514/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9550 - val_loss: 0.1698 - val_accuracy: 0.9468\n",
      "Epoch 515/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9568 - val_loss: 0.1828 - val_accuracy: 0.9484\n",
      "Epoch 516/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9514 - val_loss: 0.1745 - val_accuracy: 0.9452\n",
      "Epoch 517/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9556 - val_loss: 0.1659 - val_accuracy: 0.9468\n",
      "Epoch 518/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9568 - val_loss: 0.1626 - val_accuracy: 0.9484\n",
      "Epoch 519/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9548 - val_loss: 0.1623 - val_accuracy: 0.9484\n",
      "Epoch 520/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9524 - val_loss: 0.1624 - val_accuracy: 0.9507\n",
      "Epoch 521/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9554 - val_loss: 0.1767 - val_accuracy: 0.9484\n",
      "Epoch 522/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9505 - val_loss: 0.1645 - val_accuracy: 0.9476\n",
      "Epoch 523/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9539 - val_loss: 0.1639 - val_accuracy: 0.9476\n",
      "Epoch 524/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9584 - val_loss: 0.1669 - val_accuracy: 0.9476\n",
      "Epoch 525/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.9435 - val_loss: 0.1619 - val_accuracy: 0.9491\n",
      "Epoch 526/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9519 - val_loss: 0.1614 - val_accuracy: 0.9476\n",
      "Epoch 527/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9524 - val_loss: 0.1650 - val_accuracy: 0.9491\n",
      "Epoch 528/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9542 - val_loss: 0.1620 - val_accuracy: 0.9476\n",
      "Epoch 529/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9573 - val_loss: 0.1621 - val_accuracy: 0.9484\n",
      "Epoch 530/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9562 - val_loss: 0.1758 - val_accuracy: 0.9460\n",
      "Epoch 531/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9586 - val_loss: 0.1587 - val_accuracy: 0.9491\n",
      "Epoch 532/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9549 - val_loss: 0.1634 - val_accuracy: 0.9476\n",
      "Epoch 533/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9541 - val_loss: 0.1637 - val_accuracy: 0.9452\n",
      "Epoch 534/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9534 - val_loss: 0.1724 - val_accuracy: 0.9476\n",
      "Epoch 535/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9504 - val_loss: 0.1578 - val_accuracy: 0.9499\n",
      "Epoch 536/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9524 - val_loss: 0.1689 - val_accuracy: 0.9484\n",
      "Epoch 537/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9556 - val_loss: 0.1750 - val_accuracy: 0.9468\n",
      "Epoch 538/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9529 - val_loss: 0.1707 - val_accuracy: 0.9491\n",
      "Epoch 539/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9551 - val_loss: 0.1666 - val_accuracy: 0.9491\n",
      "Epoch 540/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9491 - val_loss: 0.1662 - val_accuracy: 0.9484\n",
      "Epoch 541/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9583 - val_loss: 0.1644 - val_accuracy: 0.9484\n",
      "Epoch 542/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9520 - val_loss: 0.1633 - val_accuracy: 0.9468\n",
      "Epoch 543/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9525 - val_loss: 0.1772 - val_accuracy: 0.9491\n",
      "Epoch 544/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9544 - val_loss: 0.1631 - val_accuracy: 0.9499\n",
      "Epoch 545/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9598 - val_loss: 0.1622 - val_accuracy: 0.9476\n",
      "Epoch 546/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9555 - val_loss: 0.1695 - val_accuracy: 0.9468\n",
      "Epoch 547/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9558 - val_loss: 0.1911 - val_accuracy: 0.9429\n",
      "Epoch 548/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9499 - val_loss: 0.1591 - val_accuracy: 0.9484\n",
      "Epoch 549/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9523 - val_loss: 0.1674 - val_accuracy: 0.9476\n",
      "Epoch 550/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9478 - val_loss: 0.1672 - val_accuracy: 0.9491\n",
      "Epoch 551/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9547 - val_loss: 0.1699 - val_accuracy: 0.9460\n",
      "Epoch 552/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9530 - val_loss: 0.1656 - val_accuracy: 0.9476\n",
      "Epoch 553/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9511 - val_loss: 0.1636 - val_accuracy: 0.9484\n",
      "Epoch 554/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9567 - val_loss: 0.1641 - val_accuracy: 0.9484\n",
      "Epoch 555/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9520 - val_loss: 0.1663 - val_accuracy: 0.9499\n",
      "Epoch 556/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9556 - val_loss: 0.1701 - val_accuracy: 0.9484\n",
      "Epoch 557/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9540 - val_loss: 0.1695 - val_accuracy: 0.9499\n",
      "Epoch 558/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9593 - val_loss: 0.1645 - val_accuracy: 0.9499\n",
      "Epoch 559/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9531 - val_loss: 0.1647 - val_accuracy: 0.9476\n",
      "Epoch 560/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9520 - val_loss: 0.1783 - val_accuracy: 0.9452\n",
      "Epoch 561/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9541 - val_loss: 0.1691 - val_accuracy: 0.9468\n",
      "Epoch 562/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9510 - val_loss: 0.1802 - val_accuracy: 0.9452\n",
      "Epoch 563/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9539 - val_loss: 0.1852 - val_accuracy: 0.9444\n",
      "Epoch 564/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9504 - val_loss: 0.1700 - val_accuracy: 0.9484\n",
      "Epoch 565/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9575 - val_loss: 0.1776 - val_accuracy: 0.9460\n",
      "Epoch 566/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9582 - val_loss: 0.1599 - val_accuracy: 0.9499\n",
      "Epoch 567/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9500 - val_loss: 0.1594 - val_accuracy: 0.9484\n",
      "Epoch 568/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9556 - val_loss: 0.1793 - val_accuracy: 0.9499\n",
      "Epoch 569/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9551 - val_loss: 0.1784 - val_accuracy: 0.9444\n",
      "Epoch 570/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9618 - val_loss: 0.1665 - val_accuracy: 0.9491\n",
      "Epoch 571/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9571 - val_loss: 0.1734 - val_accuracy: 0.9468\n",
      "Epoch 572/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9503 - val_loss: 0.1854 - val_accuracy: 0.9476\n",
      "Epoch 573/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9529 - val_loss: 0.1767 - val_accuracy: 0.9476\n",
      "Epoch 574/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9500 - val_loss: 0.1762 - val_accuracy: 0.9491\n",
      "Epoch 575/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9588 - val_loss: 0.1748 - val_accuracy: 0.9476\n",
      "Epoch 576/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9553 - val_loss: 0.1692 - val_accuracy: 0.9484\n",
      "Epoch 577/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9558 - val_loss: 0.1705 - val_accuracy: 0.9484\n",
      "Epoch 578/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9478 - val_loss: 0.1728 - val_accuracy: 0.9484\n",
      "Epoch 579/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9561 - val_loss: 0.1619 - val_accuracy: 0.9484\n",
      "Epoch 580/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9479 - val_loss: 0.1738 - val_accuracy: 0.9484\n",
      "Epoch 581/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9545 - val_loss: 0.1659 - val_accuracy: 0.9491\n",
      "Epoch 582/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9535 - val_loss: 0.1765 - val_accuracy: 0.9460\n",
      "Epoch 583/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9562 - val_loss: 0.1688 - val_accuracy: 0.9499\n",
      "Epoch 584/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9516 - val_loss: 0.1780 - val_accuracy: 0.9491\n",
      "Epoch 585/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9586 - val_loss: 0.1722 - val_accuracy: 0.9476\n",
      "Epoch 586/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9539 - val_loss: 0.1767 - val_accuracy: 0.9491\n",
      "Epoch 587/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9568 - val_loss: 0.1668 - val_accuracy: 0.9460\n",
      "Epoch 588/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9454 - val_loss: 0.1798 - val_accuracy: 0.9484\n",
      "Epoch 589/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9555 - val_loss: 0.1805 - val_accuracy: 0.9460\n",
      "Epoch 590/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9532 - val_loss: 0.1733 - val_accuracy: 0.9452\n",
      "Epoch 591/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9517 - val_loss: 0.1713 - val_accuracy: 0.9484\n",
      "Epoch 592/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9588 - val_loss: 0.1764 - val_accuracy: 0.9468\n",
      "Epoch 593/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9512 - val_loss: 0.1699 - val_accuracy: 0.9476\n",
      "Epoch 594/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9559 - val_loss: 0.1738 - val_accuracy: 0.9491\n",
      "Epoch 595/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9548 - val_loss: 0.1745 - val_accuracy: 0.9468\n",
      "Epoch 596/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9564 - val_loss: 0.1701 - val_accuracy: 0.9499\n",
      "Epoch 597/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9538 - val_loss: 0.1691 - val_accuracy: 0.9476\n",
      "Epoch 598/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9540 - val_loss: 0.2120 - val_accuracy: 0.9397\n",
      "Epoch 599/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9539 - val_loss: 0.1715 - val_accuracy: 0.9499\n",
      "Epoch 600/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9504 - val_loss: 0.1849 - val_accuracy: 0.9444\n",
      "Epoch 601/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9582 - val_loss: 0.1697 - val_accuracy: 0.9499\n",
      "Epoch 602/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9568 - val_loss: 0.1764 - val_accuracy: 0.9484\n",
      "Epoch 603/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9518 - val_loss: 0.1883 - val_accuracy: 0.9468\n",
      "Epoch 604/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9538 - val_loss: 0.1827 - val_accuracy: 0.9468\n",
      "Epoch 605/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9489 - val_loss: 0.1856 - val_accuracy: 0.9468\n",
      "Epoch 606/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9529 - val_loss: 0.1702 - val_accuracy: 0.9507\n",
      "Epoch 607/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9510 - val_loss: 0.1604 - val_accuracy: 0.9491\n",
      "Epoch 608/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9550 - val_loss: 0.1747 - val_accuracy: 0.9476\n",
      "Epoch 609/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9614 - val_loss: 0.1896 - val_accuracy: 0.9452\n",
      "Epoch 610/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9552 - val_loss: 0.1883 - val_accuracy: 0.9421\n",
      "Epoch 611/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9608 - val_loss: 0.1802 - val_accuracy: 0.9484\n",
      "Epoch 612/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9588 - val_loss: 0.1803 - val_accuracy: 0.9468\n",
      "Epoch 613/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9593 - val_loss: 0.1766 - val_accuracy: 0.9476\n",
      "Epoch 614/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9580 - val_loss: 0.1697 - val_accuracy: 0.9476\n",
      "Epoch 615/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9547 - val_loss: 0.1740 - val_accuracy: 0.9468\n",
      "Epoch 616/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9538 - val_loss: 0.1757 - val_accuracy: 0.9468\n",
      "Epoch 617/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9485 - val_loss: 0.1754 - val_accuracy: 0.9484\n",
      "Epoch 618/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9526 - val_loss: 0.1853 - val_accuracy: 0.9452\n",
      "Epoch 619/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9531 - val_loss: 0.1722 - val_accuracy: 0.9452\n",
      "Epoch 620/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9488 - val_loss: 0.1752 - val_accuracy: 0.9491\n",
      "Epoch 621/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9470 - val_loss: 0.1920 - val_accuracy: 0.9452\n",
      "Epoch 622/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9575 - val_loss: 0.1777 - val_accuracy: 0.9476\n",
      "Epoch 623/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9550 - val_loss: 0.1784 - val_accuracy: 0.9444\n",
      "Epoch 624/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9515 - val_loss: 0.1780 - val_accuracy: 0.9476\n",
      "Epoch 625/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9582 - val_loss: 0.1884 - val_accuracy: 0.9452\n",
      "Epoch 626/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9530 - val_loss: 0.1774 - val_accuracy: 0.9484\n",
      "Epoch 627/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9603 - val_loss: 0.1829 - val_accuracy: 0.9476\n",
      "Epoch 628/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9554 - val_loss: 0.1905 - val_accuracy: 0.9460\n",
      "Epoch 629/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9575 - val_loss: 0.1773 - val_accuracy: 0.9476\n",
      "Epoch 630/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9526 - val_loss: 0.1914 - val_accuracy: 0.9405\n",
      "Epoch 631/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9507 - val_loss: 0.1683 - val_accuracy: 0.9484\n",
      "Epoch 632/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9512 - val_loss: 0.1708 - val_accuracy: 0.9484\n",
      "Epoch 633/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9508 - val_loss: 0.1768 - val_accuracy: 0.9437\n",
      "Epoch 634/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9585 - val_loss: 0.2000 - val_accuracy: 0.9444\n",
      "Epoch 635/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9565 - val_loss: 0.1692 - val_accuracy: 0.9468\n",
      "Epoch 636/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9623 - val_loss: 0.1804 - val_accuracy: 0.9460\n",
      "Epoch 637/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9548 - val_loss: 0.1884 - val_accuracy: 0.9327\n",
      "Epoch 638/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9557 - val_loss: 0.1777 - val_accuracy: 0.9460\n",
      "Epoch 639/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9523 - val_loss: 0.1768 - val_accuracy: 0.9476\n",
      "Epoch 640/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9526 - val_loss: 0.1623 - val_accuracy: 0.9484\n",
      "Epoch 641/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9570 - val_loss: 0.1676 - val_accuracy: 0.9468\n",
      "Epoch 642/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9534 - val_loss: 0.1775 - val_accuracy: 0.9468\n",
      "Epoch 643/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9538 - val_loss: 0.1601 - val_accuracy: 0.9468\n",
      "Epoch 644/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9486 - val_loss: 0.1647 - val_accuracy: 0.9484\n",
      "Epoch 645/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9470 - val_loss: 0.1628 - val_accuracy: 0.9491\n",
      "Epoch 646/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9601 - val_loss: 0.1611 - val_accuracy: 0.9476\n",
      "Epoch 647/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9559 - val_loss: 0.1618 - val_accuracy: 0.9484\n",
      "Epoch 648/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9599 - val_loss: 0.1618 - val_accuracy: 0.9484\n",
      "Epoch 649/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1743 - val_accuracy: 0.9444\n",
      "Epoch 650/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9544 - val_loss: 0.1666 - val_accuracy: 0.9468\n",
      "Epoch 651/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9561 - val_loss: 0.1566 - val_accuracy: 0.9468\n",
      "Epoch 652/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9515 - val_loss: 0.1604 - val_accuracy: 0.9491\n",
      "Epoch 653/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9494 - val_loss: 0.1662 - val_accuracy: 0.9468\n",
      "Epoch 654/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9536 - val_loss: 0.1563 - val_accuracy: 0.9491\n",
      "Epoch 655/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9502 - val_loss: 0.1626 - val_accuracy: 0.9484\n",
      "Epoch 656/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9553 - val_loss: 0.1647 - val_accuracy: 0.9468\n",
      "Epoch 657/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9565 - val_loss: 0.1569 - val_accuracy: 0.9484\n",
      "Epoch 658/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1370 - accuracy: 0.9570 - val_loss: 0.1531 - val_accuracy: 0.9515\n",
      "Epoch 659/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9543 - val_loss: 0.1564 - val_accuracy: 0.9468\n",
      "Epoch 660/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9523 - val_loss: 0.1631 - val_accuracy: 0.9468\n",
      "Epoch 661/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9577 - val_loss: 0.1619 - val_accuracy: 0.9476\n",
      "Epoch 662/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9539 - val_loss: 0.1668 - val_accuracy: 0.9460\n",
      "Epoch 663/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9509 - val_loss: 0.1683 - val_accuracy: 0.9484\n",
      "Epoch 664/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9521 - val_loss: 0.1681 - val_accuracy: 0.9499\n",
      "Epoch 665/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9524 - val_loss: 0.1648 - val_accuracy: 0.9484\n",
      "Epoch 666/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9526 - val_loss: 0.1706 - val_accuracy: 0.9468\n",
      "Epoch 667/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1712 - val_accuracy: 0.9507\n",
      "Epoch 668/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9600 - val_loss: 0.1723 - val_accuracy: 0.9476\n",
      "Epoch 669/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9520 - val_loss: 0.2001 - val_accuracy: 0.9468\n",
      "Epoch 670/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9536 - val_loss: 0.1582 - val_accuracy: 0.9499\n",
      "Epoch 671/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9513 - val_loss: 0.1591 - val_accuracy: 0.9499\n",
      "Epoch 672/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9553 - val_loss: 0.1577 - val_accuracy: 0.9499\n",
      "Epoch 673/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9539 - val_loss: 0.1681 - val_accuracy: 0.9499\n",
      "Epoch 674/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9472 - val_loss: 0.1709 - val_accuracy: 0.9507\n",
      "Epoch 675/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9524 - val_loss: 0.1658 - val_accuracy: 0.9484\n",
      "Epoch 676/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9550 - val_loss: 0.1670 - val_accuracy: 0.9484\n",
      "Epoch 677/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1422 - accuracy: 0.9556 - val_loss: 0.1789 - val_accuracy: 0.9468\n",
      "Epoch 678/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9530 - val_loss: 0.1622 - val_accuracy: 0.9499\n",
      "Epoch 679/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9571 - val_loss: 0.1656 - val_accuracy: 0.9491\n",
      "Epoch 680/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9554 - val_loss: 0.1641 - val_accuracy: 0.9499\n",
      "Epoch 681/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9528 - val_loss: 0.1603 - val_accuracy: 0.9491\n",
      "Epoch 682/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9537 - val_loss: 0.1560 - val_accuracy: 0.9507\n",
      "Epoch 683/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9546 - val_loss: 0.1599 - val_accuracy: 0.9499\n",
      "Epoch 684/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9542 - val_loss: 0.1576 - val_accuracy: 0.9491\n",
      "Epoch 685/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9549 - val_loss: 0.1689 - val_accuracy: 0.9491\n",
      "Epoch 686/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9528 - val_loss: 0.1576 - val_accuracy: 0.9491\n",
      "Epoch 687/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9523 - val_loss: 0.1641 - val_accuracy: 0.9491\n",
      "Epoch 688/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9514 - val_loss: 0.1563 - val_accuracy: 0.9499\n",
      "Epoch 689/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1606 - val_accuracy: 0.9499\n",
      "Epoch 690/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9523 - val_loss: 0.1683 - val_accuracy: 0.9491\n",
      "Epoch 691/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9521 - val_loss: 0.1754 - val_accuracy: 0.9484\n",
      "Epoch 692/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.9564 - val_loss: 0.1722 - val_accuracy: 0.9491\n",
      "Epoch 693/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9523 - val_loss: 0.1659 - val_accuracy: 0.9499\n",
      "Epoch 694/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9508 - val_loss: 0.1601 - val_accuracy: 0.9491\n",
      "Epoch 695/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9639 - val_loss: 0.1573 - val_accuracy: 0.9491\n",
      "Epoch 696/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9583 - val_loss: 0.1631 - val_accuracy: 0.9484\n",
      "Epoch 697/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9573 - val_loss: 0.1697 - val_accuracy: 0.9468\n",
      "Epoch 698/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9564 - val_loss: 0.1718 - val_accuracy: 0.9484\n",
      "Epoch 699/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9506 - val_loss: 0.1659 - val_accuracy: 0.9507\n",
      "Epoch 700/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9522 - val_loss: 0.1802 - val_accuracy: 0.9429\n",
      "Epoch 701/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9521 - val_loss: 0.1601 - val_accuracy: 0.9484\n",
      "Epoch 702/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9503 - val_loss: 0.1596 - val_accuracy: 0.9507\n",
      "Epoch 703/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9535 - val_loss: 0.1626 - val_accuracy: 0.9515\n",
      "Epoch 704/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9576 - val_loss: 0.1613 - val_accuracy: 0.9499\n",
      "Epoch 705/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9517 - val_loss: 0.1826 - val_accuracy: 0.9460\n",
      "Epoch 706/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9547 - val_loss: 0.1609 - val_accuracy: 0.9491\n",
      "Epoch 707/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9569 - val_loss: 0.1640 - val_accuracy: 0.9515\n",
      "Epoch 708/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9558 - val_loss: 0.1688 - val_accuracy: 0.9484\n",
      "Epoch 709/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9530 - val_loss: 0.1801 - val_accuracy: 0.9499\n",
      "Epoch 710/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9521 - val_loss: 0.1662 - val_accuracy: 0.9484\n",
      "Epoch 711/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9534 - val_loss: 0.1632 - val_accuracy: 0.9476\n",
      "Epoch 712/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9541 - val_loss: 0.1685 - val_accuracy: 0.9507\n",
      "Epoch 713/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9571 - val_loss: 0.1838 - val_accuracy: 0.9476\n",
      "Epoch 714/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9607 - val_loss: 0.1673 - val_accuracy: 0.9491\n",
      "Epoch 715/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9603 - val_loss: 0.1695 - val_accuracy: 0.9460\n",
      "Epoch 716/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9563 - val_loss: 0.1795 - val_accuracy: 0.9499\n",
      "Epoch 717/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9481 - val_loss: 0.1842 - val_accuracy: 0.9468\n",
      "Epoch 718/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.9573 - val_loss: 0.2077 - val_accuracy: 0.9499\n",
      "Epoch 719/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9541 - val_loss: 0.1728 - val_accuracy: 0.9452\n",
      "Epoch 720/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9527 - val_loss: 0.1695 - val_accuracy: 0.9484\n",
      "Epoch 721/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9544 - val_loss: 0.1674 - val_accuracy: 0.9484\n",
      "Epoch 722/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9519 - val_loss: 0.1686 - val_accuracy: 0.9476\n",
      "Epoch 723/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.9555 - val_loss: 0.1723 - val_accuracy: 0.9507\n",
      "Epoch 724/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9593 - val_loss: 0.1665 - val_accuracy: 0.9507\n",
      "Epoch 725/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9526 - val_loss: 0.1683 - val_accuracy: 0.9499\n",
      "Epoch 726/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9583 - val_loss: 0.1853 - val_accuracy: 0.9507\n",
      "Epoch 727/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9553 - val_loss: 0.1733 - val_accuracy: 0.9484\n",
      "Epoch 728/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9567 - val_loss: 0.1847 - val_accuracy: 0.9491\n",
      "Epoch 729/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9490 - val_loss: 0.1667 - val_accuracy: 0.9515\n",
      "Epoch 730/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9597 - val_loss: 0.1704 - val_accuracy: 0.9491\n",
      "Epoch 731/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9507 - val_loss: 0.1723 - val_accuracy: 0.9491\n",
      "Epoch 732/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9512 - val_loss: 0.1644 - val_accuracy: 0.9499\n",
      "Epoch 733/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9534 - val_loss: 0.1586 - val_accuracy: 0.9499\n",
      "Epoch 734/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9524 - val_loss: 0.1649 - val_accuracy: 0.9507\n",
      "Epoch 735/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9494 - val_loss: 0.1692 - val_accuracy: 0.9468\n",
      "Epoch 736/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9481 - val_loss: 0.1652 - val_accuracy: 0.9507\n",
      "Epoch 737/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9548 - val_loss: 0.1658 - val_accuracy: 0.9499\n",
      "Epoch 738/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9475 - val_loss: 0.1666 - val_accuracy: 0.9491\n",
      "Epoch 739/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9542 - val_loss: 0.1715 - val_accuracy: 0.9484\n",
      "Epoch 740/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9540 - val_loss: 0.1624 - val_accuracy: 0.9491\n",
      "Epoch 741/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9498 - val_loss: 0.1704 - val_accuracy: 0.9484\n",
      "Epoch 742/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9544 - val_loss: 0.1687 - val_accuracy: 0.9491\n",
      "Epoch 743/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9599 - val_loss: 0.1686 - val_accuracy: 0.9476\n",
      "Epoch 744/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9486 - val_loss: 0.1661 - val_accuracy: 0.9499\n",
      "Epoch 745/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9471 - val_loss: 0.1655 - val_accuracy: 0.9491\n",
      "Epoch 746/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9518 - val_loss: 0.1733 - val_accuracy: 0.9491\n",
      "Epoch 747/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.9579 - val_loss: 0.1683 - val_accuracy: 0.9499\n",
      "Epoch 748/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9526 - val_loss: 0.1788 - val_accuracy: 0.9499\n",
      "Epoch 749/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9504 - val_loss: 0.1763 - val_accuracy: 0.9499\n",
      "Epoch 750/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9554 - val_loss: 0.1784 - val_accuracy: 0.9484\n",
      "Epoch 751/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9496 - val_loss: 0.1687 - val_accuracy: 0.9491\n",
      "Epoch 752/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9514 - val_loss: 0.1758 - val_accuracy: 0.9507\n",
      "Epoch 753/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1424 - accuracy: 0.9546 - val_loss: 0.1726 - val_accuracy: 0.9452\n",
      "Epoch 754/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9525 - val_loss: 0.1776 - val_accuracy: 0.9484\n",
      "Epoch 755/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9540 - val_loss: 0.1672 - val_accuracy: 0.9507\n",
      "Epoch 756/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9553 - val_loss: 0.1769 - val_accuracy: 0.9499\n",
      "Epoch 757/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9577 - val_loss: 0.1697 - val_accuracy: 0.9491\n",
      "Epoch 758/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9598 - val_loss: 0.1735 - val_accuracy: 0.9507\n",
      "Epoch 759/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9577 - val_loss: 0.1683 - val_accuracy: 0.9491\n",
      "Epoch 760/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9518 - val_loss: 0.1765 - val_accuracy: 0.9491\n",
      "Epoch 761/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9474 - val_loss: 0.1784 - val_accuracy: 0.9484\n",
      "Epoch 762/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9483 - val_loss: 0.1822 - val_accuracy: 0.9452\n",
      "Epoch 763/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9516 - val_loss: 0.1859 - val_accuracy: 0.9452\n",
      "Epoch 764/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9530 - val_loss: 0.1813 - val_accuracy: 0.9491\n",
      "Epoch 765/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9555 - val_loss: 0.1817 - val_accuracy: 0.9452\n",
      "Epoch 766/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9536 - val_loss: 0.1983 - val_accuracy: 0.9491\n",
      "Epoch 767/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9520 - val_loss: 0.1940 - val_accuracy: 0.9476\n",
      "Epoch 768/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9548 - val_loss: 0.1887 - val_accuracy: 0.9476\n",
      "Epoch 769/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9554 - val_loss: 0.1744 - val_accuracy: 0.9484\n",
      "Epoch 770/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9536 - val_loss: 0.1825 - val_accuracy: 0.9484\n",
      "Epoch 771/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9522 - val_loss: 0.1878 - val_accuracy: 0.9484\n",
      "Epoch 772/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9566 - val_loss: 0.2064 - val_accuracy: 0.9468\n",
      "Epoch 773/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9481 - val_loss: 0.1698 - val_accuracy: 0.9491\n",
      "Epoch 774/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9585 - val_loss: 0.1709 - val_accuracy: 0.9476\n",
      "Epoch 775/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9607 - val_loss: 0.1861 - val_accuracy: 0.9468\n",
      "Epoch 776/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9532 - val_loss: 0.1958 - val_accuracy: 0.9476\n",
      "Epoch 777/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9569 - val_loss: 0.2006 - val_accuracy: 0.9476\n",
      "Epoch 778/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9552 - val_loss: 0.2004 - val_accuracy: 0.9476\n",
      "Epoch 779/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9506 - val_loss: 0.1792 - val_accuracy: 0.9491\n",
      "Epoch 780/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9560 - val_loss: 0.1685 - val_accuracy: 0.9491\n",
      "Epoch 781/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9505 - val_loss: 0.1838 - val_accuracy: 0.9460\n",
      "Epoch 782/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9557 - val_loss: 0.1781 - val_accuracy: 0.9444\n",
      "Epoch 783/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9525 - val_loss: 0.1999 - val_accuracy: 0.9429\n",
      "Epoch 784/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9562 - val_loss: 0.2011 - val_accuracy: 0.9468\n",
      "Epoch 785/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9573 - val_loss: 0.1899 - val_accuracy: 0.9507\n",
      "Epoch 786/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9472 - val_loss: 0.1729 - val_accuracy: 0.9421\n",
      "Epoch 787/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9510 - val_loss: 0.1703 - val_accuracy: 0.9476\n",
      "Epoch 788/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9588 - val_loss: 0.1798 - val_accuracy: 0.9499\n",
      "Epoch 789/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9555 - val_loss: 0.1808 - val_accuracy: 0.9499\n",
      "Epoch 790/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9565 - val_loss: 0.1887 - val_accuracy: 0.9491\n",
      "Epoch 791/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9531 - val_loss: 0.2105 - val_accuracy: 0.9468\n",
      "Epoch 792/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9503 - val_loss: 0.2006 - val_accuracy: 0.9452\n",
      "Epoch 793/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9562 - val_loss: 0.1867 - val_accuracy: 0.9476\n",
      "Epoch 794/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9592 - val_loss: 0.2047 - val_accuracy: 0.9452\n",
      "Epoch 795/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9565 - val_loss: 0.2251 - val_accuracy: 0.9499\n",
      "Epoch 796/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9602 - val_loss: 0.1776 - val_accuracy: 0.9421\n",
      "Epoch 797/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9567 - val_loss: 0.1720 - val_accuracy: 0.9499\n",
      "Epoch 798/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9506 - val_loss: 0.1798 - val_accuracy: 0.9491\n",
      "Epoch 799/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9591 - val_loss: 0.2343 - val_accuracy: 0.9351\n",
      "Epoch 800/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9459 - val_loss: 0.1636 - val_accuracy: 0.9507\n",
      "Epoch 801/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9496 - val_loss: 0.1782 - val_accuracy: 0.9515\n",
      "Epoch 802/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9570 - val_loss: 0.1898 - val_accuracy: 0.9491\n",
      "Epoch 803/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9574 - val_loss: 0.1799 - val_accuracy: 0.9507\n",
      "Epoch 804/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9516 - val_loss: 0.1904 - val_accuracy: 0.9405\n",
      "Epoch 805/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9542 - val_loss: 0.1812 - val_accuracy: 0.9484\n",
      "Epoch 806/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9591 - val_loss: 0.1807 - val_accuracy: 0.9476\n",
      "Epoch 807/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9538 - val_loss: 0.1833 - val_accuracy: 0.9468\n",
      "Epoch 808/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9593 - val_loss: 0.1922 - val_accuracy: 0.9476\n",
      "Epoch 809/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9557 - val_loss: 0.1872 - val_accuracy: 0.9484\n",
      "Epoch 810/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9468 - val_loss: 0.1749 - val_accuracy: 0.9491\n",
      "Epoch 811/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.9578 - val_loss: 0.1727 - val_accuracy: 0.9515\n",
      "Epoch 812/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9537 - val_loss: 0.1811 - val_accuracy: 0.9476\n",
      "Epoch 813/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9543 - val_loss: 0.1920 - val_accuracy: 0.9491\n",
      "Epoch 814/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9571 - val_loss: 0.1904 - val_accuracy: 0.9491\n",
      "Epoch 815/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9559 - val_loss: 0.1794 - val_accuracy: 0.9468\n",
      "Epoch 816/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9598 - val_loss: 0.1932 - val_accuracy: 0.9499\n",
      "Epoch 817/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9539 - val_loss: 0.1758 - val_accuracy: 0.9476\n",
      "Epoch 818/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9576 - val_loss: 0.1707 - val_accuracy: 0.9476\n",
      "Epoch 819/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9538 - val_loss: 0.1791 - val_accuracy: 0.9491\n",
      "Epoch 820/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9525 - val_loss: 0.2224 - val_accuracy: 0.9397\n",
      "Epoch 821/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9556 - val_loss: 0.1695 - val_accuracy: 0.9499\n",
      "Epoch 822/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9512 - val_loss: 0.1780 - val_accuracy: 0.9476\n",
      "Epoch 823/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9559 - val_loss: 0.1993 - val_accuracy: 0.9499\n",
      "Epoch 824/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9485 - val_loss: 0.1721 - val_accuracy: 0.9476\n",
      "Epoch 825/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9541 - val_loss: 0.1703 - val_accuracy: 0.9444\n",
      "Epoch 826/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9562 - val_loss: 0.1757 - val_accuracy: 0.9468\n",
      "Epoch 827/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9499 - val_loss: 0.1885 - val_accuracy: 0.9515\n",
      "Epoch 828/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9564 - val_loss: 0.1666 - val_accuracy: 0.9507\n",
      "Epoch 829/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9500 - val_loss: 0.1732 - val_accuracy: 0.9491\n",
      "Epoch 830/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9625 - val_loss: 0.1874 - val_accuracy: 0.9452\n",
      "Epoch 831/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9568 - val_loss: 0.1885 - val_accuracy: 0.9429\n",
      "Epoch 832/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9597 - val_loss: 0.1789 - val_accuracy: 0.9468\n",
      "Epoch 833/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9588 - val_loss: 0.1924 - val_accuracy: 0.9460\n",
      "Epoch 834/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9590 - val_loss: 0.1988 - val_accuracy: 0.9476\n",
      "Epoch 835/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9590 - val_loss: 0.1925 - val_accuracy: 0.9366\n",
      "Epoch 836/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9551 - val_loss: 0.1792 - val_accuracy: 0.9476\n",
      "Epoch 837/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9535 - val_loss: 0.1836 - val_accuracy: 0.9421\n",
      "Epoch 838/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9536 - val_loss: 0.1703 - val_accuracy: 0.9452\n",
      "Epoch 839/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9519 - val_loss: 0.1770 - val_accuracy: 0.9468\n",
      "Epoch 840/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9538 - val_loss: 0.1853 - val_accuracy: 0.9460\n",
      "Epoch 841/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9551 - val_loss: 0.1707 - val_accuracy: 0.9499\n",
      "Epoch 842/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9538 - val_loss: 0.1892 - val_accuracy: 0.9437\n",
      "Epoch 843/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9542 - val_loss: 0.1934 - val_accuracy: 0.9476\n",
      "Epoch 844/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9525 - val_loss: 0.1921 - val_accuracy: 0.9476\n",
      "Epoch 845/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9557 - val_loss: 0.1729 - val_accuracy: 0.9460\n",
      "Epoch 846/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9573 - val_loss: 0.1988 - val_accuracy: 0.9444\n",
      "Epoch 847/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9599 - val_loss: 0.1772 - val_accuracy: 0.9421\n",
      "Epoch 848/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9568 - val_loss: 0.1698 - val_accuracy: 0.9444\n",
      "Epoch 849/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9484 - val_loss: 0.1568 - val_accuracy: 0.9499\n",
      "Epoch 850/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9526 - val_loss: 0.1618 - val_accuracy: 0.9515\n",
      "Epoch 851/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9562 - val_loss: 0.1639 - val_accuracy: 0.9491\n",
      "Epoch 852/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9544 - val_loss: 0.1647 - val_accuracy: 0.9452\n",
      "Epoch 853/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9610 - val_loss: 0.1652 - val_accuracy: 0.9468\n",
      "Epoch 854/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9548 - val_loss: 0.1655 - val_accuracy: 0.9468\n",
      "Epoch 855/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9574 - val_loss: 0.1980 - val_accuracy: 0.9437\n",
      "Epoch 856/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9546 - val_loss: 0.1645 - val_accuracy: 0.9484\n",
      "Epoch 857/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9606 - val_loss: 0.1744 - val_accuracy: 0.9476\n",
      "Epoch 858/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9532 - val_loss: 0.1670 - val_accuracy: 0.9499\n",
      "Epoch 859/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9518 - val_loss: 0.1739 - val_accuracy: 0.9491\n",
      "Epoch 860/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9569 - val_loss: 0.1665 - val_accuracy: 0.9491\n",
      "Epoch 861/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9595 - val_loss: 0.1767 - val_accuracy: 0.9476\n",
      "Epoch 862/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9590 - val_loss: 0.1811 - val_accuracy: 0.9476\n",
      "Epoch 863/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9579 - val_loss: 0.1950 - val_accuracy: 0.9429\n",
      "Epoch 864/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.9571 - val_loss: 0.1911 - val_accuracy: 0.9484\n",
      "Epoch 865/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9611 - val_loss: 0.1940 - val_accuracy: 0.9476\n",
      "Epoch 866/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9555 - val_loss: 0.1875 - val_accuracy: 0.9437\n",
      "Epoch 867/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9578 - val_loss: 0.1708 - val_accuracy: 0.9484\n",
      "Epoch 868/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9508 - val_loss: 0.1733 - val_accuracy: 0.9491\n",
      "Epoch 869/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9507 - val_loss: 0.1938 - val_accuracy: 0.9452\n",
      "Epoch 870/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9586 - val_loss: 0.1885 - val_accuracy: 0.9468\n",
      "Epoch 871/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9538 - val_loss: 0.1868 - val_accuracy: 0.9460\n",
      "Epoch 872/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9550 - val_loss: 0.2274 - val_accuracy: 0.9452\n",
      "Epoch 873/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9541 - val_loss: 0.1760 - val_accuracy: 0.9468\n",
      "Epoch 874/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9544 - val_loss: 0.1654 - val_accuracy: 0.9452\n",
      "Epoch 875/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9570 - val_loss: 0.1743 - val_accuracy: 0.9468\n",
      "Epoch 876/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9577 - val_loss: 0.1750 - val_accuracy: 0.9484\n",
      "Epoch 877/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9607 - val_loss: 0.1812 - val_accuracy: 0.9468\n",
      "Epoch 878/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9639 - val_loss: 0.2264 - val_accuracy: 0.9515\n",
      "Epoch 879/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9525 - val_loss: 0.1780 - val_accuracy: 0.9484\n",
      "Epoch 880/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9543 - val_loss: 0.1771 - val_accuracy: 0.9484\n",
      "Epoch 881/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9558 - val_loss: 0.1699 - val_accuracy: 0.9484\n",
      "Epoch 882/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9563 - val_loss: 0.1716 - val_accuracy: 0.9468\n",
      "Epoch 883/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9532 - val_loss: 0.1813 - val_accuracy: 0.9460\n",
      "Epoch 884/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9525 - val_loss: 0.1850 - val_accuracy: 0.9444\n",
      "Epoch 885/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9575 - val_loss: 0.1776 - val_accuracy: 0.9460\n",
      "Epoch 886/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9551 - val_loss: 0.1909 - val_accuracy: 0.9484\n",
      "Epoch 887/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9599 - val_loss: 0.1800 - val_accuracy: 0.9460\n",
      "Epoch 888/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9616 - val_loss: 0.2025 - val_accuracy: 0.9421\n",
      "Epoch 889/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9549 - val_loss: 0.2447 - val_accuracy: 0.9429\n",
      "Epoch 890/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9581 - val_loss: 0.1874 - val_accuracy: 0.9452\n",
      "Epoch 891/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9528 - val_loss: 0.1818 - val_accuracy: 0.9452\n",
      "Epoch 892/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9512 - val_loss: 0.1827 - val_accuracy: 0.9491\n",
      "Epoch 893/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9529 - val_loss: 0.1740 - val_accuracy: 0.9460\n",
      "Epoch 894/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9640 - val_loss: 0.1675 - val_accuracy: 0.9476\n",
      "Epoch 895/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9576 - val_loss: 0.1793 - val_accuracy: 0.9476\n",
      "Epoch 896/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9588 - val_loss: 0.1669 - val_accuracy: 0.9468\n",
      "Epoch 897/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9577 - val_loss: 0.1679 - val_accuracy: 0.9476\n",
      "Epoch 898/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9553 - val_loss: 0.1755 - val_accuracy: 0.9484\n",
      "Epoch 899/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9597 - val_loss: 0.1920 - val_accuracy: 0.9413\n",
      "Epoch 900/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9562 - val_loss: 0.1743 - val_accuracy: 0.9499\n",
      "Epoch 901/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9595 - val_loss: 0.1882 - val_accuracy: 0.9484\n",
      "Epoch 902/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9555 - val_loss: 0.1847 - val_accuracy: 0.9468\n",
      "Epoch 903/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9503 - val_loss: 0.1858 - val_accuracy: 0.9491\n",
      "Epoch 904/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9572 - val_loss: 0.2028 - val_accuracy: 0.9460\n",
      "Epoch 905/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9554 - val_loss: 0.1649 - val_accuracy: 0.9507\n",
      "Epoch 906/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9649 - val_loss: 0.1609 - val_accuracy: 0.9499\n",
      "Epoch 907/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9574 - val_loss: 0.1707 - val_accuracy: 0.9491\n",
      "Epoch 908/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9594 - val_loss: 0.1820 - val_accuracy: 0.9476\n",
      "Epoch 909/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1215 - accuracy: 0.9593 - val_loss: 0.1940 - val_accuracy: 0.9468\n",
      "Epoch 910/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9570 - val_loss: 0.1734 - val_accuracy: 0.9444\n",
      "Epoch 911/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9542 - val_loss: 0.1751 - val_accuracy: 0.9484\n",
      "Epoch 912/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9580 - val_loss: 0.1825 - val_accuracy: 0.9476\n",
      "Epoch 913/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9574 - val_loss: 0.1787 - val_accuracy: 0.9484\n",
      "Epoch 914/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9593 - val_loss: 0.1697 - val_accuracy: 0.9452\n",
      "Epoch 915/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9598 - val_loss: 0.1696 - val_accuracy: 0.9484\n",
      "Epoch 916/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9597 - val_loss: 0.1738 - val_accuracy: 0.9452\n",
      "Epoch 917/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9584 - val_loss: 0.1827 - val_accuracy: 0.9460\n",
      "Epoch 918/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1422 - accuracy: 0.9538 - val_loss: 0.1582 - val_accuracy: 0.9476\n",
      "Epoch 919/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.9566 - val_loss: 0.1655 - val_accuracy: 0.9484\n",
      "Epoch 920/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9549 - val_loss: 0.1642 - val_accuracy: 0.9484\n",
      "Epoch 921/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9581 - val_loss: 0.1817 - val_accuracy: 0.9499\n",
      "Epoch 922/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9559 - val_loss: 0.1790 - val_accuracy: 0.9460\n",
      "Epoch 923/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9515 - val_loss: 0.1766 - val_accuracy: 0.9476\n",
      "Epoch 924/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9619 - val_loss: 0.2622 - val_accuracy: 0.9452\n",
      "Epoch 925/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9566 - val_loss: 0.1790 - val_accuracy: 0.9468\n",
      "Epoch 926/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9555 - val_loss: 0.1928 - val_accuracy: 0.9484\n",
      "Epoch 927/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9586 - val_loss: 0.1910 - val_accuracy: 0.9476\n",
      "Epoch 928/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9554 - val_loss: 0.1802 - val_accuracy: 0.9484\n",
      "Epoch 929/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9568 - val_loss: 0.2084 - val_accuracy: 0.9468\n",
      "Epoch 930/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.9565 - val_loss: 0.1852 - val_accuracy: 0.9460\n",
      "Epoch 931/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9523 - val_loss: 0.2072 - val_accuracy: 0.9437\n",
      "Epoch 932/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9557 - val_loss: 0.1834 - val_accuracy: 0.9460\n",
      "Epoch 933/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9594 - val_loss: 0.1912 - val_accuracy: 0.9452\n",
      "Epoch 934/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9526 - val_loss: 0.1836 - val_accuracy: 0.9468\n",
      "Epoch 935/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9558 - val_loss: 0.1711 - val_accuracy: 0.9507\n",
      "Epoch 936/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9526 - val_loss: 0.2202 - val_accuracy: 0.9484\n",
      "Epoch 937/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9605 - val_loss: 0.1901 - val_accuracy: 0.9460\n",
      "Epoch 938/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9585 - val_loss: 0.1916 - val_accuracy: 0.9437\n",
      "Epoch 939/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9528 - val_loss: 0.1983 - val_accuracy: 0.9468\n",
      "Epoch 940/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9580 - val_loss: 0.1892 - val_accuracy: 0.9429\n",
      "Epoch 941/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9580 - val_loss: 0.1846 - val_accuracy: 0.9460\n",
      "Epoch 942/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9530 - val_loss: 0.1901 - val_accuracy: 0.9452\n",
      "Epoch 943/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9559 - val_loss: 0.1747 - val_accuracy: 0.9484\n",
      "Epoch 944/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9531 - val_loss: 0.1814 - val_accuracy: 0.9476\n",
      "Epoch 945/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9592 - val_loss: 0.1963 - val_accuracy: 0.9444\n",
      "Epoch 946/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9582 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
      "Epoch 947/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9591 - val_loss: 0.1841 - val_accuracy: 0.9413\n",
      "Epoch 948/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9584 - val_loss: 0.1886 - val_accuracy: 0.9452\n",
      "Epoch 949/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9577 - val_loss: 0.1804 - val_accuracy: 0.9421\n",
      "Epoch 950/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9584 - val_loss: 0.1739 - val_accuracy: 0.9491\n",
      "Epoch 951/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9571 - val_loss: 0.2083 - val_accuracy: 0.9468\n",
      "Epoch 952/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9576 - val_loss: 0.2298 - val_accuracy: 0.9460\n",
      "Epoch 953/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9601 - val_loss: 0.2047 - val_accuracy: 0.9452\n",
      "Epoch 954/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9523 - val_loss: 0.1671 - val_accuracy: 0.9491\n",
      "Epoch 955/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9537 - val_loss: 0.1810 - val_accuracy: 0.9460\n",
      "Epoch 956/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9484 - val_loss: 0.2009 - val_accuracy: 0.9444\n",
      "Epoch 957/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9535 - val_loss: 0.1971 - val_accuracy: 0.9491\n",
      "Epoch 958/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9565 - val_loss: 0.1751 - val_accuracy: 0.9484\n",
      "Epoch 959/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9566 - val_loss: 0.1781 - val_accuracy: 0.9476\n",
      "Epoch 960/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9595 - val_loss: 0.1777 - val_accuracy: 0.9452\n",
      "Epoch 961/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9552 - val_loss: 0.1774 - val_accuracy: 0.9452\n",
      "Epoch 962/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9594 - val_loss: 0.1776 - val_accuracy: 0.9484\n",
      "Epoch 963/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9573 - val_loss: 0.1783 - val_accuracy: 0.9437\n",
      "Epoch 964/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9623 - val_loss: 0.1837 - val_accuracy: 0.9468\n",
      "Epoch 965/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9612 - val_loss: 0.2083 - val_accuracy: 0.9421\n",
      "Epoch 966/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9607 - val_loss: 0.1703 - val_accuracy: 0.9452\n",
      "Epoch 967/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9578 - val_loss: 0.1802 - val_accuracy: 0.9484\n",
      "Epoch 968/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9523 - val_loss: 0.1973 - val_accuracy: 0.9452\n",
      "Epoch 969/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9559 - val_loss: 0.1930 - val_accuracy: 0.9476\n",
      "Epoch 970/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9554 - val_loss: 0.2040 - val_accuracy: 0.9491\n",
      "Epoch 971/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9543 - val_loss: 0.1899 - val_accuracy: 0.9499\n",
      "Epoch 972/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9533 - val_loss: 0.2042 - val_accuracy: 0.9437\n",
      "Epoch 973/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9569 - val_loss: 0.1884 - val_accuracy: 0.9452\n",
      "Epoch 974/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9621 - val_loss: 0.2037 - val_accuracy: 0.9452\n",
      "Epoch 975/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9577 - val_loss: 0.1781 - val_accuracy: 0.9452\n",
      "Epoch 976/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9606 - val_loss: 0.1721 - val_accuracy: 0.9452\n",
      "Epoch 977/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9589 - val_loss: 0.1774 - val_accuracy: 0.9437\n",
      "Epoch 978/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9508 - val_loss: 0.1826 - val_accuracy: 0.9476\n",
      "Epoch 979/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9594 - val_loss: 0.1870 - val_accuracy: 0.9468\n",
      "Epoch 980/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9519 - val_loss: 0.2067 - val_accuracy: 0.9460\n",
      "Epoch 981/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9526 - val_loss: 0.1752 - val_accuracy: 0.9484\n",
      "Epoch 982/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9550 - val_loss: 0.1667 - val_accuracy: 0.9468\n",
      "Epoch 983/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9593 - val_loss: 0.1725 - val_accuracy: 0.9476\n",
      "Epoch 984/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9550 - val_loss: 0.2166 - val_accuracy: 0.9476\n",
      "Epoch 985/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9535 - val_loss: 0.1718 - val_accuracy: 0.9421\n",
      "Epoch 986/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9633 - val_loss: 0.1957 - val_accuracy: 0.9452\n",
      "Epoch 987/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1215 - accuracy: 0.9611 - val_loss: 0.1843 - val_accuracy: 0.9460\n",
      "Epoch 988/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9583 - val_loss: 0.1832 - val_accuracy: 0.9476\n",
      "Epoch 989/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9551 - val_loss: 0.1936 - val_accuracy: 0.9484\n",
      "Epoch 990/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9638 - val_loss: 0.2055 - val_accuracy: 0.9484\n",
      "Epoch 991/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9614 - val_loss: 0.1743 - val_accuracy: 0.9452\n",
      "Epoch 992/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9563 - val_loss: 0.1788 - val_accuracy: 0.9460\n",
      "Epoch 993/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9612 - val_loss: 0.1704 - val_accuracy: 0.9476\n",
      "Epoch 994/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9611 - val_loss: 0.2075 - val_accuracy: 0.9429\n",
      "Epoch 995/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9611 - val_loss: 0.2061 - val_accuracy: 0.9460\n",
      "Epoch 996/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1213 - accuracy: 0.9592 - val_loss: 0.1757 - val_accuracy: 0.9476\n",
      "Epoch 997/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9618 - val_loss: 0.1795 - val_accuracy: 0.9476\n",
      "Epoch 998/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1213 - accuracy: 0.9599 - val_loss: 0.1922 - val_accuracy: 0.9484\n",
      "Epoch 999/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9603 - val_loss: 0.1934 - val_accuracy: 0.9444\n",
      "Epoch 1000/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9576 - val_loss: 0.1612 - val_accuracy: 0.9468\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9514867067337036"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history1.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.title('model1 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('model1 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 400)               4400      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 145,102\n",
      "Trainable params: 145,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "                    keras.layers.Input(shape=X_train.shape[1], name='input'),\n",
    "                    keras.layers.Dense(400, activation='selu'),\n",
    "                    keras.layers.Dense(200, activation='selu'),\n",
    "                    keras.layers.Dense(200, activation='selu'),\n",
    "                    keras.layers.Dense(100, activation='selu'),\n",
    "                    keras.layers.Dense(2, activation='softmax', name='output')\n",
    "                    ])\n",
    "\n",
    "model2.compile(\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            optimizer='Adam',\n",
    "            metrics= ['accuracy']\n",
    "            )\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "120/120 [==============================] - 1s 3ms/step - loss: 0.8603 - accuracy: 0.8924 - val_loss: 0.1639 - val_accuracy: 0.9515\n",
      "Epoch 2/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.9386 - val_loss: 0.1888 - val_accuracy: 0.9515\n",
      "Epoch 3/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9362 - val_loss: 0.1680 - val_accuracy: 0.9515\n",
      "Epoch 4/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9491 - val_loss: 0.1652 - val_accuracy: 0.9515\n",
      "Epoch 5/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9527 - val_loss: 0.1604 - val_accuracy: 0.9515\n",
      "Epoch 6/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9522 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 7/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9427 - val_loss: 0.1657 - val_accuracy: 0.9515\n",
      "Epoch 8/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9518 - val_loss: 0.1619 - val_accuracy: 0.9437\n",
      "Epoch 9/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9568 - val_loss: 0.2650 - val_accuracy: 0.8975\n",
      "Epoch 10/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9445 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 11/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9506 - val_loss: 0.1525 - val_accuracy: 0.9515\n",
      "Epoch 12/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9549 - val_loss: 0.1864 - val_accuracy: 0.9280\n",
      "Epoch 13/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9480 - val_loss: 0.1571 - val_accuracy: 0.9515\n",
      "Epoch 14/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1561 - accuracy: 0.9539 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 15/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9494 - val_loss: 0.1729 - val_accuracy: 0.9429\n",
      "Epoch 16/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9467 - val_loss: 0.1865 - val_accuracy: 0.9515\n",
      "Epoch 17/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9535 - val_loss: 0.1620 - val_accuracy: 0.9515\n",
      "Epoch 18/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9481 - val_loss: 0.1624 - val_accuracy: 0.9515\n",
      "Epoch 19/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9507 - val_loss: 0.1952 - val_accuracy: 0.9178\n",
      "Epoch 20/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9492 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 21/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9513 - val_loss: 0.1701 - val_accuracy: 0.9515\n",
      "Epoch 22/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9477 - val_loss: 0.1523 - val_accuracy: 0.9515\n",
      "Epoch 23/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9581 - val_loss: 0.1886 - val_accuracy: 0.9515\n",
      "Epoch 24/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9539 - val_loss: 0.1803 - val_accuracy: 0.9366\n",
      "Epoch 25/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9462 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 26/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.9523 - val_loss: 0.1622 - val_accuracy: 0.9515\n",
      "Epoch 27/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9546 - val_loss: 0.1770 - val_accuracy: 0.9515\n",
      "Epoch 28/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.9520 - val_loss: 0.1597 - val_accuracy: 0.9515\n",
      "Epoch 29/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9444 - val_loss: 0.1664 - val_accuracy: 0.9515\n",
      "Epoch 30/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.9513 - val_loss: 0.1608 - val_accuracy: 0.9515\n",
      "Epoch 31/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9459 - val_loss: 0.1618 - val_accuracy: 0.9515\n",
      "Epoch 32/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9541 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 33/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9510 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 34/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9532 - val_loss: 0.1522 - val_accuracy: 0.9515\n",
      "Epoch 35/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9495 - val_loss: 0.1518 - val_accuracy: 0.9515\n",
      "Epoch 36/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9522 - val_loss: 0.1805 - val_accuracy: 0.9515\n",
      "Epoch 37/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9549 - val_loss: 0.1639 - val_accuracy: 0.9515\n",
      "Epoch 38/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9466 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 39/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9456 - val_loss: 0.1614 - val_accuracy: 0.9515\n",
      "Epoch 40/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9498 - val_loss: 0.1503 - val_accuracy: 0.9515\n",
      "Epoch 41/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9497 - val_loss: 0.1534 - val_accuracy: 0.9515\n",
      "Epoch 42/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9594 - val_loss: 0.1627 - val_accuracy: 0.9515\n",
      "Epoch 43/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9542 - val_loss: 0.1522 - val_accuracy: 0.9515\n",
      "Epoch 44/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9529 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 45/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9509 - val_loss: 0.1532 - val_accuracy: 0.9515\n",
      "Epoch 46/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9557 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 47/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9511 - val_loss: 0.1497 - val_accuracy: 0.9515\n",
      "Epoch 48/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9535 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 49/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9492 - val_loss: 0.1518 - val_accuracy: 0.9515\n",
      "Epoch 50/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9467 - val_loss: 0.1515 - val_accuracy: 0.9515\n",
      "Epoch 51/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9462 - val_loss: 0.1573 - val_accuracy: 0.9515\n",
      "Epoch 52/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9484 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 53/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9483 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 54/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9468 - val_loss: 0.1512 - val_accuracy: 0.9515\n",
      "Epoch 55/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1697 - accuracy: 0.9469 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 56/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9497 - val_loss: 0.1514 - val_accuracy: 0.9515\n",
      "Epoch 57/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9523 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 58/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9454 - val_loss: 0.1597 - val_accuracy: 0.9507\n",
      "Epoch 59/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9480 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 60/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9534 - val_loss: 0.1719 - val_accuracy: 0.9515\n",
      "Epoch 61/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9475 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 62/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9535 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 63/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9534 - val_loss: 0.1501 - val_accuracy: 0.9515\n",
      "Epoch 64/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9515 - val_loss: 0.1528 - val_accuracy: 0.9515\n",
      "Epoch 65/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9595 - val_loss: 0.1601 - val_accuracy: 0.9515\n",
      "Epoch 66/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9524 - val_loss: 0.1596 - val_accuracy: 0.9515\n",
      "Epoch 67/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9536 - val_loss: 0.1493 - val_accuracy: 0.9515\n",
      "Epoch 68/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.9508 - val_loss: 0.1604 - val_accuracy: 0.9507\n",
      "Epoch 69/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9530 - val_loss: 0.1499 - val_accuracy: 0.9515\n",
      "Epoch 70/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9494 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 71/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9539 - val_loss: 0.1522 - val_accuracy: 0.9515\n",
      "Epoch 72/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9548 - val_loss: 0.1523 - val_accuracy: 0.9515\n",
      "Epoch 73/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9526 - val_loss: 0.1519 - val_accuracy: 0.9507\n",
      "Epoch 74/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9572 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 75/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9539 - val_loss: 0.1527 - val_accuracy: 0.9515\n",
      "Epoch 76/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9548 - val_loss: 0.1560 - val_accuracy: 0.9507\n",
      "Epoch 77/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9450 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 78/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9521 - val_loss: 0.1510 - val_accuracy: 0.9515\n",
      "Epoch 79/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9597 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 80/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9448 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 81/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9528 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 82/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9561 - val_loss: 0.1529 - val_accuracy: 0.9515\n",
      "Epoch 83/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9506 - val_loss: 0.1601 - val_accuracy: 0.9515\n",
      "Epoch 84/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9459 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 85/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9520 - val_loss: 0.1516 - val_accuracy: 0.9515\n",
      "Epoch 86/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9502 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 87/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9520 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 88/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9506 - val_loss: 0.1725 - val_accuracy: 0.9515\n",
      "Epoch 89/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9549 - val_loss: 0.1639 - val_accuracy: 0.9444\n",
      "Epoch 90/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9491 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 91/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9500 - val_loss: 0.1519 - val_accuracy: 0.9515\n",
      "Epoch 92/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9543 - val_loss: 0.1594 - val_accuracy: 0.9491\n",
      "Epoch 93/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9496 - val_loss: 0.1619 - val_accuracy: 0.9515\n",
      "Epoch 94/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9515 - val_loss: 0.1515 - val_accuracy: 0.9515\n",
      "Epoch 95/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9511 - val_loss: 0.1520 - val_accuracy: 0.9515\n",
      "Epoch 96/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9586 - val_loss: 0.1519 - val_accuracy: 0.9515\n",
      "Epoch 97/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9500 - val_loss: 0.1511 - val_accuracy: 0.9515\n",
      "Epoch 98/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9531 - val_loss: 0.1510 - val_accuracy: 0.9515\n",
      "Epoch 99/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.9506 - val_loss: 0.1517 - val_accuracy: 0.9515\n",
      "Epoch 100/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9522 - val_loss: 0.1521 - val_accuracy: 0.9515\n",
      "Epoch 101/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9501 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 102/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9471 - val_loss: 0.1588 - val_accuracy: 0.9515\n",
      "Epoch 103/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.9515 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 104/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.9512 - val_loss: 0.1574 - val_accuracy: 0.9515\n",
      "Epoch 105/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9511 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 106/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9505 - val_loss: 0.1528 - val_accuracy: 0.9515\n",
      "Epoch 107/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9474 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 108/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9592 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 109/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9571 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 110/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9512 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 111/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9543 - val_loss: 0.1537 - val_accuracy: 0.9507\n",
      "Epoch 112/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9483 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 113/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9518 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 114/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9516 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 115/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9504 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 116/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9529 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 117/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9542 - val_loss: 0.1554 - val_accuracy: 0.9507\n",
      "Epoch 118/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.9480 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 119/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9530 - val_loss: 0.1511 - val_accuracy: 0.9515\n",
      "Epoch 120/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9465 - val_loss: 0.1656 - val_accuracy: 0.9382\n",
      "Epoch 121/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9567 - val_loss: 0.1600 - val_accuracy: 0.9499\n",
      "Epoch 122/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9498 - val_loss: 0.1537 - val_accuracy: 0.9499\n",
      "Epoch 123/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9549 - val_loss: 0.1642 - val_accuracy: 0.9460\n",
      "Epoch 124/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9484 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 125/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9560 - val_loss: 0.1634 - val_accuracy: 0.9468\n",
      "Epoch 126/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9515 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 127/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9541 - val_loss: 0.1644 - val_accuracy: 0.9515\n",
      "Epoch 128/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9454 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 129/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 0.9488 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 130/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9449 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 131/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9453 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 132/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9518 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 133/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9506 - val_loss: 0.1585 - val_accuracy: 0.9515\n",
      "Epoch 134/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9536 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 135/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9518 - val_loss: 0.1583 - val_accuracy: 0.9484\n",
      "Epoch 136/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.9493 - val_loss: 0.1631 - val_accuracy: 0.9515\n",
      "Epoch 137/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9552 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 138/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9530 - val_loss: 0.1600 - val_accuracy: 0.9468\n",
      "Epoch 139/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9509 - val_loss: 0.1646 - val_accuracy: 0.9429\n",
      "Epoch 140/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9535 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 141/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.9423 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 142/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9530 - val_loss: 0.1550 - val_accuracy: 0.9507\n",
      "Epoch 143/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9502 - val_loss: 0.1590 - val_accuracy: 0.9515\n",
      "Epoch 144/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9544 - val_loss: 0.1611 - val_accuracy: 0.9515\n",
      "Epoch 145/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9556 - val_loss: 0.1516 - val_accuracy: 0.9515\n",
      "Epoch 146/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9488 - val_loss: 0.1551 - val_accuracy: 0.9507\n",
      "Epoch 147/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9452 - val_loss: 0.1961 - val_accuracy: 0.9515\n",
      "Epoch 148/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9429 - val_loss: 0.1609 - val_accuracy: 0.9507\n",
      "Epoch 149/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9542 - val_loss: 0.1548 - val_accuracy: 0.9491\n",
      "Epoch 150/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9559 - val_loss: 0.1564 - val_accuracy: 0.9507\n",
      "Epoch 151/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9538 - val_loss: 0.1633 - val_accuracy: 0.9515\n",
      "Epoch 152/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9546 - val_loss: 0.1555 - val_accuracy: 0.9507\n",
      "Epoch 153/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9492 - val_loss: 0.1522 - val_accuracy: 0.9515\n",
      "Epoch 154/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9503 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 155/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9561 - val_loss: 0.1564 - val_accuracy: 0.9499\n",
      "Epoch 156/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9513 - val_loss: 0.1585 - val_accuracy: 0.9515\n",
      "Epoch 157/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9543 - val_loss: 0.1571 - val_accuracy: 0.9515\n",
      "Epoch 158/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9488 - val_loss: 0.1527 - val_accuracy: 0.9515\n",
      "Epoch 159/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9521 - val_loss: 0.1585 - val_accuracy: 0.9484\n",
      "Epoch 160/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9536 - val_loss: 0.1607 - val_accuracy: 0.9484\n",
      "Epoch 161/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9499 - val_loss: 0.1528 - val_accuracy: 0.9515\n",
      "Epoch 162/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9557 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 163/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9543 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 164/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9529 - val_loss: 0.1647 - val_accuracy: 0.9507\n",
      "Epoch 165/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9499 - val_loss: 0.1696 - val_accuracy: 0.9405\n",
      "Epoch 166/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9544 - val_loss: 0.1536 - val_accuracy: 0.9499\n",
      "Epoch 167/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.9474 - val_loss: 0.1545 - val_accuracy: 0.9507\n",
      "Epoch 168/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9549 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 169/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9516 - val_loss: 0.1541 - val_accuracy: 0.9507\n",
      "Epoch 170/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9459 - val_loss: 0.1534 - val_accuracy: 0.9515\n",
      "Epoch 171/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9510 - val_loss: 0.1664 - val_accuracy: 0.9515\n",
      "Epoch 172/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9428 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 173/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9525 - val_loss: 0.1526 - val_accuracy: 0.9507\n",
      "Epoch 174/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9494 - val_loss: 0.1567 - val_accuracy: 0.9491\n",
      "Epoch 175/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9569 - val_loss: 0.1677 - val_accuracy: 0.9484\n",
      "Epoch 176/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9498 - val_loss: 0.1572 - val_accuracy: 0.9491\n",
      "Epoch 177/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9464 - val_loss: 0.1546 - val_accuracy: 0.9507\n",
      "Epoch 178/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9502 - val_loss: 0.1557 - val_accuracy: 0.9491\n",
      "Epoch 179/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9563 - val_loss: 0.1570 - val_accuracy: 0.9507\n",
      "Epoch 180/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 0.9499 - val_loss: 0.1647 - val_accuracy: 0.9515\n",
      "Epoch 181/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9563 - val_loss: 0.1579 - val_accuracy: 0.9491\n",
      "Epoch 182/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9532 - val_loss: 0.1569 - val_accuracy: 0.9476\n",
      "Epoch 183/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9506 - val_loss: 0.1583 - val_accuracy: 0.9499\n",
      "Epoch 184/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9472 - val_loss: 0.1601 - val_accuracy: 0.9515\n",
      "Epoch 185/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9479 - val_loss: 0.1586 - val_accuracy: 0.9484\n",
      "Epoch 186/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9540 - val_loss: 0.1608 - val_accuracy: 0.9515\n",
      "Epoch 187/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9497 - val_loss: 0.1655 - val_accuracy: 0.9507\n",
      "Epoch 188/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9545 - val_loss: 0.1616 - val_accuracy: 0.9507\n",
      "Epoch 189/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9513 - val_loss: 0.1536 - val_accuracy: 0.9507\n",
      "Epoch 190/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9532 - val_loss: 0.1638 - val_accuracy: 0.9460\n",
      "Epoch 191/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9508 - val_loss: 0.1527 - val_accuracy: 0.9515\n",
      "Epoch 192/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9549 - val_loss: 0.1577 - val_accuracy: 0.9484\n",
      "Epoch 193/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9419 - val_loss: 0.1649 - val_accuracy: 0.9507\n",
      "Epoch 194/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9492 - val_loss: 0.1524 - val_accuracy: 0.9507\n",
      "Epoch 195/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9502 - val_loss: 0.1687 - val_accuracy: 0.9515\n",
      "Epoch 196/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9514 - val_loss: 0.1587 - val_accuracy: 0.9515\n",
      "Epoch 197/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9531 - val_loss: 0.1602 - val_accuracy: 0.9515\n",
      "Epoch 198/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9569 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 199/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9519 - val_loss: 0.1532 - val_accuracy: 0.9507\n",
      "Epoch 200/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9560 - val_loss: 0.1629 - val_accuracy: 0.9515\n",
      "Epoch 201/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9511 - val_loss: 0.1597 - val_accuracy: 0.9452\n",
      "Epoch 202/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9504 - val_loss: 0.1534 - val_accuracy: 0.9515\n",
      "Epoch 203/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9424 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 204/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9418 - val_loss: 0.1615 - val_accuracy: 0.9515\n",
      "Epoch 205/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9531 - val_loss: 0.1594 - val_accuracy: 0.9507\n",
      "Epoch 206/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9521 - val_loss: 0.1545 - val_accuracy: 0.9499\n",
      "Epoch 207/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9536 - val_loss: 0.1571 - val_accuracy: 0.9507\n",
      "Epoch 208/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9518 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 209/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9543 - val_loss: 0.1522 - val_accuracy: 0.9507\n",
      "Epoch 210/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9566 - val_loss: 0.1517 - val_accuracy: 0.9507\n",
      "Epoch 211/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9493 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 212/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9555 - val_loss: 0.1587 - val_accuracy: 0.9476\n",
      "Epoch 213/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9510 - val_loss: 0.1653 - val_accuracy: 0.9515\n",
      "Epoch 214/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9526 - val_loss: 0.1561 - val_accuracy: 0.9484\n",
      "Epoch 215/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9512 - val_loss: 0.1558 - val_accuracy: 0.9507\n",
      "Epoch 216/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9571 - val_loss: 0.1644 - val_accuracy: 0.9507\n",
      "Epoch 217/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9470 - val_loss: 0.1583 - val_accuracy: 0.9507\n",
      "Epoch 218/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9523 - val_loss: 0.1690 - val_accuracy: 0.9515\n",
      "Epoch 219/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9530 - val_loss: 0.1551 - val_accuracy: 0.9484\n",
      "Epoch 220/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9531 - val_loss: 0.1635 - val_accuracy: 0.9476\n",
      "Epoch 221/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9513 - val_loss: 0.1608 - val_accuracy: 0.9468\n",
      "Epoch 222/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9505 - val_loss: 0.1538 - val_accuracy: 0.9499\n",
      "Epoch 223/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9519 - val_loss: 0.1630 - val_accuracy: 0.9484\n",
      "Epoch 224/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.94 - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9472 - val_loss: 0.1552 - val_accuracy: 0.9507\n",
      "Epoch 225/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9478 - val_loss: 0.1739 - val_accuracy: 0.9507\n",
      "Epoch 226/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9520 - val_loss: 0.1560 - val_accuracy: 0.9484\n",
      "Epoch 227/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9471 - val_loss: 0.1524 - val_accuracy: 0.9507\n",
      "Epoch 228/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9507 - val_loss: 0.1699 - val_accuracy: 0.9507\n",
      "Epoch 229/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9546 - val_loss: 0.1814 - val_accuracy: 0.9296\n",
      "Epoch 230/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9496 - val_loss: 0.1565 - val_accuracy: 0.9507\n",
      "Epoch 231/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9565 - val_loss: 0.1581 - val_accuracy: 0.9507\n",
      "Epoch 232/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.9442 - val_loss: 0.1701 - val_accuracy: 0.9515\n",
      "Epoch 233/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9542 - val_loss: 0.1557 - val_accuracy: 0.9507\n",
      "Epoch 234/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9539 - val_loss: 0.1541 - val_accuracy: 0.9507\n",
      "Epoch 235/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.9490 - val_loss: 0.1646 - val_accuracy: 0.9460\n",
      "Epoch 236/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9544 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 237/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9540 - val_loss: 0.1628 - val_accuracy: 0.9491\n",
      "Epoch 238/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9538 - val_loss: 0.1603 - val_accuracy: 0.9476\n",
      "Epoch 239/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9494 - val_loss: 0.1646 - val_accuracy: 0.9507\n",
      "Epoch 240/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9463 - val_loss: 0.1602 - val_accuracy: 0.9476\n",
      "Epoch 241/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9497 - val_loss: 0.1646 - val_accuracy: 0.9515\n",
      "Epoch 242/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9526 - val_loss: 0.1551 - val_accuracy: 0.9507\n",
      "Epoch 243/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9546 - val_loss: 0.1645 - val_accuracy: 0.9468\n",
      "Epoch 244/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9518 - val_loss: 0.1574 - val_accuracy: 0.9507\n",
      "Epoch 245/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9538 - val_loss: 0.1677 - val_accuracy: 0.9405\n",
      "Epoch 246/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9512 - val_loss: 0.1601 - val_accuracy: 0.9499\n",
      "Epoch 247/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9474 - val_loss: 0.1554 - val_accuracy: 0.9507\n",
      "Epoch 248/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9541 - val_loss: 0.1556 - val_accuracy: 0.9507\n",
      "Epoch 249/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9518 - val_loss: 0.1729 - val_accuracy: 0.9429\n",
      "Epoch 250/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9555 - val_loss: 0.1559 - val_accuracy: 0.9499\n",
      "Epoch 251/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9587 - val_loss: 0.1642 - val_accuracy: 0.9460\n",
      "Epoch 252/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.9479 - val_loss: 0.1603 - val_accuracy: 0.9476\n",
      "Epoch 253/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9560 - val_loss: 0.1559 - val_accuracy: 0.9507\n",
      "Epoch 254/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9536 - val_loss: 0.1559 - val_accuracy: 0.9507\n",
      "Epoch 255/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9594 - val_loss: 0.1589 - val_accuracy: 0.9507\n",
      "Epoch 256/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9508 - val_loss: 0.1556 - val_accuracy: 0.9507\n",
      "Epoch 257/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9508 - val_loss: 0.1809 - val_accuracy: 0.9507\n",
      "Epoch 258/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9497 - val_loss: 0.1573 - val_accuracy: 0.9507\n",
      "Epoch 259/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9527 - val_loss: 0.1582 - val_accuracy: 0.9491\n",
      "Epoch 260/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9546 - val_loss: 0.1621 - val_accuracy: 0.9515\n",
      "Epoch 261/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9564 - val_loss: 0.1685 - val_accuracy: 0.9460\n",
      "Epoch 262/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9499 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 263/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9554 - val_loss: 0.1527 - val_accuracy: 0.9507\n",
      "Epoch 264/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9487 - val_loss: 0.1819 - val_accuracy: 0.9507\n",
      "Epoch 265/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9533 - val_loss: 0.1553 - val_accuracy: 0.9507\n",
      "Epoch 266/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9544 - val_loss: 0.1602 - val_accuracy: 0.9507\n",
      "Epoch 267/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9485 - val_loss: 0.1624 - val_accuracy: 0.9468\n",
      "Epoch 268/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9487 - val_loss: 0.1526 - val_accuracy: 0.9507\n",
      "Epoch 269/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9484 - val_loss: 0.1640 - val_accuracy: 0.9507\n",
      "Epoch 270/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9528 - val_loss: 0.1555 - val_accuracy: 0.9507\n",
      "Epoch 271/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9492 - val_loss: 0.1611 - val_accuracy: 0.9515\n",
      "Epoch 272/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9508 - val_loss: 0.1629 - val_accuracy: 0.9507\n",
      "Epoch 273/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9528 - val_loss: 0.1612 - val_accuracy: 0.9460\n",
      "Epoch 274/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9409 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 275/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9495 - val_loss: 0.1670 - val_accuracy: 0.9507\n",
      "Epoch 276/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.9553 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 277/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9539 - val_loss: 0.1618 - val_accuracy: 0.9468\n",
      "Epoch 278/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9471 - val_loss: 0.1622 - val_accuracy: 0.9507\n",
      "Epoch 279/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9521 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 280/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9528 - val_loss: 0.1697 - val_accuracy: 0.9390\n",
      "Epoch 281/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9525 - val_loss: 0.1607 - val_accuracy: 0.9507\n",
      "Epoch 282/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9548 - val_loss: 0.1705 - val_accuracy: 0.9499\n",
      "Epoch 283/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9508 - val_loss: 0.1567 - val_accuracy: 0.9507\n",
      "Epoch 284/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9501 - val_loss: 0.1542 - val_accuracy: 0.9507\n",
      "Epoch 285/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9478 - val_loss: 0.1561 - val_accuracy: 0.9507\n",
      "Epoch 286/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.9587 - val_loss: 0.1604 - val_accuracy: 0.9460\n",
      "Epoch 287/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9504 - val_loss: 0.1531 - val_accuracy: 0.9507\n",
      "Epoch 288/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9535 - val_loss: 0.1549 - val_accuracy: 0.9499\n",
      "Epoch 289/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1424 - accuracy: 0.9523 - val_loss: 0.1587 - val_accuracy: 0.9507\n",
      "Epoch 290/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9487 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 291/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9609 - val_loss: 0.1653 - val_accuracy: 0.9460\n",
      "Epoch 292/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1698 - accuracy: 0.9500 - val_loss: 0.1763 - val_accuracy: 0.9515\n",
      "Epoch 293/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9512 - val_loss: 0.1583 - val_accuracy: 0.9507\n",
      "Epoch 294/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9552 - val_loss: 0.1577 - val_accuracy: 0.9499\n",
      "Epoch 295/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9545 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 296/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9565 - val_loss: 0.1593 - val_accuracy: 0.9507\n",
      "Epoch 297/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9484 - val_loss: 0.1625 - val_accuracy: 0.9484\n",
      "Epoch 298/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9561 - val_loss: 0.1674 - val_accuracy: 0.9507\n",
      "Epoch 299/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9523 - val_loss: 0.1555 - val_accuracy: 0.9499\n",
      "Epoch 300/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9502 - val_loss: 0.1657 - val_accuracy: 0.9491\n",
      "Epoch 301/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9515 - val_loss: 0.1630 - val_accuracy: 0.9515\n",
      "Epoch 302/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9523 - val_loss: 0.1574 - val_accuracy: 0.9507\n",
      "Epoch 303/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9532 - val_loss: 0.1525 - val_accuracy: 0.9515\n",
      "Epoch 304/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9498 - val_loss: 0.1550 - val_accuracy: 0.9491\n",
      "Epoch 305/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9581 - val_loss: 0.1744 - val_accuracy: 0.9491\n",
      "Epoch 306/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9439 - val_loss: 0.1595 - val_accuracy: 0.9484\n",
      "Epoch 307/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9542 - val_loss: 0.1782 - val_accuracy: 0.9413\n",
      "Epoch 308/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9603 - val_loss: 0.1800 - val_accuracy: 0.9413\n",
      "Epoch 309/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9523 - val_loss: 0.1583 - val_accuracy: 0.9491\n",
      "Epoch 310/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9552 - val_loss: 0.1655 - val_accuracy: 0.9507\n",
      "Epoch 311/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9500 - val_loss: 0.1777 - val_accuracy: 0.9319\n",
      "Epoch 312/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9467 - val_loss: 0.1634 - val_accuracy: 0.9507\n",
      "Epoch 313/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9519 - val_loss: 0.1626 - val_accuracy: 0.9515\n",
      "Epoch 314/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9571 - val_loss: 0.1601 - val_accuracy: 0.9484\n",
      "Epoch 315/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.9487 - val_loss: 0.1611 - val_accuracy: 0.9468\n",
      "Epoch 316/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9510 - val_loss: 0.1648 - val_accuracy: 0.9491\n",
      "Epoch 317/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9533 - val_loss: 0.1601 - val_accuracy: 0.9491\n",
      "Epoch 318/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9547 - val_loss: 0.1654 - val_accuracy: 0.9460\n",
      "Epoch 319/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9570 - val_loss: 0.1617 - val_accuracy: 0.9468\n",
      "Epoch 320/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9555 - val_loss: 0.1595 - val_accuracy: 0.9491\n",
      "Epoch 321/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9548 - val_loss: 0.1611 - val_accuracy: 0.9429\n",
      "Epoch 322/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9546 - val_loss: 0.1549 - val_accuracy: 0.9507\n",
      "Epoch 323/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9510 - val_loss: 0.1584 - val_accuracy: 0.9507\n",
      "Epoch 324/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9490 - val_loss: 0.1559 - val_accuracy: 0.9491\n",
      "Epoch 325/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9526 - val_loss: 0.1645 - val_accuracy: 0.9507\n",
      "Epoch 326/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9449 - val_loss: 0.1630 - val_accuracy: 0.9484\n",
      "Epoch 327/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9530 - val_loss: 0.1564 - val_accuracy: 0.9507\n",
      "Epoch 328/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9544 - val_loss: 0.1578 - val_accuracy: 0.9499\n",
      "Epoch 329/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9528 - val_loss: 0.1674 - val_accuracy: 0.9429\n",
      "Epoch 330/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9494 - val_loss: 0.1653 - val_accuracy: 0.9507\n",
      "Epoch 331/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9552 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 332/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9598 - val_loss: 0.1602 - val_accuracy: 0.9491\n",
      "Epoch 333/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9571 - val_loss: 0.1595 - val_accuracy: 0.9491\n",
      "Epoch 334/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9505 - val_loss: 0.1582 - val_accuracy: 0.9491\n",
      "Epoch 335/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9489 - val_loss: 0.1535 - val_accuracy: 0.9507\n",
      "Epoch 336/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9524 - val_loss: 0.1705 - val_accuracy: 0.9437\n",
      "Epoch 337/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.9473 - val_loss: 0.1865 - val_accuracy: 0.9507\n",
      "Epoch 338/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9517 - val_loss: 0.1620 - val_accuracy: 0.9507\n",
      "Epoch 339/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9482 - val_loss: 0.1736 - val_accuracy: 0.9491\n",
      "Epoch 340/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9538 - val_loss: 0.1537 - val_accuracy: 0.9499\n",
      "Epoch 341/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9565 - val_loss: 0.1723 - val_accuracy: 0.9444\n",
      "Epoch 342/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9627 - val_loss: 0.1895 - val_accuracy: 0.9405\n",
      "Epoch 343/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9502 - val_loss: 0.1602 - val_accuracy: 0.9484\n",
      "Epoch 344/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9538 - val_loss: 0.1613 - val_accuracy: 0.9476\n",
      "Epoch 345/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1307 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9581 - val_loss: 0.1636 - val_accuracy: 0.9476\n",
      "Epoch 346/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9532 - val_loss: 0.1618 - val_accuracy: 0.9491\n",
      "Epoch 347/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9529 - val_loss: 0.1718 - val_accuracy: 0.9452\n",
      "Epoch 348/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9537 - val_loss: 0.1661 - val_accuracy: 0.9468\n",
      "Epoch 349/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9561 - val_loss: 0.1561 - val_accuracy: 0.9499\n",
      "Epoch 350/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9559 - val_loss: 0.1592 - val_accuracy: 0.9507\n",
      "Epoch 351/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9523 - val_loss: 0.1754 - val_accuracy: 0.9468\n",
      "Epoch 352/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9480 - val_loss: 0.1564 - val_accuracy: 0.9476\n",
      "Epoch 353/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9559 - val_loss: 0.1633 - val_accuracy: 0.9444\n",
      "Epoch 354/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9478 - val_loss: 0.1697 - val_accuracy: 0.9507\n",
      "Epoch 355/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9597 - val_loss: 0.1585 - val_accuracy: 0.9491\n",
      "Epoch 356/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9543 - val_loss: 0.1665 - val_accuracy: 0.9444\n",
      "Epoch 357/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9524 - val_loss: 0.1952 - val_accuracy: 0.9374\n",
      "Epoch 358/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9500 - val_loss: 0.1652 - val_accuracy: 0.9484\n",
      "Epoch 359/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9622 - val_loss: 0.1675 - val_accuracy: 0.9484\n",
      "Epoch 360/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9513 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 361/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9534 - val_loss: 0.1546 - val_accuracy: 0.9499\n",
      "Epoch 362/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9528 - val_loss: 0.1664 - val_accuracy: 0.9452\n",
      "Epoch 363/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9507 - val_loss: 0.1650 - val_accuracy: 0.9484\n",
      "Epoch 364/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9535 - val_loss: 0.1645 - val_accuracy: 0.9468\n",
      "Epoch 365/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9555 - val_loss: 0.1618 - val_accuracy: 0.9476\n",
      "Epoch 366/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9580 - val_loss: 0.1643 - val_accuracy: 0.9507\n",
      "Epoch 367/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9535 - val_loss: 0.1572 - val_accuracy: 0.9499\n",
      "Epoch 368/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9577 - val_loss: 0.1583 - val_accuracy: 0.9491\n",
      "Epoch 369/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9538 - val_loss: 0.1613 - val_accuracy: 0.9507\n",
      "Epoch 370/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9554 - val_loss: 0.1746 - val_accuracy: 0.9476\n",
      "Epoch 371/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9563 - val_loss: 0.1586 - val_accuracy: 0.9491\n",
      "Epoch 372/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9516 - val_loss: 0.1620 - val_accuracy: 0.9499\n",
      "Epoch 373/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9493 - val_loss: 0.1576 - val_accuracy: 0.9507\n",
      "Epoch 374/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9486 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 375/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9530 - val_loss: 0.1644 - val_accuracy: 0.9499\n",
      "Epoch 376/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9518 - val_loss: 0.1562 - val_accuracy: 0.9499\n",
      "Epoch 377/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9534 - val_loss: 0.1516 - val_accuracy: 0.9515\n",
      "Epoch 378/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9535 - val_loss: 0.1757 - val_accuracy: 0.9491\n",
      "Epoch 379/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9562 - val_loss: 0.1570 - val_accuracy: 0.9507\n",
      "Epoch 380/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9448 - val_loss: 0.1806 - val_accuracy: 0.9382\n",
      "Epoch 381/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9522 - val_loss: 0.1772 - val_accuracy: 0.9507\n",
      "Epoch 382/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9505 - val_loss: 0.1649 - val_accuracy: 0.9468\n",
      "Epoch 383/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9547 - val_loss: 0.1698 - val_accuracy: 0.9484\n",
      "Epoch 384/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9566 - val_loss: 0.1600 - val_accuracy: 0.9499\n",
      "Epoch 385/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9537 - val_loss: 0.1593 - val_accuracy: 0.9507\n",
      "Epoch 386/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9528 - val_loss: 0.1584 - val_accuracy: 0.9491\n",
      "Epoch 387/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9578 - val_loss: 0.1607 - val_accuracy: 0.9499\n",
      "Epoch 388/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9530 - val_loss: 0.1548 - val_accuracy: 0.9507\n",
      "Epoch 389/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9547 - val_loss: 0.1596 - val_accuracy: 0.9507\n",
      "Epoch 390/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9549 - val_loss: 0.1584 - val_accuracy: 0.9507\n",
      "Epoch 391/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9538 - val_loss: 0.1864 - val_accuracy: 0.9429\n",
      "Epoch 392/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9505 - val_loss: 0.1664 - val_accuracy: 0.9515\n",
      "Epoch 393/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9502 - val_loss: 0.1628 - val_accuracy: 0.9515\n",
      "Epoch 394/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9546 - val_loss: 0.1891 - val_accuracy: 0.9452\n",
      "Epoch 395/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9567 - val_loss: 0.1547 - val_accuracy: 0.9499\n",
      "Epoch 396/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9515 - val_loss: 0.1599 - val_accuracy: 0.9491\n",
      "Epoch 397/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9567 - val_loss: 0.1587 - val_accuracy: 0.9491\n",
      "Epoch 398/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9519 - val_loss: 0.1565 - val_accuracy: 0.9507\n",
      "Epoch 399/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9533 - val_loss: 0.1623 - val_accuracy: 0.9491\n",
      "Epoch 400/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9544 - val_loss: 0.1629 - val_accuracy: 0.9491\n",
      "Epoch 401/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9555 - val_loss: 0.1588 - val_accuracy: 0.9507\n",
      "Epoch 402/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9494 - val_loss: 0.1867 - val_accuracy: 0.9437\n",
      "Epoch 403/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9496 - val_loss: 0.1753 - val_accuracy: 0.9499\n",
      "Epoch 404/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9490 - val_loss: 0.1766 - val_accuracy: 0.9452\n",
      "Epoch 405/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9560 - val_loss: 0.1664 - val_accuracy: 0.9499\n",
      "Epoch 406/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9518 - val_loss: 0.1671 - val_accuracy: 0.9460\n",
      "Epoch 407/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9527 - val_loss: 0.1684 - val_accuracy: 0.9515\n",
      "Epoch 408/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9521 - val_loss: 0.1589 - val_accuracy: 0.9468\n",
      "Epoch 409/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.9568 - val_loss: 0.1661 - val_accuracy: 0.9484\n",
      "Epoch 410/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9509 - val_loss: 0.1598 - val_accuracy: 0.9507\n",
      "Epoch 411/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9501 - val_loss: 0.1619 - val_accuracy: 0.9507\n",
      "Epoch 412/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9614 - val_loss: 0.1620 - val_accuracy: 0.9468\n",
      "Epoch 413/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9584 - val_loss: 0.1547 - val_accuracy: 0.9499\n",
      "Epoch 414/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9518 - val_loss: 0.1584 - val_accuracy: 0.9507\n",
      "Epoch 415/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9558 - val_loss: 0.1574 - val_accuracy: 0.9491\n",
      "Epoch 416/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9544 - val_loss: 0.1565 - val_accuracy: 0.9507\n",
      "Epoch 417/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9527 - val_loss: 0.1704 - val_accuracy: 0.9499\n",
      "Epoch 418/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9567 - val_loss: 0.1593 - val_accuracy: 0.9491\n",
      "Epoch 419/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9562 - val_loss: 0.1600 - val_accuracy: 0.9468\n",
      "Epoch 420/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9539 - val_loss: 0.1554 - val_accuracy: 0.9507\n",
      "Epoch 421/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9529 - val_loss: 0.1888 - val_accuracy: 0.9437\n",
      "Epoch 422/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9497 - val_loss: 0.1673 - val_accuracy: 0.9452\n",
      "Epoch 423/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9542 - val_loss: 0.1619 - val_accuracy: 0.9452\n",
      "Epoch 424/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9510 - val_loss: 0.1678 - val_accuracy: 0.9515\n",
      "Epoch 425/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9476 - val_loss: 0.1694 - val_accuracy: 0.9499\n",
      "Epoch 426/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9474 - val_loss: 0.1689 - val_accuracy: 0.9491\n",
      "Epoch 427/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9573 - val_loss: 0.1531 - val_accuracy: 0.9507\n",
      "Epoch 428/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9512 - val_loss: 0.1594 - val_accuracy: 0.9491\n",
      "Epoch 429/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9554 - val_loss: 0.1581 - val_accuracy: 0.9499\n",
      "Epoch 430/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9532 - val_loss: 0.1632 - val_accuracy: 0.9507\n",
      "Epoch 431/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9533 - val_loss: 0.1647 - val_accuracy: 0.9452\n",
      "Epoch 432/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9513 - val_loss: 0.1647 - val_accuracy: 0.9476\n",
      "Epoch 433/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9517 - val_loss: 0.1671 - val_accuracy: 0.9468\n",
      "Epoch 434/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9579 - val_loss: 0.1650 - val_accuracy: 0.9484\n",
      "Epoch 435/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9552 - val_loss: 0.1614 - val_accuracy: 0.9476\n",
      "Epoch 436/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9463 - val_loss: 0.1677 - val_accuracy: 0.9484\n",
      "Epoch 437/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9543 - val_loss: 0.1603 - val_accuracy: 0.9476\n",
      "Epoch 438/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9486 - val_loss: 0.1674 - val_accuracy: 0.9468\n",
      "Epoch 439/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9543 - val_loss: 0.1620 - val_accuracy: 0.9484\n",
      "Epoch 440/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9546 - val_loss: 0.1617 - val_accuracy: 0.9468\n",
      "Epoch 441/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9523 - val_loss: 0.1749 - val_accuracy: 0.9476\n",
      "Epoch 442/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9505 - val_loss: 0.1736 - val_accuracy: 0.9468\n",
      "Epoch 443/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9540 - val_loss: 0.1701 - val_accuracy: 0.9499\n",
      "Epoch 444/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9553 - val_loss: 0.2339 - val_accuracy: 0.9335\n",
      "Epoch 445/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9485 - val_loss: 0.1727 - val_accuracy: 0.9499\n",
      "Epoch 446/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9554 - val_loss: 0.1620 - val_accuracy: 0.9476\n",
      "Epoch 447/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9532 - val_loss: 0.1955 - val_accuracy: 0.9499\n",
      "Epoch 448/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9510 - val_loss: 0.1738 - val_accuracy: 0.9491\n",
      "Epoch 449/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9566 - val_loss: 0.1808 - val_accuracy: 0.9515\n",
      "Epoch 450/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9513 - val_loss: 0.1910 - val_accuracy: 0.9491\n",
      "Epoch 451/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9530 - val_loss: 0.1659 - val_accuracy: 0.9452\n",
      "Epoch 452/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9528 - val_loss: 0.1861 - val_accuracy: 0.9460\n",
      "Epoch 453/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9580 - val_loss: 0.1634 - val_accuracy: 0.9476\n",
      "Epoch 454/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9552 - val_loss: 0.1738 - val_accuracy: 0.9515\n",
      "Epoch 455/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9544 - val_loss: 0.1682 - val_accuracy: 0.9491\n",
      "Epoch 456/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9569 - val_loss: 0.1665 - val_accuracy: 0.9491\n",
      "Epoch 457/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9575 - val_loss: 0.1715 - val_accuracy: 0.9444\n",
      "Epoch 458/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9589 - val_loss: 0.1734 - val_accuracy: 0.9460\n",
      "Epoch 459/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9538 - val_loss: 0.1710 - val_accuracy: 0.9515\n",
      "Epoch 460/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9552 - val_loss: 0.1581 - val_accuracy: 0.9491\n",
      "Epoch 461/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9517 - val_loss: 0.1570 - val_accuracy: 0.9484\n",
      "Epoch 462/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9481 - val_loss: 0.1722 - val_accuracy: 0.9484\n",
      "Epoch 463/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9549 - val_loss: 0.1672 - val_accuracy: 0.9460\n",
      "Epoch 464/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9522 - val_loss: 0.1717 - val_accuracy: 0.9460\n",
      "Epoch 465/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9530 - val_loss: 0.1555 - val_accuracy: 0.9507\n",
      "Epoch 466/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9581 - val_loss: 0.1759 - val_accuracy: 0.9468\n",
      "Epoch 467/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9552 - val_loss: 0.1652 - val_accuracy: 0.9507\n",
      "Epoch 468/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9565 - val_loss: 0.1847 - val_accuracy: 0.9476\n",
      "Epoch 469/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9530 - val_loss: 0.1768 - val_accuracy: 0.9452\n",
      "Epoch 470/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9507 - val_loss: 0.1639 - val_accuracy: 0.9491\n",
      "Epoch 471/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9524 - val_loss: 0.1762 - val_accuracy: 0.9429\n",
      "Epoch 472/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9515 - val_loss: 0.1693 - val_accuracy: 0.9484\n",
      "Epoch 473/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9503 - val_loss: 0.1760 - val_accuracy: 0.9452\n",
      "Epoch 474/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9541 - val_loss: 0.1803 - val_accuracy: 0.9444\n",
      "Epoch 475/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9552 - val_loss: 0.1679 - val_accuracy: 0.9499\n",
      "Epoch 476/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9573 - val_loss: 0.1700 - val_accuracy: 0.9468\n",
      "Epoch 477/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9535 - val_loss: 0.1825 - val_accuracy: 0.9437\n",
      "Epoch 478/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9586 - val_loss: 0.1689 - val_accuracy: 0.9491\n",
      "Epoch 479/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9529 - val_loss: 0.2027 - val_accuracy: 0.9499\n",
      "Epoch 480/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9559 - val_loss: 0.1697 - val_accuracy: 0.9484\n",
      "Epoch 481/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9516 - val_loss: 0.1777 - val_accuracy: 0.9429\n",
      "Epoch 482/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.94 - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9504 - val_loss: 0.1727 - val_accuracy: 0.9444\n",
      "Epoch 483/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9528 - val_loss: 0.1695 - val_accuracy: 0.9460\n",
      "Epoch 484/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9540 - val_loss: 0.1556 - val_accuracy: 0.9507\n",
      "Epoch 485/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9533 - val_loss: 0.1779 - val_accuracy: 0.9499\n",
      "Epoch 486/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9607 - val_loss: 0.1596 - val_accuracy: 0.9499\n",
      "Epoch 487/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9509 - val_loss: 0.1559 - val_accuracy: 0.9484\n",
      "Epoch 488/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9551 - val_loss: 0.1655 - val_accuracy: 0.9476\n",
      "Epoch 489/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9560 - val_loss: 0.1790 - val_accuracy: 0.9476\n",
      "Epoch 490/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1424 - accuracy: 0.9546 - val_loss: 0.1703 - val_accuracy: 0.9468\n",
      "Epoch 491/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9577 - val_loss: 0.1653 - val_accuracy: 0.9499\n",
      "Epoch 492/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9627 - val_loss: 0.1937 - val_accuracy: 0.9484\n",
      "Epoch 493/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9518 - val_loss: 0.1755 - val_accuracy: 0.9476\n",
      "Epoch 494/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9538 - val_loss: 0.1889 - val_accuracy: 0.9452\n",
      "Epoch 495/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9596 - val_loss: 0.1718 - val_accuracy: 0.9460\n",
      "Epoch 496/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9573 - val_loss: 0.1727 - val_accuracy: 0.9444\n",
      "Epoch 497/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9577 - val_loss: 0.1815 - val_accuracy: 0.9429\n",
      "Epoch 498/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9526 - val_loss: 0.1687 - val_accuracy: 0.9476\n",
      "Epoch 499/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9575 - val_loss: 0.1619 - val_accuracy: 0.9484\n",
      "Epoch 500/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9533 - val_loss: 0.1719 - val_accuracy: 0.9507\n",
      "Epoch 501/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9544 - val_loss: 0.1599 - val_accuracy: 0.9484\n",
      "Epoch 502/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9472 - val_loss: 0.1746 - val_accuracy: 0.9484\n",
      "Epoch 503/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9551 - val_loss: 0.1718 - val_accuracy: 0.9491\n",
      "Epoch 504/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9564 - val_loss: 0.1764 - val_accuracy: 0.9421\n",
      "Epoch 505/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9557 - val_loss: 0.1632 - val_accuracy: 0.9476\n",
      "Epoch 506/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9571 - val_loss: 0.1801 - val_accuracy: 0.9499\n",
      "Epoch 507/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9553 - val_loss: 0.1748 - val_accuracy: 0.9499\n",
      "Epoch 508/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9565 - val_loss: 0.1706 - val_accuracy: 0.9499\n",
      "Epoch 509/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9569 - val_loss: 0.1802 - val_accuracy: 0.9452\n",
      "Epoch 510/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9499 - val_loss: 0.1626 - val_accuracy: 0.9507\n",
      "Epoch 511/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9576 - val_loss: 0.1674 - val_accuracy: 0.9491\n",
      "Epoch 512/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9543 - val_loss: 0.1625 - val_accuracy: 0.9468\n",
      "Epoch 513/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9561 - val_loss: 0.1715 - val_accuracy: 0.9491\n",
      "Epoch 514/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9526 - val_loss: 0.1659 - val_accuracy: 0.9491\n",
      "Epoch 515/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9582 - val_loss: 0.1783 - val_accuracy: 0.9437\n",
      "Epoch 516/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9506 - val_loss: 0.1604 - val_accuracy: 0.9491\n",
      "Epoch 517/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9542 - val_loss: 0.1640 - val_accuracy: 0.9484\n",
      "Epoch 518/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9564 - val_loss: 0.1604 - val_accuracy: 0.9491\n",
      "Epoch 519/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9522 - val_loss: 0.1675 - val_accuracy: 0.9484\n",
      "Epoch 520/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9546 - val_loss: 0.1734 - val_accuracy: 0.9452\n",
      "Epoch 521/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9504 - val_loss: 0.1762 - val_accuracy: 0.9460\n",
      "Epoch 522/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9610 - val_loss: 0.1643 - val_accuracy: 0.9491\n",
      "Epoch 523/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9554 - val_loss: 0.1654 - val_accuracy: 0.9491\n",
      "Epoch 524/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9537 - val_loss: 0.1690 - val_accuracy: 0.9491\n",
      "Epoch 525/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.9580 - val_loss: 0.1666 - val_accuracy: 0.9468\n",
      "Epoch 526/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9602 - val_loss: 0.1731 - val_accuracy: 0.9452\n",
      "Epoch 527/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9542 - val_loss: 0.1854 - val_accuracy: 0.9452\n",
      "Epoch 528/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9529 - val_loss: 0.1809 - val_accuracy: 0.9491\n",
      "Epoch 529/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9562 - val_loss: 0.1763 - val_accuracy: 0.9429\n",
      "Epoch 530/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9554 - val_loss: 0.1736 - val_accuracy: 0.9421\n",
      "Epoch 531/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9489 - val_loss: 0.1687 - val_accuracy: 0.9491\n",
      "Epoch 532/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9537 - val_loss: 0.1669 - val_accuracy: 0.9452\n",
      "Epoch 533/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9525 - val_loss: 0.1618 - val_accuracy: 0.9507\n",
      "Epoch 534/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9528 - val_loss: 0.1621 - val_accuracy: 0.9484\n",
      "Epoch 535/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9539 - val_loss: 0.1651 - val_accuracy: 0.9484\n",
      "Epoch 536/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9498 - val_loss: 0.1766 - val_accuracy: 0.9444\n",
      "Epoch 537/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9488 - val_loss: 0.1739 - val_accuracy: 0.9444\n",
      "Epoch 538/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9580 - val_loss: 0.1609 - val_accuracy: 0.9491\n",
      "Epoch 539/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9576 - val_loss: 0.1850 - val_accuracy: 0.9499\n",
      "Epoch 540/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9513 - val_loss: 0.1607 - val_accuracy: 0.9507\n",
      "Epoch 541/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9521 - val_loss: 0.1717 - val_accuracy: 0.9499\n",
      "Epoch 542/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9617 - val_loss: 0.1831 - val_accuracy: 0.9444\n",
      "Epoch 543/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9508 - val_loss: 0.1815 - val_accuracy: 0.9405\n",
      "Epoch 544/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1449 - accuracy: 0.9495 - val_loss: 0.1715 - val_accuracy: 0.9484\n",
      "Epoch 545/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9560 - val_loss: 0.1850 - val_accuracy: 0.9421\n",
      "Epoch 546/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9531 - val_loss: 0.1823 - val_accuracy: 0.9484\n",
      "Epoch 547/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9583 - val_loss: 0.1840 - val_accuracy: 0.9421\n",
      "Epoch 548/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9570 - val_loss: 0.1925 - val_accuracy: 0.9468\n",
      "Epoch 549/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9519 - val_loss: 0.1931 - val_accuracy: 0.9429\n",
      "Epoch 550/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9594 - val_loss: 0.1757 - val_accuracy: 0.9507\n",
      "Epoch 551/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9547 - val_loss: 0.1728 - val_accuracy: 0.9484\n",
      "Epoch 552/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9549 - val_loss: 0.1556 - val_accuracy: 0.9507\n",
      "Epoch 553/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9540 - val_loss: 0.1625 - val_accuracy: 0.9484\n",
      "Epoch 554/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9533 - val_loss: 0.1742 - val_accuracy: 0.9507\n",
      "Epoch 555/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9574 - val_loss: 0.1716 - val_accuracy: 0.9484\n",
      "Epoch 556/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9510 - val_loss: 0.1974 - val_accuracy: 0.9507\n",
      "Epoch 557/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9585 - val_loss: 0.1786 - val_accuracy: 0.9429\n",
      "Epoch 558/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9554 - val_loss: 0.1790 - val_accuracy: 0.9491\n",
      "Epoch 559/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9562 - val_loss: 0.2024 - val_accuracy: 0.9499\n",
      "Epoch 560/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9596 - val_loss: 0.2174 - val_accuracy: 0.9382\n",
      "Epoch 561/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9586 - val_loss: 0.1851 - val_accuracy: 0.9421\n",
      "Epoch 562/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9564 - val_loss: 0.1748 - val_accuracy: 0.9484\n",
      "Epoch 563/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9593 - val_loss: 0.1999 - val_accuracy: 0.9382\n",
      "Epoch 564/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9608 - val_loss: 0.2143 - val_accuracy: 0.9491\n",
      "Epoch 565/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9568 - val_loss: 0.1813 - val_accuracy: 0.9484\n",
      "Epoch 566/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9525 - val_loss: 0.1692 - val_accuracy: 0.9468\n",
      "Epoch 567/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9613 - val_loss: 0.1698 - val_accuracy: 0.9468\n",
      "Epoch 568/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9582 - val_loss: 0.1978 - val_accuracy: 0.9476\n",
      "Epoch 569/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9573 - val_loss: 0.1970 - val_accuracy: 0.9413\n",
      "Epoch 570/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9496 - val_loss: 0.1706 - val_accuracy: 0.9460\n",
      "Epoch 571/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9501 - val_loss: 0.1783 - val_accuracy: 0.9452\n",
      "Epoch 572/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9564 - val_loss: 0.1649 - val_accuracy: 0.9476\n",
      "Epoch 573/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9528 - val_loss: 0.1647 - val_accuracy: 0.9484\n",
      "Epoch 574/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9609 - val_loss: 0.1754 - val_accuracy: 0.9460\n",
      "Epoch 575/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9590 - val_loss: 0.1714 - val_accuracy: 0.9468\n",
      "Epoch 576/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9604 - val_loss: 0.1876 - val_accuracy: 0.9491\n",
      "Epoch 577/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9585 - val_loss: 0.1940 - val_accuracy: 0.9405\n",
      "Epoch 578/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9532 - val_loss: 0.2132 - val_accuracy: 0.9382\n",
      "Epoch 579/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9528 - val_loss: 0.1793 - val_accuracy: 0.9444\n",
      "Epoch 580/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9557 - val_loss: 0.1741 - val_accuracy: 0.9491\n",
      "Epoch 581/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9585 - val_loss: 0.1822 - val_accuracy: 0.9484\n",
      "Epoch 582/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9602 - val_loss: 0.1934 - val_accuracy: 0.9460\n",
      "Epoch 583/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9586 - val_loss: 0.1689 - val_accuracy: 0.9491\n",
      "Epoch 584/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9514 - val_loss: 0.1854 - val_accuracy: 0.9421\n",
      "Epoch 585/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9565 - val_loss: 0.1737 - val_accuracy: 0.9484\n",
      "Epoch 586/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9564 - val_loss: 0.1791 - val_accuracy: 0.9491\n",
      "Epoch 587/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9585 - val_loss: 0.1867 - val_accuracy: 0.9452\n",
      "Epoch 588/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9505 - val_loss: 0.1767 - val_accuracy: 0.9452\n",
      "Epoch 589/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9559 - val_loss: 0.1841 - val_accuracy: 0.9421\n",
      "Epoch 590/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9560 - val_loss: 0.1648 - val_accuracy: 0.9460\n",
      "Epoch 591/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9582 - val_loss: 0.2114 - val_accuracy: 0.9437\n",
      "Epoch 592/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9557 - val_loss: 0.1898 - val_accuracy: 0.9491\n",
      "Epoch 593/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9582 - val_loss: 0.1678 - val_accuracy: 0.9468\n",
      "Epoch 594/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9551 - val_loss: 0.1861 - val_accuracy: 0.9405\n",
      "Epoch 595/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9510 - val_loss: 0.1691 - val_accuracy: 0.9499\n",
      "Epoch 596/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9546 - val_loss: 0.1755 - val_accuracy: 0.9460\n",
      "Epoch 597/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9554 - val_loss: 0.1707 - val_accuracy: 0.9484\n",
      "Epoch 598/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9573 - val_loss: 0.1689 - val_accuracy: 0.9484\n",
      "Epoch 599/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9578 - val_loss: 0.1655 - val_accuracy: 0.9491\n",
      "Epoch 600/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9505 - val_loss: 0.1816 - val_accuracy: 0.9437\n",
      "Epoch 601/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9514 - val_loss: 0.1697 - val_accuracy: 0.9460\n",
      "Epoch 602/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9575 - val_loss: 0.1918 - val_accuracy: 0.9444\n",
      "Epoch 603/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9559 - val_loss: 0.1755 - val_accuracy: 0.9460\n",
      "Epoch 604/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9614 - val_loss: 0.1751 - val_accuracy: 0.9468\n",
      "Epoch 605/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9548 - val_loss: 0.1931 - val_accuracy: 0.9437\n",
      "Epoch 606/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9563 - val_loss: 0.1820 - val_accuracy: 0.9460\n",
      "Epoch 607/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9584 - val_loss: 0.2068 - val_accuracy: 0.9484\n",
      "Epoch 608/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9585 - val_loss: 0.1750 - val_accuracy: 0.9429\n",
      "Epoch 609/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9604 - val_loss: 0.1757 - val_accuracy: 0.9460\n",
      "Epoch 610/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9528 - val_loss: 0.1979 - val_accuracy: 0.9366\n",
      "Epoch 611/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9530 - val_loss: 0.1763 - val_accuracy: 0.9468\n",
      "Epoch 612/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9583 - val_loss: 0.1801 - val_accuracy: 0.9468\n",
      "Epoch 613/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9563 - val_loss: 0.1885 - val_accuracy: 0.9429\n",
      "Epoch 614/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.9587 - val_loss: 0.1785 - val_accuracy: 0.9484\n",
      "Epoch 615/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9575 - val_loss: 0.1766 - val_accuracy: 0.9499\n",
      "Epoch 616/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9539 - val_loss: 0.1840 - val_accuracy: 0.9484\n",
      "Epoch 617/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9564 - val_loss: 0.1880 - val_accuracy: 0.9429\n",
      "Epoch 618/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9560 - val_loss: 0.1997 - val_accuracy: 0.9405\n",
      "Epoch 619/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9478 - val_loss: 0.1944 - val_accuracy: 0.9413\n",
      "Epoch 620/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9561 - val_loss: 0.2009 - val_accuracy: 0.9484\n",
      "Epoch 621/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9595 - val_loss: 0.1778 - val_accuracy: 0.9476\n",
      "Epoch 622/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9646 - val_loss: 0.1819 - val_accuracy: 0.9460\n",
      "Epoch 623/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9589 - val_loss: 0.2123 - val_accuracy: 0.9429\n",
      "Epoch 624/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9590 - val_loss: 0.1949 - val_accuracy: 0.9468\n",
      "Epoch 625/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9645 - val_loss: 0.1968 - val_accuracy: 0.9452\n",
      "Epoch 626/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9508 - val_loss: 0.1907 - val_accuracy: 0.9484\n",
      "Epoch 627/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9633 - val_loss: 0.2009 - val_accuracy: 0.9476\n",
      "Epoch 628/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9485 - val_loss: 0.1916 - val_accuracy: 0.9437\n",
      "Epoch 629/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9569 - val_loss: 0.2016 - val_accuracy: 0.9476\n",
      "Epoch 630/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9583 - val_loss: 0.1891 - val_accuracy: 0.9476\n",
      "Epoch 631/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9565 - val_loss: 0.1942 - val_accuracy: 0.9437\n",
      "Epoch 632/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9575 - val_loss: 0.1846 - val_accuracy: 0.9437\n",
      "Epoch 633/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9536 - val_loss: 0.1967 - val_accuracy: 0.9491\n",
      "Epoch 634/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9560 - val_loss: 0.2047 - val_accuracy: 0.9437\n",
      "Epoch 635/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9560 - val_loss: 0.1817 - val_accuracy: 0.9476\n",
      "Epoch 636/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9548 - val_loss: 0.1980 - val_accuracy: 0.9476\n",
      "Epoch 637/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9529 - val_loss: 0.1853 - val_accuracy: 0.9484\n",
      "Epoch 638/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9556 - val_loss: 0.1947 - val_accuracy: 0.9437\n",
      "Epoch 639/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9533 - val_loss: 0.1944 - val_accuracy: 0.9499\n",
      "Epoch 640/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9550 - val_loss: 0.2132 - val_accuracy: 0.9452\n",
      "Epoch 641/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9587 - val_loss: 0.2024 - val_accuracy: 0.9421\n",
      "Epoch 642/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9598 - val_loss: 0.2165 - val_accuracy: 0.9468\n",
      "Epoch 643/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9588 - val_loss: 0.2151 - val_accuracy: 0.9476\n",
      "Epoch 644/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9575 - val_loss: 0.2054 - val_accuracy: 0.9484\n",
      "Epoch 645/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9592 - val_loss: 0.2060 - val_accuracy: 0.9413\n",
      "Epoch 646/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9574 - val_loss: 0.2036 - val_accuracy: 0.9460\n",
      "Epoch 647/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9542 - val_loss: 0.1803 - val_accuracy: 0.9484\n",
      "Epoch 648/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9542 - val_loss: 0.1927 - val_accuracy: 0.9476\n",
      "Epoch 649/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9579 - val_loss: 0.2045 - val_accuracy: 0.9437\n",
      "Epoch 650/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9536 - val_loss: 0.2133 - val_accuracy: 0.9468\n",
      "Epoch 651/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9546 - val_loss: 0.2277 - val_accuracy: 0.9437\n",
      "Epoch 652/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9577 - val_loss: 0.2304 - val_accuracy: 0.9405\n",
      "Epoch 653/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9537 - val_loss: 0.1812 - val_accuracy: 0.9499\n",
      "Epoch 654/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9567 - val_loss: 0.1691 - val_accuracy: 0.9468\n",
      "Epoch 655/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9536 - val_loss: 0.1680 - val_accuracy: 0.9484\n",
      "Epoch 656/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9596 - val_loss: 0.2052 - val_accuracy: 0.9476\n",
      "Epoch 657/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9608 - val_loss: 0.2093 - val_accuracy: 0.9460\n",
      "Epoch 658/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1215 - accuracy: 0.9580 - val_loss: 0.2534 - val_accuracy: 0.9491\n",
      "Epoch 659/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9553 - val_loss: 0.2289 - val_accuracy: 0.9460\n",
      "Epoch 660/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9569 - val_loss: 0.2559 - val_accuracy: 0.9437\n",
      "Epoch 661/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9472 - val_loss: 0.2019 - val_accuracy: 0.9444\n",
      "Epoch 662/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9582 - val_loss: 0.2320 - val_accuracy: 0.9468\n",
      "Epoch 663/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9551 - val_loss: 0.2140 - val_accuracy: 0.9429\n",
      "Epoch 664/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.9581 - val_loss: 0.1785 - val_accuracy: 0.9491\n",
      "Epoch 665/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9571 - val_loss: 0.1991 - val_accuracy: 0.9421\n",
      "Epoch 666/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9506 - val_loss: 0.2115 - val_accuracy: 0.9444\n",
      "Epoch 667/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9576 - val_loss: 0.1960 - val_accuracy: 0.9452\n",
      "Epoch 668/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9534 - val_loss: 0.2107 - val_accuracy: 0.9437\n",
      "Epoch 669/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9530 - val_loss: 0.2203 - val_accuracy: 0.9405\n",
      "Epoch 670/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.9554 - val_loss: 0.2001 - val_accuracy: 0.9460\n",
      "Epoch 671/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9642 - val_loss: 0.2254 - val_accuracy: 0.9413\n",
      "Epoch 672/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9631 - val_loss: 0.2207 - val_accuracy: 0.9452\n",
      "Epoch 673/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9534 - val_loss: 0.2101 - val_accuracy: 0.9491\n",
      "Epoch 674/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9549 - val_loss: 0.2009 - val_accuracy: 0.9491\n",
      "Epoch 675/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9546 - val_loss: 0.2022 - val_accuracy: 0.9468\n",
      "Epoch 676/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9495 - val_loss: 0.2091 - val_accuracy: 0.9491\n",
      "Epoch 677/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9516 - val_loss: 0.2227 - val_accuracy: 0.9437\n",
      "Epoch 678/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9604 - val_loss: 0.1733 - val_accuracy: 0.9491\n",
      "Epoch 679/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9521 - val_loss: 0.1880 - val_accuracy: 0.9491\n",
      "Epoch 680/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9515 - val_loss: 0.2216 - val_accuracy: 0.9484\n",
      "Epoch 681/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9538 - val_loss: 0.2220 - val_accuracy: 0.9468\n",
      "Epoch 682/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9519 - val_loss: 0.2264 - val_accuracy: 0.9491\n",
      "Epoch 683/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9612 - val_loss: 0.2249 - val_accuracy: 0.9468\n",
      "Epoch 684/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9556 - val_loss: 0.2171 - val_accuracy: 0.9468\n",
      "Epoch 685/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9472 - val_loss: 0.2122 - val_accuracy: 0.9460\n",
      "Epoch 686/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9565 - val_loss: 0.2032 - val_accuracy: 0.9460\n",
      "Epoch 687/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9579 - val_loss: 0.1972 - val_accuracy: 0.9476\n",
      "Epoch 688/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9553 - val_loss: 0.1986 - val_accuracy: 0.9491\n",
      "Epoch 689/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9533 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
      "Epoch 690/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9523 - val_loss: 0.2128 - val_accuracy: 0.9405\n",
      "Epoch 691/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9532 - val_loss: 0.2114 - val_accuracy: 0.9444\n",
      "Epoch 692/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9598 - val_loss: 0.1995 - val_accuracy: 0.9460\n",
      "Epoch 693/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9552 - val_loss: 0.2002 - val_accuracy: 0.9476\n",
      "Epoch 694/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9588 - val_loss: 0.1902 - val_accuracy: 0.9476\n",
      "Epoch 695/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9631 - val_loss: 0.1932 - val_accuracy: 0.9468\n",
      "Epoch 696/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9590 - val_loss: 0.2027 - val_accuracy: 0.9429\n",
      "Epoch 697/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9565 - val_loss: 0.2039 - val_accuracy: 0.9460\n",
      "Epoch 698/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9559 - val_loss: 0.2024 - val_accuracy: 0.9484\n",
      "Epoch 699/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.9547 - val_loss: 0.2313 - val_accuracy: 0.9491\n",
      "Epoch 700/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.9541 - val_loss: 0.1923 - val_accuracy: 0.9484\n",
      "Epoch 701/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9586 - val_loss: 0.1972 - val_accuracy: 0.9499\n",
      "Epoch 702/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9560 - val_loss: 0.2194 - val_accuracy: 0.9491\n",
      "Epoch 703/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9558 - val_loss: 0.2291 - val_accuracy: 0.9460\n",
      "Epoch 704/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9615 - val_loss: 0.2423 - val_accuracy: 0.9413\n",
      "Epoch 705/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9626 - val_loss: 0.2333 - val_accuracy: 0.9413\n",
      "Epoch 706/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9503 - val_loss: 0.1833 - val_accuracy: 0.9476\n",
      "Epoch 707/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9528 - val_loss: 0.1902 - val_accuracy: 0.9484\n",
      "Epoch 708/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9578 - val_loss: 0.2032 - val_accuracy: 0.9476\n",
      "Epoch 709/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9544 - val_loss: 0.2297 - val_accuracy: 0.9460\n",
      "Epoch 710/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9499 - val_loss: 0.2362 - val_accuracy: 0.9335\n",
      "Epoch 711/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9518 - val_loss: 0.1873 - val_accuracy: 0.9444\n",
      "Epoch 712/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9580 - val_loss: 0.1910 - val_accuracy: 0.9444\n",
      "Epoch 713/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9555 - val_loss: 0.1783 - val_accuracy: 0.9491\n",
      "Epoch 714/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9602 - val_loss: 0.2082 - val_accuracy: 0.9460\n",
      "Epoch 715/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9579 - val_loss: 0.2141 - val_accuracy: 0.9405\n",
      "Epoch 716/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9508 - val_loss: 0.2440 - val_accuracy: 0.9484\n",
      "Epoch 717/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9554 - val_loss: 0.2172 - val_accuracy: 0.9484\n",
      "Epoch 718/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9568 - val_loss: 0.2265 - val_accuracy: 0.9484\n",
      "Epoch 719/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9597 - val_loss: 0.2055 - val_accuracy: 0.9476\n",
      "Epoch 720/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9550 - val_loss: 0.2026 - val_accuracy: 0.9460\n",
      "Epoch 721/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9525 - val_loss: 0.1807 - val_accuracy: 0.9476\n",
      "Epoch 722/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9576 - val_loss: 0.2024 - val_accuracy: 0.9468\n",
      "Epoch 723/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9584 - val_loss: 0.2128 - val_accuracy: 0.9437\n",
      "Epoch 724/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9577 - val_loss: 0.2165 - val_accuracy: 0.9421\n",
      "Epoch 725/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9559 - val_loss: 0.2384 - val_accuracy: 0.9452\n",
      "Epoch 726/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9590 - val_loss: 0.2156 - val_accuracy: 0.9429\n",
      "Epoch 727/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9579 - val_loss: 0.2055 - val_accuracy: 0.9476\n",
      "Epoch 728/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9602 - val_loss: 0.2071 - val_accuracy: 0.9429\n",
      "Epoch 729/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9558 - val_loss: 0.2070 - val_accuracy: 0.9484\n",
      "Epoch 730/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9579 - val_loss: 0.1927 - val_accuracy: 0.9476\n",
      "Epoch 731/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9559 - val_loss: 0.2179 - val_accuracy: 0.9444\n",
      "Epoch 732/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9564 - val_loss: 0.2448 - val_accuracy: 0.9390\n",
      "Epoch 733/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9566 - val_loss: 0.2112 - val_accuracy: 0.9460\n",
      "Epoch 734/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9599 - val_loss: 0.2362 - val_accuracy: 0.9405\n",
      "Epoch 735/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9535 - val_loss: 0.2048 - val_accuracy: 0.9484\n",
      "Epoch 736/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9583 - val_loss: 0.2274 - val_accuracy: 0.9437\n",
      "Epoch 737/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9514 - val_loss: 0.2120 - val_accuracy: 0.9452\n",
      "Epoch 738/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9534 - val_loss: 0.2152 - val_accuracy: 0.9397\n",
      "Epoch 739/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9554 - val_loss: 0.2177 - val_accuracy: 0.9452\n",
      "Epoch 740/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9547 - val_loss: 0.2172 - val_accuracy: 0.9476\n",
      "Epoch 741/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9531 - val_loss: 0.2147 - val_accuracy: 0.9499\n",
      "Epoch 742/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9539 - val_loss: 0.2126 - val_accuracy: 0.9468\n",
      "Epoch 743/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9579 - val_loss: 0.2230 - val_accuracy: 0.9484\n",
      "Epoch 744/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9601 - val_loss: 0.2134 - val_accuracy: 0.9444\n",
      "Epoch 745/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9593 - val_loss: 0.2212 - val_accuracy: 0.9437\n",
      "Epoch 746/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9596 - val_loss: 0.2138 - val_accuracy: 0.9460\n",
      "Epoch 747/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9574 - val_loss: 0.2752 - val_accuracy: 0.9437\n",
      "Epoch 748/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9568 - val_loss: 0.2543 - val_accuracy: 0.9476\n",
      "Epoch 749/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9566 - val_loss: 0.2318 - val_accuracy: 0.9429\n",
      "Epoch 750/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9597 - val_loss: 0.2156 - val_accuracy: 0.9437\n",
      "Epoch 751/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9599 - val_loss: 0.2377 - val_accuracy: 0.9413\n",
      "Epoch 752/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9572 - val_loss: 0.2463 - val_accuracy: 0.9444\n",
      "Epoch 753/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9587 - val_loss: 0.2144 - val_accuracy: 0.9429\n",
      "Epoch 754/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9587 - val_loss: 0.1995 - val_accuracy: 0.9468\n",
      "Epoch 755/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9574 - val_loss: 0.2146 - val_accuracy: 0.9484\n",
      "Epoch 756/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9560 - val_loss: 0.2369 - val_accuracy: 0.9452\n",
      "Epoch 757/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9574 - val_loss: 0.2089 - val_accuracy: 0.9476\n",
      "Epoch 758/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9610 - val_loss: 0.2386 - val_accuracy: 0.9452\n",
      "Epoch 759/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9587 - val_loss: 0.2168 - val_accuracy: 0.9437\n",
      "Epoch 760/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9574 - val_loss: 0.1885 - val_accuracy: 0.9460\n",
      "Epoch 761/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9510 - val_loss: 0.2515 - val_accuracy: 0.9491\n",
      "Epoch 762/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.9299 - val_loss: 0.1948 - val_accuracy: 0.9405\n",
      "Epoch 763/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9529 - val_loss: 0.1722 - val_accuracy: 0.9491\n",
      "Epoch 764/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9460 - val_loss: 0.1759 - val_accuracy: 0.9444\n",
      "Epoch 765/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9515 - val_loss: 0.1775 - val_accuracy: 0.9429\n",
      "Epoch 766/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9513 - val_loss: 0.1688 - val_accuracy: 0.9484\n",
      "Epoch 767/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9558 - val_loss: 0.1907 - val_accuracy: 0.9327\n",
      "Epoch 768/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9535 - val_loss: 0.1725 - val_accuracy: 0.9452\n",
      "Epoch 769/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9528 - val_loss: 0.1701 - val_accuracy: 0.9484\n",
      "Epoch 770/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9483 - val_loss: 0.1685 - val_accuracy: 0.9460\n",
      "Epoch 771/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9512 - val_loss: 0.1707 - val_accuracy: 0.9476\n",
      "Epoch 772/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9576 - val_loss: 0.1888 - val_accuracy: 0.9444\n",
      "Epoch 773/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9563 - val_loss: 0.1850 - val_accuracy: 0.9484\n",
      "Epoch 774/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9620 - val_loss: 0.1896 - val_accuracy: 0.9343\n",
      "Epoch 775/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9506 - val_loss: 0.1846 - val_accuracy: 0.9499\n",
      "Epoch 776/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9540 - val_loss: 0.1801 - val_accuracy: 0.9444\n",
      "Epoch 777/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9536 - val_loss: 0.1776 - val_accuracy: 0.9468\n",
      "Epoch 778/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9536 - val_loss: 0.1905 - val_accuracy: 0.9405\n",
      "Epoch 779/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9509 - val_loss: 0.1946 - val_accuracy: 0.9499\n",
      "Epoch 780/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9520 - val_loss: 0.1640 - val_accuracy: 0.9476\n",
      "Epoch 781/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9635 - val_loss: 0.1830 - val_accuracy: 0.9366\n",
      "Epoch 782/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9559 - val_loss: 0.1865 - val_accuracy: 0.9405\n",
      "Epoch 783/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9553 - val_loss: 0.1739 - val_accuracy: 0.9460\n",
      "Epoch 784/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9556 - val_loss: 0.1763 - val_accuracy: 0.9460\n",
      "Epoch 785/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9523 - val_loss: 0.1737 - val_accuracy: 0.9499\n",
      "Epoch 786/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9566 - val_loss: 0.1754 - val_accuracy: 0.9468\n",
      "Epoch 787/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9499 - val_loss: 0.1617 - val_accuracy: 0.9499\n",
      "Epoch 788/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9560 - val_loss: 0.1757 - val_accuracy: 0.9484\n",
      "Epoch 789/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9572 - val_loss: 0.1774 - val_accuracy: 0.9437\n",
      "Epoch 790/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9539 - val_loss: 0.1659 - val_accuracy: 0.9491\n",
      "Epoch 791/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9517 - val_loss: 0.1802 - val_accuracy: 0.9468\n",
      "Epoch 792/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9555 - val_loss: 0.1718 - val_accuracy: 0.9476\n",
      "Epoch 793/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9545 - val_loss: 0.1767 - val_accuracy: 0.9484\n",
      "Epoch 794/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9561 - val_loss: 0.1750 - val_accuracy: 0.9444\n",
      "Epoch 795/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9580 - val_loss: 0.1696 - val_accuracy: 0.9468\n",
      "Epoch 796/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9567 - val_loss: 0.2003 - val_accuracy: 0.9484\n",
      "Epoch 797/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9537 - val_loss: 0.1752 - val_accuracy: 0.9452\n",
      "Epoch 798/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9555 - val_loss: 0.1749 - val_accuracy: 0.9444\n",
      "Epoch 799/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9514 - val_loss: 0.1811 - val_accuracy: 0.9476\n",
      "Epoch 800/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9569 - val_loss: 0.1963 - val_accuracy: 0.9288\n",
      "Epoch 801/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9571 - val_loss: 0.1917 - val_accuracy: 0.9484\n",
      "Epoch 802/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9494 - val_loss: 0.1793 - val_accuracy: 0.9429\n",
      "Epoch 803/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9572 - val_loss: 0.1726 - val_accuracy: 0.9460\n",
      "Epoch 804/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9542 - val_loss: 0.1828 - val_accuracy: 0.9437\n",
      "Epoch 805/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9536 - val_loss: 0.1849 - val_accuracy: 0.9397\n",
      "Epoch 806/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9555 - val_loss: 0.1816 - val_accuracy: 0.9468\n",
      "Epoch 807/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9561 - val_loss: 0.1773 - val_accuracy: 0.9491\n",
      "Epoch 808/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9530 - val_loss: 0.1805 - val_accuracy: 0.9484\n",
      "Epoch 809/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9520 - val_loss: 0.2184 - val_accuracy: 0.9499\n",
      "Epoch 810/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9545 - val_loss: 0.1998 - val_accuracy: 0.9468\n",
      "Epoch 811/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9553 - val_loss: 0.1635 - val_accuracy: 0.9476\n",
      "Epoch 812/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9590 - val_loss: 0.1831 - val_accuracy: 0.9437\n",
      "Epoch 813/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9573 - val_loss: 0.1820 - val_accuracy: 0.9484\n",
      "Epoch 814/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9509 - val_loss: 0.1659 - val_accuracy: 0.9468\n",
      "Epoch 815/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9606 - val_loss: 0.1731 - val_accuracy: 0.9484\n",
      "Epoch 816/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9564 - val_loss: 0.1784 - val_accuracy: 0.9476\n",
      "Epoch 817/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9521 - val_loss: 0.1911 - val_accuracy: 0.9437\n",
      "Epoch 818/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9527 - val_loss: 0.1751 - val_accuracy: 0.9491\n",
      "Epoch 819/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9537 - val_loss: 0.1659 - val_accuracy: 0.9499\n",
      "Epoch 820/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9575 - val_loss: 0.1643 - val_accuracy: 0.9507\n",
      "Epoch 821/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9514 - val_loss: 0.1614 - val_accuracy: 0.9507\n",
      "Epoch 822/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9603 - val_loss: 0.1593 - val_accuracy: 0.9507\n",
      "Epoch 823/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9542 - val_loss: 0.1572 - val_accuracy: 0.9499\n",
      "Epoch 824/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9567 - val_loss: 0.1656 - val_accuracy: 0.9452\n",
      "Epoch 825/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9587 - val_loss: 0.1636 - val_accuracy: 0.9460\n",
      "Epoch 826/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9501 - val_loss: 0.1666 - val_accuracy: 0.9444\n",
      "Epoch 827/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9567 - val_loss: 0.1681 - val_accuracy: 0.9421\n",
      "Epoch 828/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9518 - val_loss: 0.1611 - val_accuracy: 0.9491\n",
      "Epoch 829/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9522 - val_loss: 0.1696 - val_accuracy: 0.9484\n",
      "Epoch 830/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9512 - val_loss: 0.1705 - val_accuracy: 0.9429\n",
      "Epoch 831/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9500 - val_loss: 0.1732 - val_accuracy: 0.9507\n",
      "Epoch 832/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9584 - val_loss: 0.1651 - val_accuracy: 0.9499\n",
      "Epoch 833/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9459 - val_loss: 0.1686 - val_accuracy: 0.9468\n",
      "Epoch 834/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9526 - val_loss: 0.1669 - val_accuracy: 0.9491\n",
      "Epoch 835/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9599 - val_loss: 0.1700 - val_accuracy: 0.9444\n",
      "Epoch 836/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.9556 - val_loss: 0.1637 - val_accuracy: 0.9484\n",
      "Epoch 837/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9578 - val_loss: 0.1805 - val_accuracy: 0.9397\n",
      "Epoch 838/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9566 - val_loss: 0.1598 - val_accuracy: 0.9484\n",
      "Epoch 839/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9548 - val_loss: 0.1572 - val_accuracy: 0.9491\n",
      "Epoch 840/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9570 - val_loss: 0.1762 - val_accuracy: 0.9397\n",
      "Epoch 841/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9525 - val_loss: 0.1629 - val_accuracy: 0.9460\n",
      "Epoch 842/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9536 - val_loss: 0.1617 - val_accuracy: 0.9484\n",
      "Epoch 843/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9591 - val_loss: 0.1813 - val_accuracy: 0.9421\n",
      "Epoch 844/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9556 - val_loss: 0.1721 - val_accuracy: 0.9476\n",
      "Epoch 845/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9603 - val_loss: 0.1696 - val_accuracy: 0.9460\n",
      "Epoch 846/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9589 - val_loss: 0.1692 - val_accuracy: 0.9507\n",
      "Epoch 847/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9508 - val_loss: 0.1657 - val_accuracy: 0.9468\n",
      "Epoch 848/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9598 - val_loss: 0.1778 - val_accuracy: 0.9444\n",
      "Epoch 849/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9550 - val_loss: 0.1863 - val_accuracy: 0.9444\n",
      "Epoch 850/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9584 - val_loss: 0.1800 - val_accuracy: 0.9460\n",
      "Epoch 851/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9598 - val_loss: 0.1813 - val_accuracy: 0.9491\n",
      "Epoch 852/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9537 - val_loss: 0.1779 - val_accuracy: 0.9452\n",
      "Epoch 853/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9553 - val_loss: 0.1747 - val_accuracy: 0.9437\n",
      "Epoch 854/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9462 - val_loss: 0.1624 - val_accuracy: 0.9507\n",
      "Epoch 855/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9599 - val_loss: 0.1714 - val_accuracy: 0.9484\n",
      "Epoch 856/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9548 - val_loss: 0.1662 - val_accuracy: 0.9507\n",
      "Epoch 857/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9542 - val_loss: 0.1749 - val_accuracy: 0.9437\n",
      "Epoch 858/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9559 - val_loss: 0.1762 - val_accuracy: 0.9499\n",
      "Epoch 859/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9511 - val_loss: 0.1623 - val_accuracy: 0.9499\n",
      "Epoch 860/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9574 - val_loss: 0.1768 - val_accuracy: 0.9499\n",
      "Epoch 861/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9624 - val_loss: 0.1773 - val_accuracy: 0.9437\n",
      "Epoch 862/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9599 - val_loss: 0.1784 - val_accuracy: 0.9452\n",
      "Epoch 863/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9570 - val_loss: 0.1679 - val_accuracy: 0.9460\n",
      "Epoch 864/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9589 - val_loss: 0.1741 - val_accuracy: 0.9476\n",
      "Epoch 865/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9571 - val_loss: 0.1903 - val_accuracy: 0.9468\n",
      "Epoch 866/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9602 - val_loss: 0.1801 - val_accuracy: 0.9499\n",
      "Epoch 867/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9568 - val_loss: 0.1821 - val_accuracy: 0.9452\n",
      "Epoch 868/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9506 - val_loss: 0.1758 - val_accuracy: 0.9499\n",
      "Epoch 869/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9571 - val_loss: 0.1925 - val_accuracy: 0.9499\n",
      "Epoch 870/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9550 - val_loss: 0.1785 - val_accuracy: 0.9444\n",
      "Epoch 871/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9530 - val_loss: 0.1691 - val_accuracy: 0.9491\n",
      "Epoch 872/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9533 - val_loss: 0.1734 - val_accuracy: 0.9484\n",
      "Epoch 873/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9524 - val_loss: 0.1694 - val_accuracy: 0.9484\n",
      "Epoch 874/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9561 - val_loss: 0.1935 - val_accuracy: 0.9405\n",
      "Epoch 875/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9569 - val_loss: 0.1968 - val_accuracy: 0.9437\n",
      "Epoch 876/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9495 - val_loss: 0.1692 - val_accuracy: 0.9476\n",
      "Epoch 877/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9571 - val_loss: 0.1896 - val_accuracy: 0.9429\n",
      "Epoch 878/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9500 - val_loss: 0.1682 - val_accuracy: 0.9468\n",
      "Epoch 879/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9553 - val_loss: 0.1889 - val_accuracy: 0.9452\n",
      "Epoch 880/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9549 - val_loss: 0.1789 - val_accuracy: 0.9452\n",
      "Epoch 881/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9537 - val_loss: 0.1774 - val_accuracy: 0.9499\n",
      "Epoch 882/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9579 - val_loss: 0.1886 - val_accuracy: 0.9468\n",
      "Epoch 883/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9566 - val_loss: 0.1690 - val_accuracy: 0.9460\n",
      "Epoch 884/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9571 - val_loss: 0.1836 - val_accuracy: 0.9507\n",
      "Epoch 885/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9583 - val_loss: 0.1855 - val_accuracy: 0.9460\n",
      "Epoch 886/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9567 - val_loss: 0.1714 - val_accuracy: 0.9460\n",
      "Epoch 887/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9525 - val_loss: 0.1726 - val_accuracy: 0.9476\n",
      "Epoch 888/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9542 - val_loss: 0.2079 - val_accuracy: 0.9437\n",
      "Epoch 889/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9524 - val_loss: 0.1849 - val_accuracy: 0.9499\n",
      "Epoch 890/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9579 - val_loss: 0.1820 - val_accuracy: 0.9452\n",
      "Epoch 891/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.9500 - val_loss: 0.1726 - val_accuracy: 0.9476\n",
      "Epoch 892/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9567 - val_loss: 0.1830 - val_accuracy: 0.9484\n",
      "Epoch 893/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9536 - val_loss: 0.1845 - val_accuracy: 0.9468\n",
      "Epoch 894/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9573 - val_loss: 0.1898 - val_accuracy: 0.9499\n",
      "Epoch 895/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9532 - val_loss: 0.1966 - val_accuracy: 0.9421\n",
      "Epoch 896/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9553 - val_loss: 0.1852 - val_accuracy: 0.9437\n",
      "Epoch 897/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9580 - val_loss: 0.1770 - val_accuracy: 0.9499\n",
      "Epoch 898/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9517 - val_loss: 0.1752 - val_accuracy: 0.9468\n",
      "Epoch 899/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9552 - val_loss: 0.1746 - val_accuracy: 0.9452\n",
      "Epoch 900/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9615 - val_loss: 0.1945 - val_accuracy: 0.9460\n",
      "Epoch 901/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9574 - val_loss: 0.2201 - val_accuracy: 0.9452\n",
      "Epoch 902/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.9622 - val_loss: 0.1890 - val_accuracy: 0.9499\n",
      "Epoch 903/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9515 - val_loss: 0.1889 - val_accuracy: 0.9444\n",
      "Epoch 904/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9575 - val_loss: 0.1804 - val_accuracy: 0.9491\n",
      "Epoch 905/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9517 - val_loss: 0.2206 - val_accuracy: 0.9484\n",
      "Epoch 906/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9590 - val_loss: 0.1792 - val_accuracy: 0.9484\n",
      "Epoch 907/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9581 - val_loss: 0.2029 - val_accuracy: 0.9460\n",
      "Epoch 908/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9575 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 909/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9618 - val_loss: 0.2032 - val_accuracy: 0.9468\n",
      "Epoch 910/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9529 - val_loss: 0.1922 - val_accuracy: 0.9429\n",
      "Epoch 911/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9540 - val_loss: 0.2056 - val_accuracy: 0.9476\n",
      "Epoch 912/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9579 - val_loss: 0.1757 - val_accuracy: 0.9429\n",
      "Epoch 913/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9606 - val_loss: 0.1787 - val_accuracy: 0.9484\n",
      "Epoch 914/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9579 - val_loss: 0.2212 - val_accuracy: 0.9476\n",
      "Epoch 915/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9543 - val_loss: 0.1933 - val_accuracy: 0.9444\n",
      "Epoch 916/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9644 - val_loss: 0.1890 - val_accuracy: 0.9429\n",
      "Epoch 917/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1213 - accuracy: 0.9599 - val_loss: 0.2039 - val_accuracy: 0.9444\n",
      "Epoch 918/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9645 - val_loss: 0.1689 - val_accuracy: 0.9468\n",
      "Epoch 919/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9555 - val_loss: 0.1763 - val_accuracy: 0.9429\n",
      "Epoch 920/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9601 - val_loss: 0.1878 - val_accuracy: 0.9437\n",
      "Epoch 921/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9596 - val_loss: 0.1967 - val_accuracy: 0.9288\n",
      "Epoch 922/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9508 - val_loss: 0.1722 - val_accuracy: 0.9468\n",
      "Epoch 923/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9557 - val_loss: 0.2081 - val_accuracy: 0.9468\n",
      "Epoch 924/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9549 - val_loss: 0.1985 - val_accuracy: 0.9507\n",
      "Epoch 925/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9557 - val_loss: 0.2053 - val_accuracy: 0.9264\n",
      "Epoch 926/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.9559 - val_loss: 0.1973 - val_accuracy: 0.9437\n",
      "Epoch 927/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9599 - val_loss: 0.1878 - val_accuracy: 0.9460\n",
      "Epoch 928/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9557 - val_loss: 0.2016 - val_accuracy: 0.9437\n",
      "Epoch 929/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9541 - val_loss: 0.1976 - val_accuracy: 0.9397\n",
      "Epoch 930/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9580 - val_loss: 0.1845 - val_accuracy: 0.9397\n",
      "Epoch 931/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9505 - val_loss: 0.1848 - val_accuracy: 0.9468\n",
      "Epoch 932/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9541 - val_loss: 0.1899 - val_accuracy: 0.9460\n",
      "Epoch 933/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9496 - val_loss: 0.1766 - val_accuracy: 0.9484\n",
      "Epoch 934/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.9563 - val_loss: 0.1834 - val_accuracy: 0.9476\n",
      "Epoch 935/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9540 - val_loss: 0.2048 - val_accuracy: 0.9405\n",
      "Epoch 936/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9569 - val_loss: 0.1900 - val_accuracy: 0.9484\n",
      "Epoch 937/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9564 - val_loss: 0.2068 - val_accuracy: 0.9484\n",
      "Epoch 938/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9610 - val_loss: 0.2201 - val_accuracy: 0.9429\n",
      "Epoch 939/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9558 - val_loss: 0.1992 - val_accuracy: 0.9468\n",
      "Epoch 940/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9619 - val_loss: 0.2189 - val_accuracy: 0.9437\n",
      "Epoch 941/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9552 - val_loss: 0.1850 - val_accuracy: 0.9421\n",
      "Epoch 942/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9611 - val_loss: 0.1955 - val_accuracy: 0.9452\n",
      "Epoch 943/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9584 - val_loss: 0.2014 - val_accuracy: 0.9437\n",
      "Epoch 944/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9560 - val_loss: 0.2285 - val_accuracy: 0.9452\n",
      "Epoch 945/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9562 - val_loss: 0.2026 - val_accuracy: 0.9444\n",
      "Epoch 946/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9592 - val_loss: 0.2334 - val_accuracy: 0.9421\n",
      "Epoch 947/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9539 - val_loss: 0.1956 - val_accuracy: 0.9476\n",
      "Epoch 948/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9571 - val_loss: 0.1955 - val_accuracy: 0.9468\n",
      "Epoch 949/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9592 - val_loss: 0.2013 - val_accuracy: 0.9437\n",
      "Epoch 950/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9573 - val_loss: 0.2510 - val_accuracy: 0.9311\n",
      "Epoch 951/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9550 - val_loss: 0.2067 - val_accuracy: 0.9452\n",
      "Epoch 952/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9581 - val_loss: 0.1959 - val_accuracy: 0.9452\n",
      "Epoch 953/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9632 - val_loss: 0.2161 - val_accuracy: 0.9452\n",
      "Epoch 954/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9582 - val_loss: 0.2149 - val_accuracy: 0.9437\n",
      "Epoch 955/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9563 - val_loss: 0.1958 - val_accuracy: 0.9468\n",
      "Epoch 956/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9494 - val_loss: 0.2403 - val_accuracy: 0.9437\n",
      "Epoch 957/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9576 - val_loss: 0.2368 - val_accuracy: 0.9444\n",
      "Epoch 958/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9511 - val_loss: 0.1798 - val_accuracy: 0.9484\n",
      "Epoch 959/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.9520 - val_loss: 0.1940 - val_accuracy: 0.9460\n",
      "Epoch 960/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9587 - val_loss: 0.1943 - val_accuracy: 0.9491\n",
      "Epoch 961/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9529 - val_loss: 0.2215 - val_accuracy: 0.9366\n",
      "Epoch 962/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9593 - val_loss: 0.1956 - val_accuracy: 0.9437\n",
      "Epoch 963/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9543 - val_loss: 0.1969 - val_accuracy: 0.9429\n",
      "Epoch 964/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9537 - val_loss: 0.1977 - val_accuracy: 0.9476\n",
      "Epoch 965/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9561 - val_loss: 0.1901 - val_accuracy: 0.9421\n",
      "Epoch 966/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9586 - val_loss: 0.2407 - val_accuracy: 0.9374\n",
      "Epoch 967/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9521 - val_loss: 0.2086 - val_accuracy: 0.9460\n",
      "Epoch 968/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9639 - val_loss: 0.1837 - val_accuracy: 0.9460\n",
      "Epoch 969/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9579 - val_loss: 0.1966 - val_accuracy: 0.9460\n",
      "Epoch 970/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9588 - val_loss: 0.2036 - val_accuracy: 0.9429\n",
      "Epoch 971/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9558 - val_loss: 0.2135 - val_accuracy: 0.9444\n",
      "Epoch 972/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9604 - val_loss: 0.1787 - val_accuracy: 0.9452\n",
      "Epoch 973/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9566 - val_loss: 0.2248 - val_accuracy: 0.9468\n",
      "Epoch 974/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9567 - val_loss: 0.2035 - val_accuracy: 0.9491\n",
      "Epoch 975/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9585 - val_loss: 0.2042 - val_accuracy: 0.9413\n",
      "Epoch 976/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9586 - val_loss: 0.1950 - val_accuracy: 0.9452\n",
      "Epoch 977/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9569 - val_loss: 0.2305 - val_accuracy: 0.9444\n",
      "Epoch 978/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.9624 - val_loss: 0.2166 - val_accuracy: 0.9452\n",
      "Epoch 979/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9565 - val_loss: 0.2237 - val_accuracy: 0.9429\n",
      "Epoch 980/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9561 - val_loss: 0.2111 - val_accuracy: 0.9374\n",
      "Epoch 981/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9598 - val_loss: 0.2018 - val_accuracy: 0.9460\n",
      "Epoch 982/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9527 - val_loss: 0.2093 - val_accuracy: 0.9452\n",
      "Epoch 983/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9613 - val_loss: 0.2103 - val_accuracy: 0.9429\n",
      "Epoch 984/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9546 - val_loss: 0.2173 - val_accuracy: 0.9444\n",
      "Epoch 985/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9543 - val_loss: 0.2026 - val_accuracy: 0.9460\n",
      "Epoch 986/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9581 - val_loss: 0.1994 - val_accuracy: 0.9476\n",
      "Epoch 987/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9577 - val_loss: 0.2050 - val_accuracy: 0.9484\n",
      "Epoch 988/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9644 - val_loss: 0.2147 - val_accuracy: 0.9476\n",
      "Epoch 989/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9597 - val_loss: 0.2088 - val_accuracy: 0.9397\n",
      "Epoch 990/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9522 - val_loss: 0.2557 - val_accuracy: 0.9382\n",
      "Epoch 991/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9625 - val_loss: 0.2196 - val_accuracy: 0.9343\n",
      "Epoch 992/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9546 - val_loss: 0.2140 - val_accuracy: 0.9444\n",
      "Epoch 993/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9617 - val_loss: 0.2254 - val_accuracy: 0.9484\n",
      "Epoch 994/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9568 - val_loss: 0.2137 - val_accuracy: 0.9413\n",
      "Epoch 995/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9565 - val_loss: 0.2246 - val_accuracy: 0.9491\n",
      "Epoch 996/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1422 - accuracy: 0.9474 - val_loss: 0.2026 - val_accuracy: 0.9468\n",
      "Epoch 997/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9517 - val_loss: 0.2081 - val_accuracy: 0.9429\n",
      "Epoch 998/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9543 - val_loss: 0.1958 - val_accuracy: 0.9452\n",
      "Epoch 999/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9584 - val_loss: 0.2009 - val_accuracy: 0.9429\n",
      "Epoch 1000/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9564 - val_loss: 0.1937 - val_accuracy: 0.9452\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9514867067337036"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history2.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model2 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model2 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 200)               2200      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 28,677\n",
      "Trainable params: 28,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.models.Sequential([\n",
    "                    keras.layers.Input(shape=X_train.shape[1], name='input'),\n",
    "                    keras.layers.Dense(200, activation='softplus'),\n",
    "                    keras.layers.Dense(100, activation='softplus'),\n",
    "                    keras.layers.Dense(50, activation='softplus'),\n",
    "                    keras.layers.Dense(25, activation='softplus'),\n",
    "                    keras.layers.Dense(2, activation='softmax', name='output')\n",
    "                    ])\n",
    "\n",
    "model3.compile(\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            optimizer='Adagrad',\n",
    "            metrics= ['accuracy']\n",
    "            )\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "120/120 [==============================] - 1s 3ms/step - loss: 1.9368 - accuracy: 0.7587 - val_loss: 0.2109 - val_accuracy: 0.9515\n",
      "Epoch 2/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9565 - val_loss: 0.1970 - val_accuracy: 0.9515\n",
      "Epoch 3/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.9521 - val_loss: 0.2001 - val_accuracy: 0.9358\n",
      "Epoch 4/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9496 - val_loss: 0.1824 - val_accuracy: 0.9515\n",
      "Epoch 5/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9464 - val_loss: 0.1803 - val_accuracy: 0.9491\n",
      "Epoch 6/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9555 - val_loss: 0.1821 - val_accuracy: 0.9468\n",
      "Epoch 7/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9481 - val_loss: 0.1773 - val_accuracy: 0.9491\n",
      "Epoch 8/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9464 - val_loss: 0.1854 - val_accuracy: 0.9515\n",
      "Epoch 9/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9439 - val_loss: 0.1749 - val_accuracy: 0.9507\n",
      "Epoch 10/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9514 - val_loss: 0.1740 - val_accuracy: 0.9507\n",
      "Epoch 11/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.9541 - val_loss: 0.1807 - val_accuracy: 0.9405\n",
      "Epoch 12/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9462 - val_loss: 0.1724 - val_accuracy: 0.9499\n",
      "Epoch 13/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9487 - val_loss: 0.1735 - val_accuracy: 0.9476\n",
      "Epoch 14/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9536 - val_loss: 0.1735 - val_accuracy: 0.9515\n",
      "Epoch 15/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9575 - val_loss: 0.1713 - val_accuracy: 0.9515\n",
      "Epoch 16/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9508 - val_loss: 0.1697 - val_accuracy: 0.9515\n",
      "Epoch 17/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9485 - val_loss: 0.1702 - val_accuracy: 0.9515\n",
      "Epoch 18/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9519 - val_loss: 0.1707 - val_accuracy: 0.9515\n",
      "Epoch 19/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9495 - val_loss: 0.1698 - val_accuracy: 0.9515\n",
      "Epoch 20/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9504 - val_loss: 0.1676 - val_accuracy: 0.9515\n",
      "Epoch 21/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9510 - val_loss: 0.1675 - val_accuracy: 0.9507\n",
      "Epoch 22/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9479 - val_loss: 0.1671 - val_accuracy: 0.9507\n",
      "Epoch 23/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9529 - val_loss: 0.1693 - val_accuracy: 0.9515\n",
      "Epoch 24/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9507 - val_loss: 0.1663 - val_accuracy: 0.9515\n",
      "Epoch 25/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.9503 - val_loss: 0.1669 - val_accuracy: 0.9515\n",
      "Epoch 26/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.9515 - val_loss: 0.1659 - val_accuracy: 0.9515\n",
      "Epoch 27/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9517 - val_loss: 0.1694 - val_accuracy: 0.9484\n",
      "Epoch 28/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9499 - val_loss: 0.1653 - val_accuracy: 0.9515\n",
      "Epoch 29/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9419 - val_loss: 0.1654 - val_accuracy: 0.9515\n",
      "Epoch 30/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9540 - val_loss: 0.1651 - val_accuracy: 0.9515\n",
      "Epoch 31/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9504 - val_loss: 0.1656 - val_accuracy: 0.9515\n",
      "Epoch 32/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9473 - val_loss: 0.1648 - val_accuracy: 0.9515\n",
      "Epoch 33/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9467 - val_loss: 0.1658 - val_accuracy: 0.9499\n",
      "Epoch 34/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.9507 - val_loss: 0.1646 - val_accuracy: 0.9515\n",
      "Epoch 35/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9502 - val_loss: 0.1646 - val_accuracy: 0.9515\n",
      "Epoch 36/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9542 - val_loss: 0.1677 - val_accuracy: 0.9484\n",
      "Epoch 37/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9557 - val_loss: 0.1639 - val_accuracy: 0.9515\n",
      "Epoch 38/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9496 - val_loss: 0.1640 - val_accuracy: 0.9515\n",
      "Epoch 39/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9573 - val_loss: 0.1638 - val_accuracy: 0.9515\n",
      "Epoch 40/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9524 - val_loss: 0.1635 - val_accuracy: 0.9515\n",
      "Epoch 41/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.9507 - val_loss: 0.1642 - val_accuracy: 0.9515\n",
      "Epoch 42/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.9443 - val_loss: 0.1637 - val_accuracy: 0.9515\n",
      "Epoch 43/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9523 - val_loss: 0.1644 - val_accuracy: 0.9515\n",
      "Epoch 44/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1628 - accuracy: 0.9510 - val_loss: 0.1638 - val_accuracy: 0.9515\n",
      "Epoch 45/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9474 - val_loss: 0.1632 - val_accuracy: 0.9515\n",
      "Epoch 46/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1649 - accuracy: 0.9524 - val_loss: 0.1629 - val_accuracy: 0.9515\n",
      "Epoch 47/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.9475 - val_loss: 0.1628 - val_accuracy: 0.9515\n",
      "Epoch 48/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9481 - val_loss: 0.1642 - val_accuracy: 0.9515\n",
      "Epoch 49/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9538 - val_loss: 0.1625 - val_accuracy: 0.9515\n",
      "Epoch 50/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9533 - val_loss: 0.1624 - val_accuracy: 0.9515\n",
      "Epoch 51/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9524 - val_loss: 0.1627 - val_accuracy: 0.9515\n",
      "Epoch 52/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9479 - val_loss: 0.1652 - val_accuracy: 0.9515\n",
      "Epoch 53/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9536 - val_loss: 0.1622 - val_accuracy: 0.9515\n",
      "Epoch 54/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9483 - val_loss: 0.1642 - val_accuracy: 0.9515\n",
      "Epoch 55/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.95 - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9523 - val_loss: 0.1627 - val_accuracy: 0.9515\n",
      "Epoch 56/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9469 - val_loss: 0.1621 - val_accuracy: 0.9515\n",
      "Epoch 57/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9530 - val_loss: 0.1643 - val_accuracy: 0.9499\n",
      "Epoch 58/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9505 - val_loss: 0.1618 - val_accuracy: 0.9515\n",
      "Epoch 59/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9451 - val_loss: 0.1642 - val_accuracy: 0.9515\n",
      "Epoch 60/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9503 - val_loss: 0.1616 - val_accuracy: 0.9515\n",
      "Epoch 61/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.9455 - val_loss: 0.1633 - val_accuracy: 0.9515\n",
      "Epoch 62/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1724 - accuracy: 0.9497 - val_loss: 0.1613 - val_accuracy: 0.9515\n",
      "Epoch 63/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9549 - val_loss: 0.1617 - val_accuracy: 0.9515\n",
      "Epoch 64/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9515 - val_loss: 0.1635 - val_accuracy: 0.9515\n",
      "Epoch 65/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1649 - accuracy: 0.9504 - val_loss: 0.1624 - val_accuracy: 0.9515\n",
      "Epoch 66/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9536 - val_loss: 0.1611 - val_accuracy: 0.9515\n",
      "Epoch 67/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9515 - val_loss: 0.1611 - val_accuracy: 0.9515\n",
      "Epoch 68/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9496 - val_loss: 0.1613 - val_accuracy: 0.9515\n",
      "Epoch 69/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9537 - val_loss: 0.1611 - val_accuracy: 0.9515\n",
      "Epoch 70/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9509 - val_loss: 0.1615 - val_accuracy: 0.9515\n",
      "Epoch 71/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9498 - val_loss: 0.1609 - val_accuracy: 0.9515\n",
      "Epoch 72/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9484 - val_loss: 0.1618 - val_accuracy: 0.9515\n",
      "Epoch 73/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9525 - val_loss: 0.1608 - val_accuracy: 0.9515\n",
      "Epoch 74/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.9425 - val_loss: 0.1617 - val_accuracy: 0.9515\n",
      "Epoch 75/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9465 - val_loss: 0.1617 - val_accuracy: 0.9515\n",
      "Epoch 76/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9541 - val_loss: 0.1612 - val_accuracy: 0.9515\n",
      "Epoch 77/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9516 - val_loss: 0.1621 - val_accuracy: 0.9515\n",
      "Epoch 78/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9441 - val_loss: 0.1606 - val_accuracy: 0.9515\n",
      "Epoch 79/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9495 - val_loss: 0.1605 - val_accuracy: 0.9515\n",
      "Epoch 80/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9534 - val_loss: 0.1607 - val_accuracy: 0.9515\n",
      "Epoch 81/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1576 - accuracy: 0.9532 - val_loss: 0.1607 - val_accuracy: 0.9515\n",
      "Epoch 82/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9448 - val_loss: 0.1627 - val_accuracy: 0.9515\n",
      "Epoch 83/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9541 - val_loss: 0.1604 - val_accuracy: 0.9515\n",
      "Epoch 84/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9481 - val_loss: 0.1603 - val_accuracy: 0.9515\n",
      "Epoch 85/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9529 - val_loss: 0.1604 - val_accuracy: 0.9515\n",
      "Epoch 86/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.9439 - val_loss: 0.1603 - val_accuracy: 0.9515\n",
      "Epoch 87/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9503 - val_loss: 0.1601 - val_accuracy: 0.9515\n",
      "Epoch 88/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9504 - val_loss: 0.1600 - val_accuracy: 0.9515\n",
      "Epoch 89/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9485 - val_loss: 0.1599 - val_accuracy: 0.9515\n",
      "Epoch 90/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9526 - val_loss: 0.1602 - val_accuracy: 0.9515\n",
      "Epoch 91/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9476 - val_loss: 0.1598 - val_accuracy: 0.9515\n",
      "Epoch 92/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9492 - val_loss: 0.1598 - val_accuracy: 0.9515\n",
      "Epoch 93/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9479 - val_loss: 0.1602 - val_accuracy: 0.9515\n",
      "Epoch 94/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9503 - val_loss: 0.1597 - val_accuracy: 0.9515\n",
      "Epoch 95/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9574 - val_loss: 0.1628 - val_accuracy: 0.9499\n",
      "Epoch 96/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9511 - val_loss: 0.1601 - val_accuracy: 0.9515\n",
      "Epoch 97/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9536 - val_loss: 0.1600 - val_accuracy: 0.9515\n",
      "Epoch 98/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9493 - val_loss: 0.1596 - val_accuracy: 0.9515\n",
      "Epoch 99/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9495 - val_loss: 0.1597 - val_accuracy: 0.9515\n",
      "Epoch 100/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9568 - val_loss: 0.1601 - val_accuracy: 0.9515\n",
      "Epoch 101/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9531 - val_loss: 0.1595 - val_accuracy: 0.9515\n",
      "Epoch 102/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9488 - val_loss: 0.1596 - val_accuracy: 0.9515\n",
      "Epoch 103/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9543 - val_loss: 0.1611 - val_accuracy: 0.9515\n",
      "Epoch 104/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9524 - val_loss: 0.1602 - val_accuracy: 0.9515\n",
      "Epoch 105/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9462 - val_loss: 0.1593 - val_accuracy: 0.9515\n",
      "Epoch 106/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9472 - val_loss: 0.1600 - val_accuracy: 0.9515\n",
      "Epoch 107/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9552 - val_loss: 0.1610 - val_accuracy: 0.9515\n",
      "Epoch 108/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9544 - val_loss: 0.1595 - val_accuracy: 0.9515\n",
      "Epoch 109/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9535 - val_loss: 0.1595 - val_accuracy: 0.9515\n",
      "Epoch 110/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9508 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 111/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9559 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 112/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9523 - val_loss: 0.1592 - val_accuracy: 0.9515\n",
      "Epoch 113/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9531 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 114/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9506 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 115/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9553 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 116/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9540 - val_loss: 0.1593 - val_accuracy: 0.9515\n",
      "Epoch 117/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9491 - val_loss: 0.1594 - val_accuracy: 0.9515\n",
      "Epoch 118/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9491 - val_loss: 0.1590 - val_accuracy: 0.9515\n",
      "Epoch 119/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9498 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 120/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9525 - val_loss: 0.1588 - val_accuracy: 0.9515\n",
      "Epoch 121/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9489 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 122/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9567 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 123/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9487 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 124/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1674 - accuracy: 0.9498 - val_loss: 0.1587 - val_accuracy: 0.9515\n",
      "Epoch 125/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9508 - val_loss: 0.1592 - val_accuracy: 0.9515\n",
      "Epoch 126/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9539 - val_loss: 0.1601 - val_accuracy: 0.9515\n",
      "Epoch 127/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9562 - val_loss: 0.1590 - val_accuracy: 0.9515\n",
      "Epoch 128/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9511 - val_loss: 0.1586 - val_accuracy: 0.9515\n",
      "Epoch 129/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9503 - val_loss: 0.1586 - val_accuracy: 0.9515\n",
      "Epoch 130/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9548 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 131/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9542 - val_loss: 0.1586 - val_accuracy: 0.9515\n",
      "Epoch 132/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9496 - val_loss: 0.1586 - val_accuracy: 0.9515\n",
      "Epoch 133/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9524 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 134/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9525 - val_loss: 0.1587 - val_accuracy: 0.9515\n",
      "Epoch 135/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9548 - val_loss: 0.1585 - val_accuracy: 0.9515\n",
      "Epoch 136/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.9447 - val_loss: 0.1585 - val_accuracy: 0.9515\n",
      "Epoch 137/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9567 - val_loss: 0.1582 - val_accuracy: 0.9515\n",
      "Epoch 138/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9534 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 139/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9499 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 140/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9533 - val_loss: 0.1582 - val_accuracy: 0.9515\n",
      "Epoch 141/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9519 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 142/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9564 - val_loss: 0.1582 - val_accuracy: 0.9515\n",
      "Epoch 143/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9559 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 144/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.9434 - val_loss: 0.1581 - val_accuracy: 0.9515\n",
      "Epoch 145/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9543 - val_loss: 0.1614 - val_accuracy: 0.9515\n",
      "Epoch 146/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.9517 - val_loss: 0.1581 - val_accuracy: 0.9515\n",
      "Epoch 147/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9526 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 148/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1563 - accuracy: 0.9552 - val_loss: 0.1590 - val_accuracy: 0.9515\n",
      "Epoch 149/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9537 - val_loss: 0.1580 - val_accuracy: 0.9515\n",
      "Epoch 150/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9501 - val_loss: 0.1587 - val_accuracy: 0.9515\n",
      "Epoch 151/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9522 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 152/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.9495 - val_loss: 0.1587 - val_accuracy: 0.9515\n",
      "Epoch 153/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9522 - val_loss: 0.1581 - val_accuracy: 0.9515\n",
      "Epoch 154/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9524 - val_loss: 0.1580 - val_accuracy: 0.9515\n",
      "Epoch 155/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9505 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 156/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9524 - val_loss: 0.1580 - val_accuracy: 0.9515\n",
      "Epoch 157/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9491 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 158/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9459 - val_loss: 0.1580 - val_accuracy: 0.9515\n",
      "Epoch 159/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9502 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 160/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9532 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 161/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.9500 - val_loss: 0.1578 - val_accuracy: 0.9515\n",
      "Epoch 162/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.9468 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 163/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9543 - val_loss: 0.1577 - val_accuracy: 0.9515\n",
      "Epoch 164/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9533 - val_loss: 0.1580 - val_accuracy: 0.9515\n",
      "Epoch 165/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9501 - val_loss: 0.1582 - val_accuracy: 0.9515\n",
      "Epoch 166/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9529 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 167/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9509 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 168/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9495 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 169/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9479 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 170/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9516 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 171/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9481 - val_loss: 0.1586 - val_accuracy: 0.9515\n",
      "Epoch 172/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9575 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 173/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9532 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 174/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9507 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 175/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9554 - val_loss: 0.1582 - val_accuracy: 0.9515\n",
      "Epoch 176/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9551 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 177/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9551 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 178/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9545 - val_loss: 0.1578 - val_accuracy: 0.9515\n",
      "Epoch 179/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.9523 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 180/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9576 - val_loss: 0.1582 - val_accuracy: 0.9515\n",
      "Epoch 181/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9516 - val_loss: 0.1574 - val_accuracy: 0.9515\n",
      "Epoch 182/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9580 - val_loss: 0.1573 - val_accuracy: 0.9515\n",
      "Epoch 183/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9509 - val_loss: 0.1593 - val_accuracy: 0.9515\n",
      "Epoch 184/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9470 - val_loss: 0.1573 - val_accuracy: 0.9515\n",
      "Epoch 185/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9520 - val_loss: 0.1573 - val_accuracy: 0.9515\n",
      "Epoch 186/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9502 - val_loss: 0.1573 - val_accuracy: 0.9515\n",
      "Epoch 187/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9494 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 188/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9523 - val_loss: 0.1577 - val_accuracy: 0.9515\n",
      "Epoch 189/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9469 - val_loss: 0.1578 - val_accuracy: 0.9515\n",
      "Epoch 190/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9548 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 191/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9527 - val_loss: 0.1581 - val_accuracy: 0.9515\n",
      "Epoch 192/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9551 - val_loss: 0.1574 - val_accuracy: 0.9515\n",
      "Epoch 193/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9477 - val_loss: 0.1580 - val_accuracy: 0.9515\n",
      "Epoch 194/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9428 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 195/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9478 - val_loss: 0.1578 - val_accuracy: 0.9515\n",
      "Epoch 196/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9538 - val_loss: 0.1577 - val_accuracy: 0.9515\n",
      "Epoch 197/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9506 - val_loss: 0.1571 - val_accuracy: 0.9515\n",
      "Epoch 198/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9490 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 199/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9535 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 200/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9573 - val_loss: 0.1571 - val_accuracy: 0.9515\n",
      "Epoch 201/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9461 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 202/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9532 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 203/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9495 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 204/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9554 - val_loss: 0.1605 - val_accuracy: 0.9515\n",
      "Epoch 205/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9534 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 206/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9527 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 207/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9523 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 208/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9505 - val_loss: 0.1585 - val_accuracy: 0.9515\n",
      "Epoch 209/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9503 - val_loss: 0.1577 - val_accuracy: 0.9515\n",
      "Epoch 210/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9408 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 211/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9513 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 212/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9550 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 213/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9526 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 214/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.9507 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 215/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9555 - val_loss: 0.1578 - val_accuracy: 0.9515\n",
      "Epoch 216/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9479 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 217/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9527 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 218/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9533 - val_loss: 0.1584 - val_accuracy: 0.9515\n",
      "Epoch 219/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9526 - val_loss: 0.1573 - val_accuracy: 0.9515\n",
      "Epoch 220/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9523 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 221/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9472 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 222/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9506 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 223/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9527 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 224/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9522 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 225/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9477 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 226/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9528 - val_loss: 0.1567 - val_accuracy: 0.9515\n",
      "Epoch 227/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9484 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 228/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9447 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 229/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9499 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 230/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9467 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 231/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9511 - val_loss: 0.1567 - val_accuracy: 0.9515\n",
      "Epoch 232/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9537 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 233/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.9461 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 234/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9523 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 235/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9518 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 236/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.9474 - val_loss: 0.1574 - val_accuracy: 0.9515\n",
      "Epoch 237/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9508 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 238/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9520 - val_loss: 0.1570 - val_accuracy: 0.9515\n",
      "Epoch 239/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9521 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 240/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9509 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 241/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9521 - val_loss: 0.1567 - val_accuracy: 0.9515\n",
      "Epoch 242/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9491 - val_loss: 0.1580 - val_accuracy: 0.9515\n",
      "Epoch 243/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9513 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 244/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.9521 - val_loss: 0.1578 - val_accuracy: 0.9515\n",
      "Epoch 245/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9538 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 246/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9492 - val_loss: 0.1567 - val_accuracy: 0.9515\n",
      "Epoch 247/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9484 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 248/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9534 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 249/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9514 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 250/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9545 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 251/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.9409 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 252/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9495 - val_loss: 0.1567 - val_accuracy: 0.9515\n",
      "Epoch 253/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9486 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 254/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9526 - val_loss: 0.1567 - val_accuracy: 0.9515\n",
      "Epoch 255/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.9503 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 256/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9522 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 257/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9550 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 258/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9470 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 259/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9474 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 260/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9516 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 261/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9525 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 262/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1688 - accuracy: 0.9482 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 263/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9494 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 264/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9476 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 265/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9525 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 266/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9561 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 267/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9461 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 268/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9537 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 269/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9527 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 270/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9560 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 271/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9528 - val_loss: 0.1586 - val_accuracy: 0.9515\n",
      "Epoch 272/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9511 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 273/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9535 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 274/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9553 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 275/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9557 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 276/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.9605 - val_loss: 0.1588 - val_accuracy: 0.9515\n",
      "Epoch 277/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9538 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 278/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9490 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 279/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9476 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 280/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9474 - val_loss: 0.1578 - val_accuracy: 0.9515\n",
      "Epoch 281/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9496 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 282/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9443 - val_loss: 0.1585 - val_accuracy: 0.9515\n",
      "Epoch 283/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9436 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 284/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9540 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 285/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9552 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 286/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1649 - accuracy: 0.9496 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 287/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.9527 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 288/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9519 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 289/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9505 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 290/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9502 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 291/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9520 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 292/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9541 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 293/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9480 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 294/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9537 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 295/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9475 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 296/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9493 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 297/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9512 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 298/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9536 - val_loss: 0.1565 - val_accuracy: 0.9515\n",
      "Epoch 299/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9532 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 300/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9571 - val_loss: 0.1588 - val_accuracy: 0.9515\n",
      "Epoch 301/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9588 - val_loss: 0.1574 - val_accuracy: 0.9515\n",
      "Epoch 302/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9547 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 303/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9559 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 304/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9566 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 305/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9518 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 306/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9537 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 307/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9511 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 308/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9492 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 309/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.9454 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 310/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9500 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 311/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9578 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 312/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9481 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 313/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9538 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 314/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9551 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 315/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9463 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 316/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9465 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 317/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9449 - val_loss: 0.1578 - val_accuracy: 0.9515\n",
      "Epoch 318/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9489 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 319/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9540 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 320/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9493 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 321/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9515 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 322/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9464 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 323/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9483 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 324/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9478 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 325/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9571 - val_loss: 0.1567 - val_accuracy: 0.9515\n",
      "Epoch 326/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9507 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 327/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9480 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 328/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9523 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 329/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9528 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 330/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9532 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 331/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9503 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 332/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.9450 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 333/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9548 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 334/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9481 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 335/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9569 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 336/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9504 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 337/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9453 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 338/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9542 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 339/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9531 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 340/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9537 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 341/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9452 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 342/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9546 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 343/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9556 - val_loss: 0.1577 - val_accuracy: 0.9515\n",
      "Epoch 344/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9522 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 345/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9540 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 346/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9518 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 347/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9415 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 348/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.9474 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 349/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9500 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 350/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9513 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 351/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9564 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 352/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9526 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 353/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.9474 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 354/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9530 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 355/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9519 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 356/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9518 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 357/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9550 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 358/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9431 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 359/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9496 - val_loss: 0.1563 - val_accuracy: 0.9515\n",
      "Epoch 360/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9475 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 361/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9531 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 362/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9556 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 363/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9520 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 364/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9525 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 365/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9499 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 366/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9479 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 367/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9516 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 368/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9542 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 369/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9552 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 370/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9538 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 371/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9471 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 372/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9511 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 373/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9513 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 374/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.9473 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 375/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9511 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 376/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9492 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 377/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9495 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 378/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9527 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 379/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9484 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 380/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9514 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 381/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9525 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 382/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9570 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 383/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9547 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 384/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9494 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 385/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9496 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 386/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9634 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 387/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9472 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 388/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9525 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 389/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9525 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 390/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9518 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 391/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9502 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 392/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9533 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 393/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9531 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 394/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9525 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 395/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9505 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 396/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9488 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 397/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9512 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 398/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1576 - accuracy: 0.9527 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 399/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9522 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 400/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9493 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 401/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9499 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 402/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9525 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 403/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9518 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 404/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9511 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 405/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9452 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 406/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9561 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 407/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9491 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 408/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9530 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 409/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9563 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 410/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9490 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 411/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9498 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 412/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9514 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 413/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9514 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 414/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9542 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 415/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9536 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 416/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9532 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 417/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9519 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 418/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9504 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 419/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9548 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 420/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9544 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 421/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9550 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 422/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9528 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 423/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9476 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 424/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9449 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 425/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9490 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 426/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9511 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 427/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9499 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 428/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9548 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 429/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.9479 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 430/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9538 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 431/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9508 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 432/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9468 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 433/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9483 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 434/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9511 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 435/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1733 - accuracy: 0.9474 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 436/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9461 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 437/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9476 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 438/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9441 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 439/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9473 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 440/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9532 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 441/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9418 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 442/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9484 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 443/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9493 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 444/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1693 - accuracy: 0.9475 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 445/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9495 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 446/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9489 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 447/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9542 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 448/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9495 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 449/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9489 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 450/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9487 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 451/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9554 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 452/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9505 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 453/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9528 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 454/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9530 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 455/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9511 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 456/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9475 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 457/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9503 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 458/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9526 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 459/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9541 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 460/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9528 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 461/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9534 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 462/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.9524 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 463/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9530 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 464/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.9522 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 465/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9523 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 466/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9490 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 467/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9528 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 468/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9532 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 469/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1708 - accuracy: 0.9461 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 470/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9468 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 471/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9504 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 472/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9487 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 473/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9469 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 474/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9498 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 475/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9533 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 476/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9561 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 477/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9576 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 478/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9442 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 479/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9407 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 480/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9523 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 481/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9515 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 482/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9543 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 483/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9550 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 484/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9501 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 485/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9498 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 486/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9459 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 487/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9467 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 488/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9444 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 489/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.9458 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 490/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9520 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 491/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9483 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 492/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9539 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 493/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1704 - accuracy: 0.9468 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 494/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9487 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 495/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9504 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 496/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9583 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 497/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9537 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 498/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9588 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 499/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9551 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 500/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9538 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 501/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9575 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 502/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9514 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 503/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9455 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 504/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9535 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 505/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9582 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 506/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9484 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 507/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9522 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 508/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9554 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 509/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9458 - val_loss: 0.1564 - val_accuracy: 0.9515\n",
      "Epoch 510/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9483 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 511/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9413 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 512/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9492 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 513/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9566 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 514/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9514 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 515/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9481 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 516/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1688 - accuracy: 0.9452 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 517/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9515 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 518/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9559 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 519/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9516 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 520/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9507 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 521/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9438 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
      "Epoch 522/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9449 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 523/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9519 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 524/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9547 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 525/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9538 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 526/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9607 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 527/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9510 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 528/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9493 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 529/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9533 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 530/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9559 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 531/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9534 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 532/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9501 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 533/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9465 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 534/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9543 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 535/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9520 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 536/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1576 - accuracy: 0.9514 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 537/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9510 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 538/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.9488 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 539/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 0.9441 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 540/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9571 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 541/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9479 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 542/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9560 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 543/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.9472 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 544/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9509 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 545/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9537 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 546/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9526 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 547/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9555 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 548/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9483 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 549/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9509 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 550/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9538 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 551/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9573 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 552/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9551 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 553/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9513 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 554/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9525 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 555/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9541 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 556/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9500 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 557/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9510 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 558/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9557 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 559/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9504 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 560/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9561 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 561/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9569 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 562/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9496 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 563/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9471 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 564/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9477 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 565/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9505 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 566/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9530 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 567/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9502 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 568/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9462 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 569/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9582 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 570/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9543 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 571/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9520 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 572/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9470 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 573/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9534 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 574/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9492 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 575/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9539 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 576/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9517 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 577/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9565 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 578/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9526 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 579/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9532 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 580/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9498 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 581/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9563 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 582/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9518 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 583/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9485 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 584/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1632 - accuracy: 0.9472 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 585/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9530 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 586/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9515 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 587/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1719 - accuracy: 0.9480 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 588/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9481 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 589/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9510 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 590/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9478 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 591/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9520 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 592/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9564 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 593/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9510 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 594/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9508 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 595/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9441 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 596/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9487 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 597/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9543 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 598/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9501 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 599/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9539 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 600/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9543 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 601/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9556 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 602/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9495 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 603/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9549 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 604/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9558 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 605/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9517 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 606/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9493 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 607/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9529 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 608/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9517 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 609/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9493 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 610/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9479 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 611/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9467 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 612/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9498 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 613/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9521 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 614/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9548 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 615/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9495 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 616/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9508 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 617/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9534 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 618/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9493 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 619/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9504 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 620/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1693 - accuracy: 0.9447 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 621/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9543 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 622/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9551 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 623/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9512 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 624/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9536 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 625/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9533 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 626/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9465 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 627/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9525 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 628/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9468 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 629/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9517 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 630/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9492 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 631/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9537 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 632/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9540 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 633/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9545 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 634/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9504 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 635/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9516 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 636/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9455 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 637/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9573 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 638/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9595 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 639/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9528 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 640/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9528 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 641/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9525 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 642/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9548 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 643/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9507 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 644/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9477 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 645/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9510 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 646/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9553 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 647/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9547 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 648/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9525 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 649/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9465 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 650/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9503 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 651/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9570 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 652/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9556 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 653/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9520 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 654/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9536 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 655/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9545 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 656/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9469 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 657/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9476 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 658/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9463 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 659/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9545 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 660/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9495 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 661/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9498 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 662/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9497 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 663/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.9515 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 664/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9435 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 665/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9548 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 666/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9505 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 667/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9551 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 668/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9542 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 669/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9495 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 670/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9504 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 671/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9499 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 672/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9537 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 673/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9532 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 674/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9474 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 675/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9518 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 676/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9554 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 677/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9547 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 678/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9521 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 679/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9524 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 680/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9431 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 681/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9444 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 682/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9573 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 683/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9497 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 684/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.9460 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 685/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9490 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 686/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9474 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 687/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9523 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 688/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9502 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 689/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9569 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 690/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9516 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 691/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9486 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 692/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9552 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 693/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9520 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 694/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9480 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 695/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9558 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 696/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9503 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 697/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9504 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 698/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9541 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 699/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9495 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 700/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9504 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 701/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9488 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 702/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9518 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 703/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9544 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 704/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9550 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 705/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9486 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 706/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9524 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 707/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9543 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 708/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9530 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 709/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9558 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 710/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9545 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 711/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9482 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 712/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9536 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 713/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9525 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 714/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9491 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 715/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9523 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 716/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9538 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 717/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9494 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 718/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9588 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 719/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9590 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 720/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9483 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 721/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9493 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 722/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9525 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 723/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9440 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 724/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9549 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 725/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9567 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 726/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9525 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 727/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9503 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 728/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9525 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 729/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9496 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 730/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9520 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 731/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9535 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 732/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9486 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 733/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9538 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 734/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9498 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 735/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9557 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 736/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9568 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 737/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9403 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 738/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9507 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 739/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9546 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 740/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9452 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 741/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9531 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 742/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9516 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 743/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9473 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 744/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9505 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 745/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9524 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 746/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9522 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 747/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9530 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 748/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9567 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 749/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9507 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 750/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9508 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 751/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9446 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 752/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9466 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 753/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9551 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 754/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.9524 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 755/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9553 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 756/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9482 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 757/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9480 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 758/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9516 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 759/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9511 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 760/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9516 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 761/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9506 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 762/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9537 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 763/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9477 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 764/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9531 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 765/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9490 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 766/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9526 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 767/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9529 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 768/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9508 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 769/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9581 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 770/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9540 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 771/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9473 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 772/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9576 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 773/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9523 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 774/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9521 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 775/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9538 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 776/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9473 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 777/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9578 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 778/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9458 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 779/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9548 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 780/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9494 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 781/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9521 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 782/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9484 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 783/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9535 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 784/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9522 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 785/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9533 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 786/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9527 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 787/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9532 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 788/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9480 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 789/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9510 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 790/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9501 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 791/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9488 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 792/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9542 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 793/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1628 - accuracy: 0.9478 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 794/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9491 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 795/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.9435 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 796/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9513 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 797/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9501 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 798/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9477 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 799/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9540 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 800/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9508 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 801/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9498 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 802/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9476 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 803/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9527 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 804/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9500 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 805/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.9475 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 806/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9447 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 807/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9558 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 808/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9473 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 809/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9512 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 810/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9527 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 811/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9503 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 812/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9559 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 813/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9482 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 814/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.9535 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 815/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9438 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 816/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9480 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 817/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9617 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 818/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9547 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 819/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9505 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 820/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9510 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 821/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.9503 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 822/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9541 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 823/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9485 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 824/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9523 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 825/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9538 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 826/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9514 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 827/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9572 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 828/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9550 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 829/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9455 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 830/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9477 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 831/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9483 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 832/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9446 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 833/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9565 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 834/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9512 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 835/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9496 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 836/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9563 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 837/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9452 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 838/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9572 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 839/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9487 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 840/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9543 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 841/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9494 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 842/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9527 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 843/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9482 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 844/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9507 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 845/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9505 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 846/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9483 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 847/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9478 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 848/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9522 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 849/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9531 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 850/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9493 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 851/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9544 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 852/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9510 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 853/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9539 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 854/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9496 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 855/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9502 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 856/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9538 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 857/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9560 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 858/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9523 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 859/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9516 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 860/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9487 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 861/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9499 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 862/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9546 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 863/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9532 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 864/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9555 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 865/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9518 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 866/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9518 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 867/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9490 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 868/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9533 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 869/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9475 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 870/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9527 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 871/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9455 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 872/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9501 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 873/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9493 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 874/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9513 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 875/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9537 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 876/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9538 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 877/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9492 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 878/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9483 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 879/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9479 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 880/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9541 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 881/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9551 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 882/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9505 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 883/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9522 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 884/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9492 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 885/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9508 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 886/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9482 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 887/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9554 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 888/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9491 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 889/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9512 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 890/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9514 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 891/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9526 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 892/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9483 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 893/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9490 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 894/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9467 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 895/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9537 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 896/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9562 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 897/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9491 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 898/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9497 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 899/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9475 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 900/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9507 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 901/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9497 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 902/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9518 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 903/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9516 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 904/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9458 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 905/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9563 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 906/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9506 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 907/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9539 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 908/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9458 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 909/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9542 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 910/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 911/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9513 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 912/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9555 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 913/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9587 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 914/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9543 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 915/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9515 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 916/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9504 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 917/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9511 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 918/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9496 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 919/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9551 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 920/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9549 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 921/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9510 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 922/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9472 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 923/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9554 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 924/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9514 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 925/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9466 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 926/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9485 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 927/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9498 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 928/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9540 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 929/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9517 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 930/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9504 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 931/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9453 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 932/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9495 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 933/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9533 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 934/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9500 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 935/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9526 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 936/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9459 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 937/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9531 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 938/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9484 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 939/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9503 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 940/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9523 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 941/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9526 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 942/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9476 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 943/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9510 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 944/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9504 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 945/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9539 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 946/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9561 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 947/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9519 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 948/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9465 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 949/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9485 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 950/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9521 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 951/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9508 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 952/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9540 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 953/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9452 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 954/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9462 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 955/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9605 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 956/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9504 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 957/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9550 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 958/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9476 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 959/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9516 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 960/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9521 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 961/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9521 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 962/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9549 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 963/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9516 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 964/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9524 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 965/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9538 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 966/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9501 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 967/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9542 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 968/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9484 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 969/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9495 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 970/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9510 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 971/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9523 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 972/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9513 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 973/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9513 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 974/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9517 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 975/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9484 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 976/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9510 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 977/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9554 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 978/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9503 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 979/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9499 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 980/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9553 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 981/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9461 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 982/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9570 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 983/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9516 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 984/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9535 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 985/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9517 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 986/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9519 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 987/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.9469 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 988/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9509 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 989/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9578 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 990/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9512 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 991/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9512 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 992/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9503 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 993/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9537 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 994/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9519 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 995/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9533 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 996/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9549 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 997/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9552 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 998/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9445 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 999/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9540 - val_loss: 0.1537 - val_accuracy: 0.9515\n",
      "Epoch 1000/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9530 - val_loss: 0.1537 - val_accuracy: 0.9515\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9514867067337036"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history3.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3.history['accuracy'])\n",
    "plt.plot(history3.history['val_accuracy'])\n",
    "plt.title('model3 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlKUlEQVR4nO3de5xddXnv8c+z77PnPpNJSDKBRAkoIAQIFLxU1KJEVLAqUEXbekFPa4unrRWO1R5P6zleWktREVFptSrUCiitUVIURIsCgUbkFhJuZnIhk5DMfWbfnvPHWhP2nqyEPSE7k5n1fb9e88re67af387M/u7f+q2LuTsiIhJfiZkuQEREZpaCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BILIPZvbPZva3dS77pJn9zgG+jpvZ0QeyrsjBoCAQOcjM7CIzW29mA2a23cy+bmZtM12XyL4oCEQOvv8CXubu7cALgBRQV89CZCYoCGRWC3fJfNjM7jezETP7mpktMLMfmtmQmd1qZp1Vy7/JzB40s91mdruZvbhq3slmdl+43r8CuSmv9QYzWxeue6eZnRhVk7tvcvcdVZPKQF27fsys3cy+YWb9ZvaUmf2VmSXCeUeb2U/DnsaOsEYs8A9h72MgfC9OqPtNlNhTEMhc8BbgbOAY4I3AD4H/Bcwj+B3/UwAzOwa4DvgQ0AOsBv7dzDJmlgG+B/wL0AX8W7hdwnVPAa4F3g90A18GbjazbFRBZvZyMxsAhsLtXFFnWz4PTPYkXgm8C/jDcN7fAGuATqA3XBbgtcBvh+3vAC4Edtb5eiIKApkTPu/uT7v7ZuBnwF3u/t/uPgHcBJwcLnch8AN3/093LwJ/BzQBLwXOANLAFe5edPfvAvdUvcb7gC+7+13uXnb3rwMT4Xp7cfefh7uGeoHPAk8+VyPMLBnWeLm7D7n7k8DfA+8MFykCRwGL3H3c3X9eNb0VeBFg7v6wu299rtcTmaQgkLng6arHYxHPW8LHi4CnJme4ewXYBCwO52322qswPlX1+Cjgz8PdQrvNbDewJFxvn8Jw+hFwfR3tmAdkprzuU2F9AH8JGHB3uHvr3eFr/AT4AvBF4Gkzu0aD0zIdCgKJky0EH+hAsG+d4MN8M7AVWBxOm3Rk1eNNwCfdvaPqJ+/u19XxuinghXUst4Nnv/VX17AZwN23ufv73H0RwS6qqyYPO3X3K939VOB4gl1EH67j9UQABYHEy3eAc83sNWaWBv6cYPfOncAvgBLwp2aWMrPfBU6vWvcrwAfM7LfCwdlmMzvXzFqnvoiZvcPMjgyXOwr4JPDj5yrO3cthjZ80s9Zw3T8Dvhlu921m1hsuvgtwoGxmp4V1pYERYJxggFqkLgoCiQ13Xw9cTDDIuoNgYPmN7l5w9wLwu8AfEHzIXgjcWLXuWoJxgi+E8zeGy0Y5jiBchgkOJV0frluPPyH4MH8c+DnwbYJBaoDTgLvMbBi4GbjU3Z8A2giCahfBrqSdBOMfInUx3ZhGRCTe1CMQEYk5BYGISMwpCEREYk5BICISc6mZLmC65s2b50uXLp3pMkREZpV77713h7v3RM2bdUGwdOlS1q5dO9NliIjMKmb21L7madeQiEjMKQhERGJOQSAiEnOzbowgSrFYpK+vj/Hx8ZkupeFyuRy9vb2k0+mZLkVE5og5EQR9fX20traydOlSai8eObe4Ozt37qSvr49ly5bNdDkiMkfMiV1D4+PjdHd3z+kQADAzuru7Y9HzEZFDZ04EATDnQ2BSXNopIofOnAmC5zJeLLNtYJxiuTLTpYiIHFZiFQTbh8YpVw7+Zbd3797NVVddNe31Xv/617N79+6DXo+IyHTEJggaaV9BUC7v/yZRq1evpqOjo0FViYjUZ04cNVSPRu5Zv+yyy3jsscdYsWIF6XSalpYWFi5cyLp163jooYc4//zz2bRpE+Pj41x66aVccsklwLOXyxgeHmbVqlW8/OUv584772Tx4sV8//vfp6mpqYFVi4gE5lwQfOLfH+ShLYN7TS9XnPFimaZMksQ0B1yPW9TGX7/x+H3O/9SnPsUDDzzAunXruP322zn33HN54IEH9hziee2119LV1cXY2BinnXYab3nLW+ju7q7ZxoYNG7juuuv4yle+wgUXXMANN9zAxRdfPK06RUQOxJwLgsPB6aefXnOc/5VXXslNN90EwKZNm9iwYcNeQbBs2TJWrFgBwKmnnsqTTz55qMoVkZibc0Gwr2/uA6MFnnpmlOULWmlKJxtaQ3Nz857Ht99+O7feeiu/+MUvyOfznHXWWZHnAWSz2T2Pk8kkY2NjDa1RRGRS/AaLD/5BQ7S2tjI0NBQ5b2BggM7OTvL5PI888gi//OUvD34BIiLPw5zrEexTA0eLu7u7ednLXsYJJ5xAU1MTCxYs2DPvnHPO4eqrr+bEE0/k2GOP5YwzzmhcISIiB8DcG/AVuYFWrlzpU29M8/DDD/PiF794v+sNjBV4aucoy+e30pRp7K6hRqunvSIi1czsXndfGTUvRruGdGkGEZEoMQqCSbOrByQi0mgxDAIREanW0CAws3PMbL2ZbTSzy/axzFlmts7MHjSznzayHhER2VvDjhoysyTwReBsoA+4x8xudveHqpbpAK4CznH335jZ/EbVIyIi0RrZIzgd2Ojuj7t7AbgeOG/KMm8HbnT33wC4+/YG1iMiIhEaGQSLgU1Vz/vCadWOATrN7HYzu9fM3hW1ITO7xMzWmtna/v7+BpV74A70MtQAV1xxBaOjowe5IhGR+jUyCKKO15x6yE4KOBU4F3gd8DEzO2avldyvcfeV7r6yp6fnoBVzsCgIRGQ2a+SZxX3AkqrnvcCWiGV2uPsIMGJmdwAnAY82qqhGHDxafRnqs88+m/nz5/Od73yHiYkJ3vzmN/OJT3yCkZERLrjgAvr6+iiXy3zsYx/j6aefZsuWLbzqVa9i3rx53HbbbQ2oTkRk/xoZBPcAy81sGbAZuIhgTKDa94EvmFkKyAC/BfzD83rVH14G23691+R8pcILihWymSRM976/R7wEVn1qn7OrL0O9Zs0avvvd73L33Xfj7rzpTW/ijjvuoL+/n0WLFvGDH/wACK5B1N7ezuc+9zluu+025s2bN72aREQOkobtGnL3EvBB4BbgYeA77v6gmX3AzD4QLvMw8CPgfuBu4Kvu/kCjajoU1qxZw5o1azj55JM55ZRTeOSRR9iwYQMveclLuPXWW/nIRz7Cz372M9rb22e6VBERoMEXnXP31cDqKdOunvL8s8BnD9qL7uOb++hYkSd3jnD0/BbymcY12925/PLLef/737/XvHvvvZfVq1dz+eWX89rXvpaPf/zjDatDRKReOrP4IKi+DPXrXvc6rr32WoaHhwHYvHkz27dvZ8uWLeTzeS6++GL+4i/+gvvuu2+vdUVEZkJ8LkPdQNWXoV61ahVvf/vbOfPMMwFoaWnhm9/8Jhs3buTDH/4wiUSCdDrNl770JQAuueQSVq1axcKFCzVYLCIzIjaXoR48RLuGDgVdhlpEpkuXoRYRkX1SEIiIxNycCYLZtovrQMWlnSJy6MyJIMjlcuzcubO+D8lZ/Dnq7uzcuZNcLjfTpYjIHDK7R01Dvb299PX1sb8L0o0Xy+wYLuC7smRSszf/crkcvb29M12GiMwhcyII0uk0y5Yt2+8yt63fzvu+fQ83/tFLefGRnYeoMhGRw9/s/Wo8Tbp1vYhItNgEwSSNtYqI1IpNENh0rzgqIhITsQmCZ6lLICJSLTZBoP6AiEi02ASBiIhEi10QaLBYRKRWbIJAY8UiItFiEwST1CEQEakVmyAwDReLiESKTRBM0hiBiEit2ASBxghERKLFJghERCRa7IJAN3YREakVmyDQniERkWixCYJJ6g+IiNSKTxCoSyAiEik+QRDSEIGISK3YBIFOKBMRiRabIJjkGiUQEakRmyDQCWUiItFiEwQiIhItfkGgPUMiIjUaGgRmdo6ZrTezjWZ2WcT8s8xswMzWhT8fb1gtjdqwiMgsl2rUhs0sCXwROBvoA+4xs5vd/aEpi/7M3d/QqDqmUodARKRWI3sEpwMb3f1xdy8A1wPnNfD19ss0WiwiEqmRQbAY2FT1vC+cNtWZZvYrM/uhmR0ftSEzu8TM1prZ2v7+/udVlE4oExGp1cggiPoKPvVj+D7gKHc/Cfg88L2oDbn7Ne6+0t1X9vT0HFgx6hCIiERqZBD0AUuqnvcCW6oXcPdBdx8OH68G0mY2r4E1iYjIFI0MgnuA5Wa2zMwywEXAzdULmNkRFu68N7PTw3p2NrAmnVksIjJFw44acveSmX0QuAVIAte6+4Nm9oFw/tXAW4H/YWYlYAy4yBt05xjtGRIRidawIIA9u3tWT5l2ddXjLwBfaGQNe9d0KF9NROTwF5szizVYLCISLTZBMEkdAhGRWjEKAnUJRESixCgIREQkSuyCoEEHJYmIzFqxCQINFouIRItNEExSf0BEpFZsgkAdAhGRaLEJgj3UJRARqRGbIND9CEREosUmCCbponMiIrViEwTqD4iIRItNEIiISLTYBYHOJxMRqRWbINBYsYhItNgEwST1CEREasUmCEzDxSIikWITBJPUIRARqRWbINAYgYhItNgEgYiIRItdEOh+BCIitWIXBCIiUit2QaD+gIhIrdgEgQaLRUSixSYIJmmIQESkVmyCQCeUiYhEi00QPEtdAhGRarEJAo0RiIhEi00QiIhItNgFgQaLRURqxSYItGtIRCRaXUFgZpeaWZsFvmZm95nZaxtdXCOoQyAiUqveHsG73X0QeC3QA/wh8KnnWsnMzjGz9Wa20cwu289yp5lZ2czeWmc906bDR0VEotUbBJOfoq8H/sndf1U1LXoFsyTwRWAVcBzwe2Z23D6W+zRwS71FPx8aIxARqVVvENxrZmsIguAWM2sFKs+xzunARnd/3N0LwPXAeRHL/QlwA7C9zloOiMYIRESipepc7j3ACuBxdx81sy6C3UP7sxjYVPW8D/it6gXMbDHwZuDVwGn72pCZXQJcAnDkkUfWWbKIiNSj3h7BmcB6d99tZhcDfwUMPMc6Ud/Bp+6YuQL4iLuX97chd7/G3Ve6+8qenp46S97HtjRcLCJSo94g+BIwamYnAX8JPAV84znW6QOWVD3vBbZMWWYlcL2ZPQm8FbjKzM6vs6Zp0Z4hEZFo9QZByYNbe50H/KO7/yPQ+hzr3AMsN7NlZpYBLgJurl7A3Ze5+1J3Xwp8F/gjd//edBowXRosFhGpVe8YwZCZXQ68E3hFeKRPen8ruHvJzD5IcDRQErjW3R80sw+E869+HnVPmwaLRUSi1RsEFwJvJzifYJuZHQl89rlWcvfVwOop0yIDwN3/oM5anhd1CEREatW1a8jdtwHfAtrN7A3AuLs/1xjBYUZdAhGRKPVeYuIC4G7gbcAFwF2NPAu4kVyDBCIiNerdNfRR4DR33w5gZj3ArQQDvCIiMovVe9RQYjIEQjunse5hQYPFIiLR6u0R/MjMbgGuC59fyJRBYBERmZ3qCgJ3/7CZvQV4GcGo6zXuflNDKzvI1CEQEYlWb48Ad7+B4OJws5rGikVEau03CMxsiOhD7w1wd29rSFUNYBokEBGJtN8gcPfnuozErKOLzomI1JpVR/48H+oPiIhEi00QiIhItNgFgQaLRURqxSYINFYsIhItNkEwST0CEZFasQkC03CxiEik2ATBJHUIRERqxSYINEYgIhItNkEgIiLRYhcEujGNiEit2AWBiIjUil0QqD8gIlIrNkGgwWIRkWixCYI91CUQEakRmyDQ/QhERKLFJggm6X4EIiK1YhME6g+IiESLTRCIiEi02AWBzicTEakVmyDQWLGISLTYBMEkdQhERGrFJgh0PwIRkWixCYJJGiMQEanV0CAws3PMbL2ZbTSzyyLmn2dm95vZOjNba2Yvb1wtjdqyiMjslmrUhs0sCXwROBvoA+4xs5vd/aGqxX4M3OzubmYnAt8BXtSomkREZG+N7BGcDmx098fdvQBcD5xXvYC7D/uzNwho5hCM5erMYhGRWo0MgsXApqrnfeG0Gmb2ZjN7BPgB8O6oDZnZJeGuo7X9/f0HVIz2DImIRGtkEER99u71ddzdb3L3FwHnA38TtSF3v8bdV7r7yp6enudVlAaLRURqNTII+oAlVc97gS37Wtjd7wBeaGbzGlKNugQiIpEaGQT3AMvNbJmZZYCLgJurFzCzoy28PrSZnQJkgJ0NrEkjBCIiUzTsqCF3L5nZB4FbgCRwrbs/aGYfCOdfDbwFeJeZFYEx4EJv0N3ldUKZiEi0hgUBgLuvBlZPmXZ11eNPA59uZA0RRR3SlxMROdzF7sxiERGpFZsg0JnFIiLRYhMEk7RjSESkVmyCQB0CEZFosQmCSRorFhGpFZsgMA0SiIhEik0QTGrQaQoiIrNWbIJA/QERkWixCQIREYkWuyDQjiERkVqxCQKNFYuIRItNEEzSWLGISK3YBIGuPioiEi02QTBJHQIRkVrxCQJ1CEREIsUnCEREJFLsgkBnFouI1IpNEOjwURGRaLEJAhERiRabIFCHQEQkWmyCYJKGCEREasUmCHQ/AhGRaLEJgkmuU8pERGrEJgjUHxARiRabIBARkWixCwINFouI1IpNEGisWEQkWmyCYJI6BCIitWITBLofgYhItNgEAYObWZW4i1RxZKYrERE5rMQmCJJb7uFLmX+kdXzrTJciInJYiU0QkGkBIF1Wj0BEpFpDg8DMzjGz9Wa20cwui5j/DjO7P/y508xOalQtnm0FIF0abtRLiIjMSg0LAjNLAl8EVgHHAb9nZsdNWewJ4JXufiLwN8A1jaqHTBAEGfUIRERqNLJHcDqw0d0fd/cCcD1wXvUC7n6nu+8Kn/4S6G1UMYlcEARnPHZlo15CRGRWamQQLAY2VT3vC6fty3uAH0bNMLNLzGytma3t7+8/oGLSTW0AtE9sOaD1RUTmqkYGQdSB+5Hnc5nZqwiC4CNR8939Gndf6e4re3p6DqyaXMeBrSciMsc1Mgj6gCVVz3uBvb6Om9mJwFeB89x9Z8OqSST4af517EjMa9hLiIjMRo0MgnuA5Wa2zMwywEXAzdULmNmRwI3AO9390QbWAkAimydTGW/0y4iIzCqpRm3Y3Utm9kHgFiAJXOvuD5rZB8L5VwMfB7qBq8I7iJXcfWWjakrlmsn5OO6uO5aJiIQaFgQA7r4aWD1l2tVVj98LvLeRNVTLNrWSsRKFq88ic+E/Q9eyQ/XSIiKHrficWQwceUQwPpB5eh3+XzqMVEQEYhYE3YuP3vPY7r0WBnXdIRGRWAWBHXNOzfMnf379DFUiInL4iFUQkM7BG67Y8/Qbd23mtke2UyxXZq4mEZEZZj7LbuK7cuVKX7t27fPbyP9u3/Pw1PEvMZjs4JXHzOczbz2RrubM86xQROTwY2b37uuozHgGwegz8Jlnjxh6Z+Ey1leW0G4jbPBezl+xiOULWjn/5MXk00k68mkdbiois5qCYF++fSE8+qOaSWeOf54ltp0uG+JHldP3TF91whE8sGWAS19zDC3ZFD2tGZZ2N+NAd3NGQSEihzUFwb5UyrDu23DzByNnX3nyD7jtwU08NphkZWI9AI96Lzu8nXGytXUd1Uk2nWB4okw2leDUozrp7WwCIJtKsnx+C13NGUYLZZZ0NVEsO225FMWyk06agkREGkpB8FyGt8MN74En7qh7lTJJvvbCK/nnJzpY3lGhvTJIoTBGvrCLG4ePB+AUe5Q2G+X2yorIbWSSCQrlCtlUgolShZZsile/aD4VdxzoymfYMTxBWy5NZzh20ZJNUiw7Xc0Zjj2ila0DY6QSCXo7m9g5XGBhR46F7U0kE8ZEsUxTJslYoUxP67PBVXFIGAofkRhREExHuQjbfg2P/QQeuw0Kw7B13bQ2MfjSy0hn8zTd9nEAtqy4lPSj/0FTeZhHX/RH3JU/i3yiwLaJJpoTBVo23cbq0qncvWmURe05CmXn1eNr+GjyXzh94ioslWG8VPsaRgWvOugrS4ESScoka5ZbZlt5VWId/1Q5h6QlSCWN8WKFhAWBcPT8FrYNjNPTmiWbSjBeLLOoo4lUMsG2gTGOnt9CMpHgmZEJWrNpOvJp3CGXTrCxf5itA+OcuLidU5d2MTJRIp1MMDRepH9oghVLOmjOpnCH9qY0j/UPs7gjCKklXXkGxoq05lK0ZFMMjhfpzGcoV5ymdJJ8Nkk2lWRwvIg7tOWCk+BLFSedfLbdulyISH0UBM9XpQKFIShNBCGxfjW0LICBTfDrGyDXDkMHcJ8DS4CHh64290A6H9xbOdsCm+7as5g3dcKL3kh5dBc+tgsyLaQ3BmMbI/klDC5+BQs3fJvB5mX8Kn8Gxw7+gvGmBWzvOZOVG64AYHv2KB6e9zp8aBttY5v5r54L6e7/JcWKcU75Nta3nsl9Lb9N2+6HaB/dxDfy72LnuNGWMwrWxI5duyh5gt9O3M87kj+mRJIOGyZHgXk2wGdKF/Gv5bMAo9e28/X0p/lw8f3c58vDaf28K7mGr5TOpZ92klQok+R4e4JnvI1tdPLW5B38sHw6w+SBZ3tMzYwxajlSiQTFcvD72pxJ4oUR7s++l79NvJ9bc6+l+ld58+4xFnc00d2SYWSiRFMmychEmbamNLiTSBjzW7OkkgnGCmUWtOUYHCtSqlQYK1bIJBPkM0mas0ly6SSDY6U9j8sVp1QqsWHbLo5ZNI8tu8cYnihRKjtnvaiHXCrJ3U88w7KeZha158CMwbEi2VSCTCqBmZFNBWHWmk2xfWiChe05do8VacmmSCaM7ubMnrYmDDryGZrSSR7aOkBLNk06aTRnU4wXy3S3ZCmUKlTcSZhRLFfoyKcZL5ZpyaYxg9FCmXKlQmsuCPJ00kglExTCnmjwBaFMNpUkYc9eL75Udhwnn0kpdGc5BcGhVhiF0R1QHAs+4HdsgGQKxgdg6OkgNEoFKE8Ey29/JDjHoTgOE0NBOPzmzme3t+AlMLQ1mD72zMy0qQ6ebaOc7yG167E90wptRzHRvIjWrb/Ya/ld3SfTufO/97m9nbkjyZaGaCntYkvLCQwn22guDbC++VQ8kWbB7nWcMH4vAD/pvggnSYIyA6kenhmZIJ+C3uITWDLNU76QkYkChfwCji5tZIg8W8aztBe28nRiPnkfh3QTI+kuFtozdExsZogWMuUR3sZ/cpO/kl3ewiAtPOkLuchu4YzEw/xp4Y9J4LTbCO9L/YB1laNJUmZV8h62eBefKL6LF9oWTkusZzctfLP0OxRI02JjnGBPUCTFA5WlHJPYzP9Nf42fl4/nitJbMKBEkh7bzQQZtnsHScokcHbRQoYSpyQ28JvKAgqkyFBimBwJnG4bYJ4NssPbeMqPYNwzODBBmqNsO602yojnGCHHgDezwHYxTBP93s4C280YGdoYJUeBLd7NWCJPzsqMlY1FLcausQoF0ixPPc1oooVyaYKl6d08VFhAJpvneN/AhvQxUCnx+Giehakh5qUnOGL0UdZlV9KTT9DiwwyMTtDUtZiUF5lItZBJpTjWH2NLpZMCaXpLv+HXiePIJ8tkyqO8fPRWXjH2Ez6U/3/M6+oEYOnEo+zMLMIxRp9ay33lo3n10hyZ5g46KrtZ8dTX2NZ2Ejkm2Djv1VQqsNNb6Mo581NjbCx0kaBMV6kf61pKuVBg11iRfHkYy7eTGeqjrSnDSL4XEgmaJ3YwkOykVIFsKkGrjZHItVGpOMOFMrlEhdbEGJZMM1DO0ZJLMTxeIp8NerSVSgXb/SQTlSSdXT2MJfK0lgcZSbaQSqbIMU4pkWOi5JTKRXramhkeL5JMBOOIxy9q4+QjOw/o71NBMBdVyoBBpRTsvpoYCn46lgS7t4a3w8j2YJnJ6YNbghv0ZFugfz2M74axXZCfB6M7g95OUycM9EHXCyDTDKksDD8NlgQvw+7fQDITzN98XxBY6XzwOgtPgtYFUBgJgqtUgHQTmMGW8AN/3rGwYz0sOiWofdv9wfR0MxSn3E+6qStoS2Godnp1T0piqUyCJAfnd6CCkcAZ9SwZiqRs7+2OepYJ0nTa8J5pRU+StjIAY57BMfI2sWf+kAcHi4yQI0nw99rMeM0y/d5Ojw0w6E2MkmM+uxmmiUHy9NoOBr2JQZppY4QBb2Hj0gt51bs/eUDt3F8QNPTqo9JAiXAsIJGBVBfku2rnN88DjqudtvCkZx8f8ZKGltdQ7mEQWBAylXLw3CtBSBSGg+mJVBBa5UKwTrkAE4NBcE0+b+oMQjDfHfTYCsPB/HQTjOyA0jhkW4N/0/lgmVQ26PV5+dnHloD23qCG4e1Bj7BtcRC0TZ1BPZaA3ZsAD2tLQ8dRsPVXwbzxAWhdGNSVbgqCslyESjF4jXIhfM2mYN2JQUjlgl4nwDOPB9OL40Fvs1SA1iMm37Rg1+b4QFDX8LbgC0IiFbTPEkHYWyLYLgaJBCSzwTrJTLDtZCb43SuNB8t4GcYHoXNpsF4iBVvWQc+xwbxyMVhu7Jmg7QuOC/6/SuMw0g+dy4Lf1eJosJ3+9UHN+e7gS8IRJwY960op2PaGNbD8bJKJVPCFY/dTsOhksAQlEnhhlPTE7uB9GX6akZLR1LmQyuguUp29QRuTKXxiGE+kSZTGSJSL8PQDNC04HrPw76o4gqfzsPMxWLSCpsII+dI4lZGdWMt8zMukSxP4wCYq3ceSwUmmc3immXKlQmVXH825PKVSiWbKVEgE/weVMoVtv8bLZay5m87WBZSf+ClNi04l29TNUBkSVOiqFBge2o419zAvlcKKo/SkssxbfmJD/qTUIxARiYH99Qjida0hERHZi4JARCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZibdSeUmVk/8NQBrj4P2HEQy5kN1OZ4UJvj4fm0+Sh374maMeuC4Pkws7X7OrNurlKb40FtjodGtVm7hkREYk5BICISc3ELgmtmuoAZoDbHg9ocDw1pc6zGCEREZG9x6xGIiMgUCgIRkZiLTRCY2Tlmtt7MNprZZTNdz8FiZkvM7DYze9jMHjSzS8PpXWb2n2a2Ify3s2qdy8P3Yb2ZvW7mqj9wZpY0s/82s/8In8/19naY2XfN7JHw//rMGLT5f4a/0w+Y2XVmlptrbTaza81su5k9UDVt2m00s1PN7NfhvCvNzKZViLvP+R8gCTwGvADIAL8Cjpvpug5S2xYCp4SPW4FHCe5R+RngsnD6ZcCnw8fHhe3PAsvC9yU50+04gHb/GfBt4D/C53O9vV8H3hs+zgAdc7nNwGLgCaApfP4d4A/mWpuB3wZOAR6omjbtNgJ3A2cCBvwQWDWdOuLSIzgd2Ojuj7t7AbgeOG+Gazoo3H2ru98XPh4CHib4IzqP4MOD8N/zw8fnAde7+4S7PwFsJHh/Zg0z6wXOBb5aNXkut7eN4APjawDuXnD33czhNodSQJOZpYA8sIU51mZ3vwN4ZsrkabXRzBYCbe7+Cw9S4RtV69QlLkGwGNhU9bwvnDanmNlS4GTgLmCBu2+FICyA+eFic+G9uAL4S6BSNW0ut/cFQD/wT+HusK+aWTNzuM3uvhn4O+A3wFZgwN3XMIfbXGW6bVwcPp46vW5xCYKo/WVz6rhZM2sBbgA+5O6D+1s0YtqseS/M7A3Adne/t95VIqbNmvaGUgS7D77k7icDIwS7DPZl1rc53C9+HsEukEVAs5ldvL9VIqbNqjbXYV9tfN5tj0sQ9AFLqp73EnQz5wQzSxOEwLfc/cZw8tNhl5Hw3+3h9Nn+XrwMeJOZPUmwi+/VZvZN5m57IWhDn7vfFT7/LkEwzOU2/w7whLv3u3sRuBF4KXO7zZOm28a+8PHU6XWLSxDcAyw3s2VmlgEuAm6e4ZoOivDogK8BD7v756pm3Qz8fvj494HvV02/yMyyZrYMWE4w0DQruPvl7t7r7ksJ/h9/4u4XM0fbC+Du24BNZnZsOOk1wEPM4TYT7BI6w8zy4e/4awjGv+ZymydNq43h7qMhMzsjfK/eVbVOfWZ61PwQjs6/nuCImseAj850PQexXS8n6AbeD6wLf14PdAM/BjaE/3ZVrfPR8H1YzzSPLjicfoCzePaooTndXmAFsDb8f/4e0BmDNn8CeAR4APgXgqNl5lSbgesIxkCKBN/s33MgbQRWhu/TY8AXCK8aUe+PLjEhIhJzcdk1JCIi+6AgEBGJOQWBiEjMKQhERGJOQSAiEnMKApFDyMzOmrxiqsjhQkEgIhJzCgKRCGZ2sZndbWbrzOzL4f0Phs3s783sPjP7sZn1hMuuMLNfmtn9ZnbT5PXjzexoM7vVzH4VrvPCcPMtVfcW+Na0rx0vcpApCESmMLMXAxcCL3P3FUAZeAfQDNzn7qcAPwX+OlzlG8BH3P1E4NdV078FfNHdTyK4Ts7WcPrJwIcIri//AoLrJ4nMmNRMFyByGHoNcCpwT/hlvYngwl8V4F/DZb4J3Ghm7UCHu/80nP514N/MrBVY7O43Abj7OEC4vbvdvS98vg5YCvy84a0S2QcFgcjeDPi6u19eM9HsY1OW29/1Wfa3u2ei6nEZ/R3KDNOuIZG9/Rh4q5nNhz33kD2K4O/lreEybwd+7u4DwC4ze0U4/Z3ATz24J0SfmZ0fbiNrZvlD2QiReumbiMgU7v6Qmf0VsMbMEgRXhvxjghvCHG9m9wIDBOMIEFwq+Orwg/5x4A/D6e8Evmxm/yfcxtsOYTNE6qarj4rUycyG3b1lpusQOdi0a0hEJObUIxARiTn1CEREYk5BICIScwoCEZGYUxCIiMScgkBEJOb+P3Ke+0LBKBBzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.title('model3 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 200)               2200      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 28,677\n",
      "Trainable params: 28,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = keras.models.Sequential([\n",
    "                    keras.layers.Input(shape=X_train.shape[1], name='input'),\n",
    "                    keras.layers.Dense(200, activation='softplus'),\n",
    "                    keras.layers.Dense(100, activation='softplus'),\n",
    "                    keras.layers.Dense(50, activation='softplus'),\n",
    "                    keras.layers.Dense(25, activation='softplus'),\n",
    "                    keras.layers.Dense(2, activation='softmax', name='output')\n",
    "                    ])\n",
    "\n",
    "model4.compile(\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            optimizer='Adamax',\n",
    "            metrics= ['accuracy']\n",
    "            )\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "120/120 [==============================] - 1s 3ms/step - loss: 0.9740 - accuracy: 0.8791 - val_loss: 0.1653 - val_accuracy: 0.9515\n",
      "Epoch 2/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.9482 - val_loss: 0.1612 - val_accuracy: 0.9515\n",
      "Epoch 3/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9541 - val_loss: 0.1677 - val_accuracy: 0.9515\n",
      "Epoch 4/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9551 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 5/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9558 - val_loss: 0.1614 - val_accuracy: 0.9515\n",
      "Epoch 6/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9540 - val_loss: 0.1855 - val_accuracy: 0.9515\n",
      "Epoch 7/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9539 - val_loss: 0.1669 - val_accuracy: 0.9515\n",
      "Epoch 8/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9524 - val_loss: 0.1692 - val_accuracy: 0.9515\n",
      "Epoch 9/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9449 - val_loss: 0.1551 - val_accuracy: 0.9515\n",
      "Epoch 10/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9531 - val_loss: 0.1725 - val_accuracy: 0.9515\n",
      "Epoch 11/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9562 - val_loss: 0.1719 - val_accuracy: 0.9499\n",
      "Epoch 12/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9477 - val_loss: 0.1600 - val_accuracy: 0.9515\n",
      "Epoch 13/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9560 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 14/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9506 - val_loss: 0.1626 - val_accuracy: 0.9515\n",
      "Epoch 15/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9511 - val_loss: 0.1511 - val_accuracy: 0.9515\n",
      "Epoch 16/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9587 - val_loss: 0.1568 - val_accuracy: 0.9515\n",
      "Epoch 17/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9482 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 18/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9428 - val_loss: 0.1577 - val_accuracy: 0.9515\n",
      "Epoch 19/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9509 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 20/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9481 - val_loss: 0.1532 - val_accuracy: 0.9515\n",
      "Epoch 21/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9522 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 22/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9560 - val_loss: 0.1760 - val_accuracy: 0.9515\n",
      "Epoch 23/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9504 - val_loss: 0.1727 - val_accuracy: 0.9515\n",
      "Epoch 24/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9489 - val_loss: 0.1626 - val_accuracy: 0.9515\n",
      "Epoch 25/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9506 - val_loss: 0.1528 - val_accuracy: 0.9515\n",
      "Epoch 26/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9526 - val_loss: 0.1612 - val_accuracy: 0.9515\n",
      "Epoch 27/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9494 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 28/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9518 - val_loss: 0.1533 - val_accuracy: 0.9515\n",
      "Epoch 29/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9568 - val_loss: 0.1593 - val_accuracy: 0.9515\n",
      "Epoch 30/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9525 - val_loss: 0.1665 - val_accuracy: 0.9515\n",
      "Epoch 31/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9532 - val_loss: 0.1560 - val_accuracy: 0.9515\n",
      "Epoch 32/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9448 - val_loss: 0.1520 - val_accuracy: 0.9515\n",
      "Epoch 33/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9471 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 34/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9569 - val_loss: 0.1536 - val_accuracy: 0.9515\n",
      "Epoch 35/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9485 - val_loss: 0.1611 - val_accuracy: 0.9515\n",
      "Epoch 36/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9488 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 37/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9496 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 38/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9492 - val_loss: 0.1509 - val_accuracy: 0.9515\n",
      "Epoch 39/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.9503 - val_loss: 0.1590 - val_accuracy: 0.9515\n",
      "Epoch 40/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9537 - val_loss: 0.1533 - val_accuracy: 0.9515\n",
      "Epoch 41/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9524 - val_loss: 0.1523 - val_accuracy: 0.9515\n",
      "Epoch 42/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1688 - accuracy: 0.9495 - val_loss: 0.1509 - val_accuracy: 0.9515\n",
      "Epoch 43/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9498 - val_loss: 0.1514 - val_accuracy: 0.9515\n",
      "Epoch 44/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9503 - val_loss: 0.1524 - val_accuracy: 0.9515\n",
      "Epoch 45/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9550 - val_loss: 0.1575 - val_accuracy: 0.9515\n",
      "Epoch 46/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9537 - val_loss: 0.1543 - val_accuracy: 0.9515\n",
      "Epoch 47/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9492 - val_loss: 0.1527 - val_accuracy: 0.9515\n",
      "Epoch 48/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9516 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 49/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9559 - val_loss: 0.1533 - val_accuracy: 0.9515\n",
      "Epoch 50/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9503 - val_loss: 0.1496 - val_accuracy: 0.9515\n",
      "Epoch 51/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9517 - val_loss: 0.1613 - val_accuracy: 0.9515\n",
      "Epoch 52/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9575 - val_loss: 0.1517 - val_accuracy: 0.9515\n",
      "Epoch 53/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9533 - val_loss: 0.1579 - val_accuracy: 0.9515\n",
      "Epoch 54/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9537 - val_loss: 0.1516 - val_accuracy: 0.9515\n",
      "Epoch 55/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9513 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 56/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9508 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 57/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9553 - val_loss: 0.1520 - val_accuracy: 0.9515\n",
      "Epoch 58/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9546 - val_loss: 0.1521 - val_accuracy: 0.9515\n",
      "Epoch 59/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9543 - val_loss: 0.1580 - val_accuracy: 0.9515\n",
      "Epoch 60/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9488 - val_loss: 0.1517 - val_accuracy: 0.9515\n",
      "Epoch 61/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9489 - val_loss: 0.1576 - val_accuracy: 0.9515\n",
      "Epoch 62/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9577 - val_loss: 0.1524 - val_accuracy: 0.9515\n",
      "Epoch 63/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9485 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 64/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9540 - val_loss: 0.1532 - val_accuracy: 0.9515\n",
      "Epoch 65/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9526 - val_loss: 0.1520 - val_accuracy: 0.9515\n",
      "Epoch 66/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9527 - val_loss: 0.1527 - val_accuracy: 0.9515\n",
      "Epoch 67/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9495 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 68/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9508 - val_loss: 0.1598 - val_accuracy: 0.9515\n",
      "Epoch 69/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9507 - val_loss: 0.1612 - val_accuracy: 0.9515\n",
      "Epoch 70/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9554 - val_loss: 0.1504 - val_accuracy: 0.9515\n",
      "Epoch 71/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9539 - val_loss: 0.1552 - val_accuracy: 0.9507\n",
      "Epoch 72/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9524 - val_loss: 0.1516 - val_accuracy: 0.9515\n",
      "Epoch 73/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9490 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 74/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9469 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 75/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9547 - val_loss: 0.1573 - val_accuracy: 0.9515\n",
      "Epoch 76/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9489 - val_loss: 0.1524 - val_accuracy: 0.9515\n",
      "Epoch 77/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9561 - val_loss: 0.1549 - val_accuracy: 0.9515\n",
      "Epoch 78/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9472 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 79/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9542 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 80/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9544 - val_loss: 0.1538 - val_accuracy: 0.9507\n",
      "Epoch 81/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9543 - val_loss: 0.1674 - val_accuracy: 0.9515\n",
      "Epoch 82/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9485 - val_loss: 0.1546 - val_accuracy: 0.9507\n",
      "Epoch 83/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9496 - val_loss: 0.1587 - val_accuracy: 0.9507\n",
      "Epoch 84/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9481 - val_loss: 0.1510 - val_accuracy: 0.9515\n",
      "Epoch 85/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9486 - val_loss: 0.1518 - val_accuracy: 0.9515\n",
      "Epoch 86/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9488 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
      "Epoch 87/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9481 - val_loss: 0.1509 - val_accuracy: 0.9515\n",
      "Epoch 88/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9572 - val_loss: 0.1528 - val_accuracy: 0.9515\n",
      "Epoch 89/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9489 - val_loss: 0.1535 - val_accuracy: 0.9515\n",
      "Epoch 90/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9479 - val_loss: 0.1614 - val_accuracy: 0.9515\n",
      "Epoch 91/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9483 - val_loss: 0.1515 - val_accuracy: 0.9507\n",
      "Epoch 92/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9523 - val_loss: 0.1569 - val_accuracy: 0.9507\n",
      "Epoch 93/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9524 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 94/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9563 - val_loss: 0.1542 - val_accuracy: 0.9507\n",
      "Epoch 95/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.9416 - val_loss: 0.1524 - val_accuracy: 0.9515\n",
      "Epoch 96/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9532 - val_loss: 0.1525 - val_accuracy: 0.9515\n",
      "Epoch 97/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.9493 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 98/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9473 - val_loss: 0.1522 - val_accuracy: 0.9515\n",
      "Epoch 99/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9498 - val_loss: 0.1517 - val_accuracy: 0.9515\n",
      "Epoch 100/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9537 - val_loss: 0.1522 - val_accuracy: 0.9507\n",
      "Epoch 101/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9489 - val_loss: 0.1573 - val_accuracy: 0.9476\n",
      "Epoch 102/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9516 - val_loss: 0.1532 - val_accuracy: 0.9515\n",
      "Epoch 103/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9476 - val_loss: 0.1618 - val_accuracy: 0.9507\n",
      "Epoch 104/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9457 - val_loss: 0.1535 - val_accuracy: 0.9507\n",
      "Epoch 105/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9489 - val_loss: 0.1554 - val_accuracy: 0.9515\n",
      "Epoch 106/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9520 - val_loss: 0.1699 - val_accuracy: 0.9515\n",
      "Epoch 107/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9507 - val_loss: 0.1519 - val_accuracy: 0.9499\n",
      "Epoch 108/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9475 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 109/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9500 - val_loss: 0.1527 - val_accuracy: 0.9507\n",
      "Epoch 110/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9489 - val_loss: 0.1526 - val_accuracy: 0.9507\n",
      "Epoch 111/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9438 - val_loss: 0.1555 - val_accuracy: 0.9507\n",
      "Epoch 112/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9555 - val_loss: 0.1679 - val_accuracy: 0.9484\n",
      "Epoch 113/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9551 - val_loss: 0.1526 - val_accuracy: 0.9507\n",
      "Epoch 114/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9538 - val_loss: 0.1532 - val_accuracy: 0.9507\n",
      "Epoch 115/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9518 - val_loss: 0.1519 - val_accuracy: 0.9507\n",
      "Epoch 116/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9547 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 117/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9551 - val_loss: 0.1543 - val_accuracy: 0.9507\n",
      "Epoch 118/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9527 - val_loss: 0.1543 - val_accuracy: 0.9491\n",
      "Epoch 119/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.9439 - val_loss: 0.1901 - val_accuracy: 0.9515\n",
      "Epoch 120/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9502 - val_loss: 0.1524 - val_accuracy: 0.9499\n",
      "Epoch 121/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9493 - val_loss: 0.1548 - val_accuracy: 0.9515\n",
      "Epoch 122/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9527 - val_loss: 0.1558 - val_accuracy: 0.9515\n",
      "Epoch 123/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9540 - val_loss: 0.1550 - val_accuracy: 0.9507\n",
      "Epoch 124/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9524 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 125/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9534 - val_loss: 0.1519 - val_accuracy: 0.9499\n",
      "Epoch 126/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9558 - val_loss: 0.1553 - val_accuracy: 0.9507\n",
      "Epoch 127/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9522 - val_loss: 0.1546 - val_accuracy: 0.9499\n",
      "Epoch 128/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9533 - val_loss: 0.1545 - val_accuracy: 0.9515\n",
      "Epoch 129/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9437 - val_loss: 0.1527 - val_accuracy: 0.9515\n",
      "Epoch 130/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9502 - val_loss: 0.1568 - val_accuracy: 0.9484\n",
      "Epoch 131/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9487 - val_loss: 0.1539 - val_accuracy: 0.9507\n",
      "Epoch 132/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9534 - val_loss: 0.1611 - val_accuracy: 0.9507\n",
      "Epoch 133/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9546 - val_loss: 0.1534 - val_accuracy: 0.9507\n",
      "Epoch 134/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9494 - val_loss: 0.1527 - val_accuracy: 0.9491\n",
      "Epoch 135/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9494 - val_loss: 0.1531 - val_accuracy: 0.9499\n",
      "Epoch 136/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9470 - val_loss: 0.1562 - val_accuracy: 0.9491\n",
      "Epoch 137/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9508 - val_loss: 0.1510 - val_accuracy: 0.9499\n",
      "Epoch 138/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9521 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
      "Epoch 139/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9497 - val_loss: 0.1546 - val_accuracy: 0.9491\n",
      "Epoch 140/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9510 - val_loss: 0.1711 - val_accuracy: 0.9515\n",
      "Epoch 141/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9544 - val_loss: 0.1530 - val_accuracy: 0.9515\n",
      "Epoch 142/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9539 - val_loss: 0.1528 - val_accuracy: 0.9499\n",
      "Epoch 143/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9529 - val_loss: 0.1521 - val_accuracy: 0.9499\n",
      "Epoch 144/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9566 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 145/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9518 - val_loss: 0.1589 - val_accuracy: 0.9507\n",
      "Epoch 146/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9494 - val_loss: 0.1516 - val_accuracy: 0.9499\n",
      "Epoch 147/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9539 - val_loss: 0.1560 - val_accuracy: 0.9507\n",
      "Epoch 148/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.9503 - val_loss: 0.1522 - val_accuracy: 0.9507\n",
      "Epoch 149/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9470 - val_loss: 0.1538 - val_accuracy: 0.9491\n",
      "Epoch 150/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9591 - val_loss: 0.1584 - val_accuracy: 0.9484\n",
      "Epoch 151/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9505 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 152/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9566 - val_loss: 0.1549 - val_accuracy: 0.9484\n",
      "Epoch 153/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9577 - val_loss: 0.1539 - val_accuracy: 0.9515\n",
      "Epoch 154/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9523 - val_loss: 0.1538 - val_accuracy: 0.9515\n",
      "Epoch 155/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9592 - val_loss: 0.1540 - val_accuracy: 0.9499\n",
      "Epoch 156/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9547 - val_loss: 0.1557 - val_accuracy: 0.9499\n",
      "Epoch 157/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9543 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 158/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9511 - val_loss: 0.1536 - val_accuracy: 0.9515\n",
      "Epoch 159/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9520 - val_loss: 0.1577 - val_accuracy: 0.9515\n",
      "Epoch 160/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9520 - val_loss: 0.1576 - val_accuracy: 0.9507\n",
      "Epoch 161/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9530 - val_loss: 0.1634 - val_accuracy: 0.9515\n",
      "Epoch 162/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9569 - val_loss: 0.1534 - val_accuracy: 0.9491\n",
      "Epoch 163/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9510 - val_loss: 0.1581 - val_accuracy: 0.9515\n",
      "Epoch 164/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9542 - val_loss: 0.1528 - val_accuracy: 0.9499\n",
      "Epoch 165/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9476 - val_loss: 0.1569 - val_accuracy: 0.9491\n",
      "Epoch 166/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9434 - val_loss: 0.1592 - val_accuracy: 0.9515\n",
      "Epoch 167/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9500 - val_loss: 0.1526 - val_accuracy: 0.9507\n",
      "Epoch 168/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9546 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 169/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9579 - val_loss: 0.1538 - val_accuracy: 0.9507\n",
      "Epoch 170/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9489 - val_loss: 0.1527 - val_accuracy: 0.9507\n",
      "Epoch 171/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9492 - val_loss: 0.1618 - val_accuracy: 0.9515\n",
      "Epoch 172/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9583 - val_loss: 0.1586 - val_accuracy: 0.9484\n",
      "Epoch 173/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9458 - val_loss: 0.1601 - val_accuracy: 0.9507\n",
      "Epoch 174/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9502 - val_loss: 0.1651 - val_accuracy: 0.9452\n",
      "Epoch 175/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9493 - val_loss: 0.1549 - val_accuracy: 0.9491\n",
      "Epoch 176/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9500 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 177/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9557 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 178/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9483 - val_loss: 0.1570 - val_accuracy: 0.9499\n",
      "Epoch 179/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9519 - val_loss: 0.1645 - val_accuracy: 0.9515\n",
      "Epoch 180/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9460 - val_loss: 0.1556 - val_accuracy: 0.9491\n",
      "Epoch 181/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9501 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 182/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9517 - val_loss: 0.1532 - val_accuracy: 0.9507\n",
      "Epoch 183/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9500 - val_loss: 0.1539 - val_accuracy: 0.9507\n",
      "Epoch 184/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9503 - val_loss: 0.1528 - val_accuracy: 0.9507\n",
      "Epoch 185/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9494 - val_loss: 0.1555 - val_accuracy: 0.9507\n",
      "Epoch 186/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9557 - val_loss: 0.1571 - val_accuracy: 0.9507\n",
      "Epoch 187/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9528 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 188/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9495 - val_loss: 0.1562 - val_accuracy: 0.9515\n",
      "Epoch 189/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9527 - val_loss: 0.1625 - val_accuracy: 0.9515\n",
      "Epoch 190/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9549 - val_loss: 0.1561 - val_accuracy: 0.9515\n",
      "Epoch 191/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9542 - val_loss: 0.1542 - val_accuracy: 0.9515\n",
      "Epoch 192/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9493 - val_loss: 0.1534 - val_accuracy: 0.9491\n",
      "Epoch 193/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9546 - val_loss: 0.1586 - val_accuracy: 0.9499\n",
      "Epoch 194/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9463 - val_loss: 0.1553 - val_accuracy: 0.9515\n",
      "Epoch 195/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9523 - val_loss: 0.1560 - val_accuracy: 0.9476\n",
      "Epoch 196/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9502 - val_loss: 0.1655 - val_accuracy: 0.9515\n",
      "Epoch 197/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9545 - val_loss: 0.1562 - val_accuracy: 0.9507\n",
      "Epoch 198/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9449 - val_loss: 0.1571 - val_accuracy: 0.9507\n",
      "Epoch 199/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9566 - val_loss: 0.1589 - val_accuracy: 0.9515\n",
      "Epoch 200/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9541 - val_loss: 0.1561 - val_accuracy: 0.9507\n",
      "Epoch 201/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9493 - val_loss: 0.1544 - val_accuracy: 0.9499\n",
      "Epoch 202/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9467 - val_loss: 0.1571 - val_accuracy: 0.9515\n",
      "Epoch 203/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9475 - val_loss: 0.1611 - val_accuracy: 0.9507\n",
      "Epoch 204/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9557 - val_loss: 0.1565 - val_accuracy: 0.9491\n",
      "Epoch 205/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9496 - val_loss: 0.1547 - val_accuracy: 0.9507\n",
      "Epoch 206/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9487 - val_loss: 0.1540 - val_accuracy: 0.9491\n",
      "Epoch 207/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9543 - val_loss: 0.1584 - val_accuracy: 0.9507\n",
      "Epoch 208/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9561 - val_loss: 0.1569 - val_accuracy: 0.9499\n",
      "Epoch 209/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9527 - val_loss: 0.1555 - val_accuracy: 0.9476\n",
      "Epoch 210/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9528 - val_loss: 0.1587 - val_accuracy: 0.9499\n",
      "Epoch 211/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9515 - val_loss: 0.1737 - val_accuracy: 0.9515\n",
      "Epoch 212/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9489 - val_loss: 0.1607 - val_accuracy: 0.9507\n",
      "Epoch 213/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9467 - val_loss: 0.1596 - val_accuracy: 0.9507\n",
      "Epoch 214/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9530 - val_loss: 0.1611 - val_accuracy: 0.9491\n",
      "Epoch 215/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9535 - val_loss: 0.1534 - val_accuracy: 0.9491\n",
      "Epoch 216/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9467 - val_loss: 0.1606 - val_accuracy: 0.9515\n",
      "Epoch 217/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9534 - val_loss: 0.1565 - val_accuracy: 0.9507\n",
      "Epoch 218/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9605 - val_loss: 0.1618 - val_accuracy: 0.9515\n",
      "Epoch 219/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9533 - val_loss: 0.1541 - val_accuracy: 0.9491\n",
      "Epoch 220/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9483 - val_loss: 0.1540 - val_accuracy: 0.9484\n",
      "Epoch 221/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9503 - val_loss: 0.1592 - val_accuracy: 0.9507\n",
      "Epoch 222/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9515 - val_loss: 0.1533 - val_accuracy: 0.9484\n",
      "Epoch 223/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9521 - val_loss: 0.1559 - val_accuracy: 0.9515\n",
      "Epoch 224/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9539 - val_loss: 0.1559 - val_accuracy: 0.9484\n",
      "Epoch 225/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9559 - val_loss: 0.1568 - val_accuracy: 0.9507\n",
      "Epoch 226/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9549 - val_loss: 0.1569 - val_accuracy: 0.9515\n",
      "Epoch 227/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9527 - val_loss: 0.1545 - val_accuracy: 0.9507\n",
      "Epoch 228/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9499 - val_loss: 0.1551 - val_accuracy: 0.9491\n",
      "Epoch 229/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9579 - val_loss: 0.1579 - val_accuracy: 0.9507\n",
      "Epoch 230/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9471 - val_loss: 0.1548 - val_accuracy: 0.9491\n",
      "Epoch 231/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9503 - val_loss: 0.1619 - val_accuracy: 0.9515\n",
      "Epoch 232/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9575 - val_loss: 0.1555 - val_accuracy: 0.9491\n",
      "Epoch 233/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9510 - val_loss: 0.1542 - val_accuracy: 0.9499\n",
      "Epoch 234/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9523 - val_loss: 0.1599 - val_accuracy: 0.9491\n",
      "Epoch 235/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9563 - val_loss: 0.1564 - val_accuracy: 0.9507\n",
      "Epoch 236/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9474 - val_loss: 0.1587 - val_accuracy: 0.9507\n",
      "Epoch 237/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9552 - val_loss: 0.1572 - val_accuracy: 0.9507\n",
      "Epoch 238/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9479 - val_loss: 0.1564 - val_accuracy: 0.9507\n",
      "Epoch 239/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9576 - val_loss: 0.1557 - val_accuracy: 0.9491\n",
      "Epoch 240/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9514 - val_loss: 0.1610 - val_accuracy: 0.9507\n",
      "Epoch 241/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.95 - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9509 - val_loss: 0.1525 - val_accuracy: 0.9491\n",
      "Epoch 242/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9524 - val_loss: 0.1555 - val_accuracy: 0.9499\n",
      "Epoch 243/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9460 - val_loss: 0.1625 - val_accuracy: 0.9515\n",
      "Epoch 244/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9491 - val_loss: 0.1636 - val_accuracy: 0.9515\n",
      "Epoch 245/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9504 - val_loss: 0.1573 - val_accuracy: 0.9507\n",
      "Epoch 246/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9489 - val_loss: 0.1554 - val_accuracy: 0.9484\n",
      "Epoch 247/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9545 - val_loss: 0.1589 - val_accuracy: 0.9484\n",
      "Epoch 248/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9530 - val_loss: 0.1664 - val_accuracy: 0.9499\n",
      "Epoch 249/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9549 - val_loss: 0.1651 - val_accuracy: 0.9515\n",
      "Epoch 250/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.9470 - val_loss: 0.1615 - val_accuracy: 0.9499\n",
      "Epoch 251/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9433 - val_loss: 0.1579 - val_accuracy: 0.9507\n",
      "Epoch 252/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.9454 - val_loss: 0.1601 - val_accuracy: 0.9507\n",
      "Epoch 253/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9483 - val_loss: 0.1572 - val_accuracy: 0.9484\n",
      "Epoch 254/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9522 - val_loss: 0.1578 - val_accuracy: 0.9491\n",
      "Epoch 255/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9494 - val_loss: 0.1585 - val_accuracy: 0.9484\n",
      "Epoch 256/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9558 - val_loss: 0.1580 - val_accuracy: 0.9507\n",
      "Epoch 257/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9547 - val_loss: 0.1607 - val_accuracy: 0.9515\n",
      "Epoch 258/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9552 - val_loss: 0.1613 - val_accuracy: 0.9515\n",
      "Epoch 259/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9551 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 260/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9536 - val_loss: 0.1629 - val_accuracy: 0.9491\n",
      "Epoch 261/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9516 - val_loss: 0.1633 - val_accuracy: 0.9507\n",
      "Epoch 262/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9525 - val_loss: 0.1573 - val_accuracy: 0.9507\n",
      "Epoch 263/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.9483 - val_loss: 0.1558 - val_accuracy: 0.9491\n",
      "Epoch 264/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9517 - val_loss: 0.1583 - val_accuracy: 0.9499\n",
      "Epoch 265/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9538 - val_loss: 0.1607 - val_accuracy: 0.9476\n",
      "Epoch 266/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9491 - val_loss: 0.1679 - val_accuracy: 0.9523\n",
      "Epoch 267/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9601 - val_loss: 0.1597 - val_accuracy: 0.9476\n",
      "Epoch 268/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9528 - val_loss: 0.1614 - val_accuracy: 0.9491\n",
      "Epoch 269/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9520 - val_loss: 0.1561 - val_accuracy: 0.9507\n",
      "Epoch 270/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9550 - val_loss: 0.1590 - val_accuracy: 0.9515\n",
      "Epoch 271/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9549 - val_loss: 0.1632 - val_accuracy: 0.9507\n",
      "Epoch 272/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9444 - val_loss: 0.1687 - val_accuracy: 0.9523\n",
      "Epoch 273/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9487 - val_loss: 0.1636 - val_accuracy: 0.9507\n",
      "Epoch 274/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9514 - val_loss: 0.1592 - val_accuracy: 0.9499\n",
      "Epoch 275/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9526 - val_loss: 0.1803 - val_accuracy: 0.9515\n",
      "Epoch 276/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9503 - val_loss: 0.1590 - val_accuracy: 0.9507\n",
      "Epoch 277/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9527 - val_loss: 0.1548 - val_accuracy: 0.9507\n",
      "Epoch 278/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9541 - val_loss: 0.1554 - val_accuracy: 0.9484\n",
      "Epoch 279/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9551 - val_loss: 0.1587 - val_accuracy: 0.9507\n",
      "Epoch 280/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9523 - val_loss: 0.1569 - val_accuracy: 0.9484\n",
      "Epoch 281/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9538 - val_loss: 0.1641 - val_accuracy: 0.9515\n",
      "Epoch 282/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9504 - val_loss: 0.1727 - val_accuracy: 0.9507\n",
      "Epoch 283/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9511 - val_loss: 0.1616 - val_accuracy: 0.9460\n",
      "Epoch 284/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9487 - val_loss: 0.1570 - val_accuracy: 0.9507\n",
      "Epoch 285/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9562 - val_loss: 0.1652 - val_accuracy: 0.9507\n",
      "Epoch 286/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9429 - val_loss: 0.1651 - val_accuracy: 0.9507\n",
      "Epoch 287/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9484 - val_loss: 0.1714 - val_accuracy: 0.9507\n",
      "Epoch 288/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9468 - val_loss: 0.1636 - val_accuracy: 0.9507\n",
      "Epoch 289/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9513 - val_loss: 0.1570 - val_accuracy: 0.9468\n",
      "Epoch 290/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9534 - val_loss: 0.1625 - val_accuracy: 0.9507\n",
      "Epoch 291/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9520 - val_loss: 0.1707 - val_accuracy: 0.9491\n",
      "Epoch 292/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9492 - val_loss: 0.1590 - val_accuracy: 0.9499\n",
      "Epoch 293/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9481 - val_loss: 0.1557 - val_accuracy: 0.9499\n",
      "Epoch 294/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9506 - val_loss: 0.1636 - val_accuracy: 0.9499\n",
      "Epoch 295/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9505 - val_loss: 0.1562 - val_accuracy: 0.9491\n",
      "Epoch 296/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9535 - val_loss: 0.1567 - val_accuracy: 0.9499\n",
      "Epoch 297/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9564 - val_loss: 0.1631 - val_accuracy: 0.9491\n",
      "Epoch 298/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9548 - val_loss: 0.1674 - val_accuracy: 0.9484\n",
      "Epoch 299/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9515 - val_loss: 0.1566 - val_accuracy: 0.9476\n",
      "Epoch 300/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9556 - val_loss: 0.1627 - val_accuracy: 0.9507\n",
      "Epoch 301/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9585 - val_loss: 0.1571 - val_accuracy: 0.9499\n",
      "Epoch 302/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9487 - val_loss: 0.1593 - val_accuracy: 0.9491\n",
      "Epoch 303/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9514 - val_loss: 0.1619 - val_accuracy: 0.9484\n",
      "Epoch 304/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9523 - val_loss: 0.1638 - val_accuracy: 0.9484\n",
      "Epoch 305/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9531 - val_loss: 0.1612 - val_accuracy: 0.9484\n",
      "Epoch 306/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9529 - val_loss: 0.1591 - val_accuracy: 0.9507\n",
      "Epoch 307/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9575 - val_loss: 0.1629 - val_accuracy: 0.9507\n",
      "Epoch 308/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9536 - val_loss: 0.1606 - val_accuracy: 0.9499\n",
      "Epoch 309/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9561 - val_loss: 0.1550 - val_accuracy: 0.9491\n",
      "Epoch 310/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9484 - val_loss: 0.1640 - val_accuracy: 0.9484\n",
      "Epoch 311/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9551 - val_loss: 0.1565 - val_accuracy: 0.9484\n",
      "Epoch 312/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9544 - val_loss: 0.1578 - val_accuracy: 0.9484\n",
      "Epoch 313/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9493 - val_loss: 0.1650 - val_accuracy: 0.9507\n",
      "Epoch 314/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9479 - val_loss: 0.1570 - val_accuracy: 0.9507\n",
      "Epoch 315/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9517 - val_loss: 0.1653 - val_accuracy: 0.9499\n",
      "Epoch 316/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9535 - val_loss: 0.1585 - val_accuracy: 0.9476\n",
      "Epoch 317/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9529 - val_loss: 0.1585 - val_accuracy: 0.9484\n",
      "Epoch 318/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9507 - val_loss: 0.1744 - val_accuracy: 0.9507\n",
      "Epoch 319/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9528 - val_loss: 0.1615 - val_accuracy: 0.9484\n",
      "Epoch 320/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9546 - val_loss: 0.1632 - val_accuracy: 0.9484\n",
      "Epoch 321/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9551 - val_loss: 0.1583 - val_accuracy: 0.9484\n",
      "Epoch 322/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9493 - val_loss: 0.1580 - val_accuracy: 0.9491\n",
      "Epoch 323/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9553 - val_loss: 0.1591 - val_accuracy: 0.9499\n",
      "Epoch 324/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1380 - accuracy: 0.9545 - val_loss: 0.1604 - val_accuracy: 0.9515\n",
      "Epoch 325/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9527 - val_loss: 0.1583 - val_accuracy: 0.9507\n",
      "Epoch 326/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9496 - val_loss: 0.1731 - val_accuracy: 0.9499\n",
      "Epoch 327/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9517 - val_loss: 0.1593 - val_accuracy: 0.9484\n",
      "Epoch 328/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9498 - val_loss: 0.1550 - val_accuracy: 0.9491\n",
      "Epoch 329/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9495 - val_loss: 0.1577 - val_accuracy: 0.9468\n",
      "Epoch 330/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9531 - val_loss: 0.1694 - val_accuracy: 0.9476\n",
      "Epoch 331/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9517 - val_loss: 0.1539 - val_accuracy: 0.9468\n",
      "Epoch 332/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9557 - val_loss: 0.1588 - val_accuracy: 0.9468\n",
      "Epoch 333/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9546 - val_loss: 0.1603 - val_accuracy: 0.9499\n",
      "Epoch 334/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9516 - val_loss: 0.1582 - val_accuracy: 0.9499\n",
      "Epoch 335/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9512 - val_loss: 0.1563 - val_accuracy: 0.9507\n",
      "Epoch 336/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9525 - val_loss: 0.1536 - val_accuracy: 0.9507\n",
      "Epoch 337/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9519 - val_loss: 0.1573 - val_accuracy: 0.9468\n",
      "Epoch 338/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9533 - val_loss: 0.1628 - val_accuracy: 0.9507\n",
      "Epoch 339/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9547 - val_loss: 0.1636 - val_accuracy: 0.9476\n",
      "Epoch 340/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9583 - val_loss: 0.1612 - val_accuracy: 0.9452\n",
      "Epoch 341/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9512 - val_loss: 0.1570 - val_accuracy: 0.9468\n",
      "Epoch 342/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9570 - val_loss: 0.1637 - val_accuracy: 0.9507\n",
      "Epoch 343/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9531 - val_loss: 0.1724 - val_accuracy: 0.9507\n",
      "Epoch 344/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9516 - val_loss: 0.1635 - val_accuracy: 0.9499\n",
      "Epoch 345/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9499 - val_loss: 0.1597 - val_accuracy: 0.9484\n",
      "Epoch 346/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9552 - val_loss: 0.1683 - val_accuracy: 0.9468\n",
      "Epoch 347/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9510 - val_loss: 0.1590 - val_accuracy: 0.9460\n",
      "Epoch 348/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9503 - val_loss: 0.1606 - val_accuracy: 0.9491\n",
      "Epoch 349/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9567 - val_loss: 0.1660 - val_accuracy: 0.9484\n",
      "Epoch 350/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9467 - val_loss: 0.1583 - val_accuracy: 0.9507\n",
      "Epoch 351/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9424 - val_loss: 0.1685 - val_accuracy: 0.9507\n",
      "Epoch 352/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9550 - val_loss: 0.1573 - val_accuracy: 0.9460\n",
      "Epoch 353/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9553 - val_loss: 0.1632 - val_accuracy: 0.9507\n",
      "Epoch 354/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9549 - val_loss: 0.1655 - val_accuracy: 0.9468\n",
      "Epoch 355/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9518 - val_loss: 0.1697 - val_accuracy: 0.9499\n",
      "Epoch 356/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9493 - val_loss: 0.1613 - val_accuracy: 0.9491\n",
      "Epoch 357/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9547 - val_loss: 0.1665 - val_accuracy: 0.9507\n",
      "Epoch 358/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9503 - val_loss: 0.1619 - val_accuracy: 0.9476\n",
      "Epoch 359/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9521 - val_loss: 0.1661 - val_accuracy: 0.9499\n",
      "Epoch 360/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: 0.1728 - val_accuracy: 0.9499\n",
      "Epoch 361/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9582 - val_loss: 0.1627 - val_accuracy: 0.9476\n",
      "Epoch 362/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9558 - val_loss: 0.1639 - val_accuracy: 0.9460\n",
      "Epoch 363/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9515 - val_loss: 0.1613 - val_accuracy: 0.9468\n",
      "Epoch 364/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9549 - val_loss: 0.1618 - val_accuracy: 0.9468\n",
      "Epoch 365/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9571 - val_loss: 0.1599 - val_accuracy: 0.9468\n",
      "Epoch 366/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9543 - val_loss: 0.1606 - val_accuracy: 0.9468\n",
      "Epoch 367/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9547 - val_loss: 0.1661 - val_accuracy: 0.9468\n",
      "Epoch 368/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9443 - val_loss: 0.1609 - val_accuracy: 0.9452\n",
      "Epoch 369/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9504 - val_loss: 0.1680 - val_accuracy: 0.9484\n",
      "Epoch 370/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9563 - val_loss: 0.1715 - val_accuracy: 0.9468\n",
      "Epoch 371/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9562 - val_loss: 0.1641 - val_accuracy: 0.9460\n",
      "Epoch 372/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9530 - val_loss: 0.1647 - val_accuracy: 0.9499\n",
      "Epoch 373/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9546 - val_loss: 0.1633 - val_accuracy: 0.9460\n",
      "Epoch 374/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9588 - val_loss: 0.1693 - val_accuracy: 0.9507\n",
      "Epoch 375/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9508 - val_loss: 0.1781 - val_accuracy: 0.9507\n",
      "Epoch 376/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9507 - val_loss: 0.1659 - val_accuracy: 0.9499\n",
      "Epoch 377/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9574 - val_loss: 0.1733 - val_accuracy: 0.9476\n",
      "Epoch 378/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9564 - val_loss: 0.1612 - val_accuracy: 0.9460\n",
      "Epoch 379/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.9552 - val_loss: 0.1641 - val_accuracy: 0.9484\n",
      "Epoch 380/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9509 - val_loss: 0.1829 - val_accuracy: 0.9507\n",
      "Epoch 381/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9523 - val_loss: 0.1768 - val_accuracy: 0.9491\n",
      "Epoch 382/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9532 - val_loss: 0.1642 - val_accuracy: 0.9507\n",
      "Epoch 383/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9509 - val_loss: 0.1671 - val_accuracy: 0.9476\n",
      "Epoch 384/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9553 - val_loss: 0.1675 - val_accuracy: 0.9460\n",
      "Epoch 385/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9575 - val_loss: 0.1681 - val_accuracy: 0.9476\n",
      "Epoch 386/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9552 - val_loss: 0.1679 - val_accuracy: 0.9429\n",
      "Epoch 387/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9529 - val_loss: 0.1642 - val_accuracy: 0.9476\n",
      "Epoch 388/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9546 - val_loss: 0.1656 - val_accuracy: 0.9491\n",
      "Epoch 389/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9478 - val_loss: 0.1685 - val_accuracy: 0.9499\n",
      "Epoch 390/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9533 - val_loss: 0.1659 - val_accuracy: 0.9484\n",
      "Epoch 391/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9576 - val_loss: 0.1698 - val_accuracy: 0.9452\n",
      "Epoch 392/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9563 - val_loss: 0.1655 - val_accuracy: 0.9484\n",
      "Epoch 393/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9553 - val_loss: 0.1717 - val_accuracy: 0.9499\n",
      "Epoch 394/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9483 - val_loss: 0.1737 - val_accuracy: 0.9507\n",
      "Epoch 395/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9542 - val_loss: 0.1870 - val_accuracy: 0.9507\n",
      "Epoch 396/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9518 - val_loss: 0.1644 - val_accuracy: 0.9460\n",
      "Epoch 397/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9494 - val_loss: 0.1789 - val_accuracy: 0.9491\n",
      "Epoch 398/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9515 - val_loss: 0.1608 - val_accuracy: 0.9484\n",
      "Epoch 399/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9561 - val_loss: 0.1697 - val_accuracy: 0.9499\n",
      "Epoch 400/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9522 - val_loss: 0.1795 - val_accuracy: 0.9429\n",
      "Epoch 401/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9566 - val_loss: 0.1699 - val_accuracy: 0.9499\n",
      "Epoch 402/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9483 - val_loss: 0.1890 - val_accuracy: 0.9507\n",
      "Epoch 403/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9533 - val_loss: 0.1703 - val_accuracy: 0.9491\n",
      "Epoch 404/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9556 - val_loss: 0.1766 - val_accuracy: 0.9444\n",
      "Epoch 405/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9510 - val_loss: 0.1847 - val_accuracy: 0.9491\n",
      "Epoch 406/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9578 - val_loss: 0.1628 - val_accuracy: 0.9468\n",
      "Epoch 407/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9549 - val_loss: 0.1940 - val_accuracy: 0.9499\n",
      "Epoch 408/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9525 - val_loss: 0.2096 - val_accuracy: 0.9499\n",
      "Epoch 409/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9563 - val_loss: 0.1709 - val_accuracy: 0.9484\n",
      "Epoch 410/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9501 - val_loss: 0.1744 - val_accuracy: 0.9452\n",
      "Epoch 411/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9474 - val_loss: 0.1697 - val_accuracy: 0.9491\n",
      "Epoch 412/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9554 - val_loss: 0.1831 - val_accuracy: 0.9476\n",
      "Epoch 413/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9539 - val_loss: 0.1836 - val_accuracy: 0.9437\n",
      "Epoch 414/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9535 - val_loss: 0.1842 - val_accuracy: 0.9499\n",
      "Epoch 415/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9624 - val_loss: 0.1789 - val_accuracy: 0.9452\n",
      "Epoch 416/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9529 - val_loss: 0.1772 - val_accuracy: 0.9484\n",
      "Epoch 417/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9524 - val_loss: 0.1715 - val_accuracy: 0.9452\n",
      "Epoch 418/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9500 - val_loss: 0.1810 - val_accuracy: 0.9484\n",
      "Epoch 419/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9561 - val_loss: 0.1742 - val_accuracy: 0.9460\n",
      "Epoch 420/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9585 - val_loss: 0.1662 - val_accuracy: 0.9460\n",
      "Epoch 421/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9526 - val_loss: 0.1715 - val_accuracy: 0.9468\n",
      "Epoch 422/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9582 - val_loss: 0.1761 - val_accuracy: 0.9468\n",
      "Epoch 423/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9648 - val_loss: 0.1744 - val_accuracy: 0.9476\n",
      "Epoch 424/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9472 - val_loss: 0.1667 - val_accuracy: 0.9460\n",
      "Epoch 425/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9557 - val_loss: 0.2045 - val_accuracy: 0.9515\n",
      "Epoch 426/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9560 - val_loss: 0.1905 - val_accuracy: 0.9491\n",
      "Epoch 427/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9562 - val_loss: 0.1774 - val_accuracy: 0.9507\n",
      "Epoch 428/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9548 - val_loss: 0.1722 - val_accuracy: 0.9499\n",
      "Epoch 429/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9537 - val_loss: 0.1653 - val_accuracy: 0.9468\n",
      "Epoch 430/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9588 - val_loss: 0.1902 - val_accuracy: 0.9437\n",
      "Epoch 431/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9542 - val_loss: 0.1773 - val_accuracy: 0.9468\n",
      "Epoch 432/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9598 - val_loss: 0.1927 - val_accuracy: 0.9491\n",
      "Epoch 433/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9581 - val_loss: 0.1705 - val_accuracy: 0.9476\n",
      "Epoch 434/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9560 - val_loss: 0.1947 - val_accuracy: 0.9491\n",
      "Epoch 435/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9540 - val_loss: 0.1870 - val_accuracy: 0.9476\n",
      "Epoch 436/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9547 - val_loss: 0.1887 - val_accuracy: 0.9491\n",
      "Epoch 437/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9539 - val_loss: 0.1917 - val_accuracy: 0.9491\n",
      "Epoch 438/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9517 - val_loss: 0.2175 - val_accuracy: 0.9499\n",
      "Epoch 439/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9537 - val_loss: 0.2133 - val_accuracy: 0.9476\n",
      "Epoch 440/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9575 - val_loss: 0.1941 - val_accuracy: 0.9468\n",
      "Epoch 441/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9558 - val_loss: 0.1971 - val_accuracy: 0.9468\n",
      "Epoch 442/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9563 - val_loss: 0.1814 - val_accuracy: 0.9484\n",
      "Epoch 443/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9542 - val_loss: 0.1846 - val_accuracy: 0.9460\n",
      "Epoch 444/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9587 - val_loss: 0.1725 - val_accuracy: 0.9476\n",
      "Epoch 445/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9566 - val_loss: 0.2025 - val_accuracy: 0.9484\n",
      "Epoch 446/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9539 - val_loss: 0.1949 - val_accuracy: 0.9507\n",
      "Epoch 447/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9576 - val_loss: 0.1807 - val_accuracy: 0.9491\n",
      "Epoch 448/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9545 - val_loss: 0.2081 - val_accuracy: 0.9507\n",
      "Epoch 449/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9549 - val_loss: 0.1879 - val_accuracy: 0.9491\n",
      "Epoch 450/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9565 - val_loss: 0.1836 - val_accuracy: 0.9499\n",
      "Epoch 451/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9590 - val_loss: 0.1897 - val_accuracy: 0.9491\n",
      "Epoch 452/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9537 - val_loss: 0.1811 - val_accuracy: 0.9491\n",
      "Epoch 453/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9549 - val_loss: 0.1860 - val_accuracy: 0.9444\n",
      "Epoch 454/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9528 - val_loss: 0.1891 - val_accuracy: 0.9460\n",
      "Epoch 455/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9537 - val_loss: 0.1955 - val_accuracy: 0.9452\n",
      "Epoch 456/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.9578 - val_loss: 0.1931 - val_accuracy: 0.9452\n",
      "Epoch 457/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9562 - val_loss: 0.1895 - val_accuracy: 0.9437\n",
      "Epoch 458/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9625 - val_loss: 0.1862 - val_accuracy: 0.9444\n",
      "Epoch 459/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9549 - val_loss: 0.1815 - val_accuracy: 0.9491\n",
      "Epoch 460/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9554 - val_loss: 0.1995 - val_accuracy: 0.9460\n",
      "Epoch 461/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9548 - val_loss: 0.1987 - val_accuracy: 0.9460\n",
      "Epoch 462/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9557 - val_loss: 0.1975 - val_accuracy: 0.9460\n",
      "Epoch 463/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9606 - val_loss: 0.2036 - val_accuracy: 0.9413\n",
      "Epoch 464/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9600 - val_loss: 0.1875 - val_accuracy: 0.9452\n",
      "Epoch 465/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9597 - val_loss: 0.1977 - val_accuracy: 0.9468\n",
      "Epoch 466/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9601 - val_loss: 0.2237 - val_accuracy: 0.9491\n",
      "Epoch 467/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9544 - val_loss: 0.2080 - val_accuracy: 0.9460\n",
      "Epoch 468/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9609 - val_loss: 0.1942 - val_accuracy: 0.9476\n",
      "Epoch 469/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9579 - val_loss: 0.1999 - val_accuracy: 0.9452\n",
      "Epoch 470/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9582 - val_loss: 0.2064 - val_accuracy: 0.9499\n",
      "Epoch 471/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9558 - val_loss: 0.1978 - val_accuracy: 0.9468\n",
      "Epoch 472/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9616 - val_loss: 0.1882 - val_accuracy: 0.9397\n",
      "Epoch 473/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9562 - val_loss: 0.2006 - val_accuracy: 0.9421\n",
      "Epoch 474/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9575 - val_loss: 0.2035 - val_accuracy: 0.9468\n",
      "Epoch 475/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9573 - val_loss: 0.2066 - val_accuracy: 0.9460\n",
      "Epoch 476/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9605 - val_loss: 0.1964 - val_accuracy: 0.9452\n",
      "Epoch 477/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9534 - val_loss: 0.1961 - val_accuracy: 0.9413\n",
      "Epoch 478/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9608 - val_loss: 0.2234 - val_accuracy: 0.9468\n",
      "Epoch 479/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9613 - val_loss: 0.2018 - val_accuracy: 0.9444\n",
      "Epoch 480/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9554 - val_loss: 0.1901 - val_accuracy: 0.9484\n",
      "Epoch 481/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9553 - val_loss: 0.1926 - val_accuracy: 0.9429\n",
      "Epoch 482/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9558 - val_loss: 0.2085 - val_accuracy: 0.9429\n",
      "Epoch 483/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9555 - val_loss: 0.2316 - val_accuracy: 0.9507\n",
      "Epoch 484/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.9597 - val_loss: 0.2113 - val_accuracy: 0.9468\n",
      "Epoch 485/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9537 - val_loss: 0.2054 - val_accuracy: 0.9491\n",
      "Epoch 486/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9567 - val_loss: 0.2184 - val_accuracy: 0.9468\n",
      "Epoch 487/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9583 - val_loss: 0.2185 - val_accuracy: 0.9468\n",
      "Epoch 488/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9582 - val_loss: 0.2089 - val_accuracy: 0.9429\n",
      "Epoch 489/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9558 - val_loss: 0.2276 - val_accuracy: 0.9484\n",
      "Epoch 490/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9625 - val_loss: 0.2226 - val_accuracy: 0.9452\n",
      "Epoch 491/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9565 - val_loss: 0.2202 - val_accuracy: 0.9484\n",
      "Epoch 492/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9580 - val_loss: 0.2013 - val_accuracy: 0.9444\n",
      "Epoch 493/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9620 - val_loss: 0.2240 - val_accuracy: 0.9390\n",
      "Epoch 494/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9571 - val_loss: 0.2485 - val_accuracy: 0.9468\n",
      "Epoch 495/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9603 - val_loss: 0.2033 - val_accuracy: 0.9429\n",
      "Epoch 496/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9619 - val_loss: 0.2187 - val_accuracy: 0.9429\n",
      "Epoch 497/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9612 - val_loss: 0.2144 - val_accuracy: 0.9460\n",
      "Epoch 498/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9608 - val_loss: 0.2079 - val_accuracy: 0.9460\n",
      "Epoch 499/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9577 - val_loss: 0.2613 - val_accuracy: 0.9460\n",
      "Epoch 500/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.9577 - val_loss: 0.2400 - val_accuracy: 0.9499\n",
      "Epoch 501/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9582 - val_loss: 0.2301 - val_accuracy: 0.9390\n",
      "Epoch 502/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9573 - val_loss: 0.2065 - val_accuracy: 0.9413\n",
      "Epoch 503/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9605 - val_loss: 0.2540 - val_accuracy: 0.9452\n",
      "Epoch 504/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9620 - val_loss: 0.2291 - val_accuracy: 0.9421\n",
      "Epoch 505/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9539 - val_loss: 0.2351 - val_accuracy: 0.9444\n",
      "Epoch 506/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9619 - val_loss: 0.2341 - val_accuracy: 0.9460\n",
      "Epoch 507/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9649 - val_loss: 0.2383 - val_accuracy: 0.9429\n",
      "Epoch 508/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9611 - val_loss: 0.2288 - val_accuracy: 0.9460\n",
      "Epoch 509/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9571 - val_loss: 0.2445 - val_accuracy: 0.9476\n",
      "Epoch 510/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9517 - val_loss: 0.2566 - val_accuracy: 0.9476\n",
      "Epoch 511/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9634 - val_loss: 0.2359 - val_accuracy: 0.9460\n",
      "Epoch 512/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9633 - val_loss: 0.2204 - val_accuracy: 0.9429\n",
      "Epoch 513/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9544 - val_loss: 0.2279 - val_accuracy: 0.9437\n",
      "Epoch 514/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9609 - val_loss: 0.2381 - val_accuracy: 0.9476\n",
      "Epoch 515/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9582 - val_loss: 0.2503 - val_accuracy: 0.9460\n",
      "Epoch 516/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9621 - val_loss: 0.2261 - val_accuracy: 0.9429\n",
      "Epoch 517/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9593 - val_loss: 0.2232 - val_accuracy: 0.9437\n",
      "Epoch 518/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9595 - val_loss: 0.2297 - val_accuracy: 0.9452\n",
      "Epoch 519/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9659 - val_loss: 0.2313 - val_accuracy: 0.9484\n",
      "Epoch 520/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9578 - val_loss: 0.2415 - val_accuracy: 0.9452\n",
      "Epoch 521/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9569 - val_loss: 0.2436 - val_accuracy: 0.9468\n",
      "Epoch 522/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9590 - val_loss: 0.2402 - val_accuracy: 0.9421\n",
      "Epoch 523/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9595 - val_loss: 0.2151 - val_accuracy: 0.9444\n",
      "Epoch 524/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9600 - val_loss: 0.2049 - val_accuracy: 0.9484\n",
      "Epoch 525/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9595 - val_loss: 0.2302 - val_accuracy: 0.9460\n",
      "Epoch 526/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9598 - val_loss: 0.2419 - val_accuracy: 0.9444\n",
      "Epoch 527/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9582 - val_loss: 0.2334 - val_accuracy: 0.9405\n",
      "Epoch 528/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9564 - val_loss: 0.2650 - val_accuracy: 0.9429\n",
      "Epoch 529/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9587 - val_loss: 0.2449 - val_accuracy: 0.9499\n",
      "Epoch 530/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9603 - val_loss: 0.2084 - val_accuracy: 0.9444\n",
      "Epoch 531/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9587 - val_loss: 0.2270 - val_accuracy: 0.9437\n",
      "Epoch 532/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9639 - val_loss: 0.2477 - val_accuracy: 0.9421\n",
      "Epoch 533/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9621 - val_loss: 0.2628 - val_accuracy: 0.9429\n",
      "Epoch 534/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9619 - val_loss: 0.2366 - val_accuracy: 0.9421\n",
      "Epoch 535/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9619 - val_loss: 0.2501 - val_accuracy: 0.9413\n",
      "Epoch 536/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9616 - val_loss: 0.2262 - val_accuracy: 0.9452\n",
      "Epoch 537/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9571 - val_loss: 0.2762 - val_accuracy: 0.9476\n",
      "Epoch 538/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9480 - val_loss: 0.2338 - val_accuracy: 0.9460\n",
      "Epoch 539/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9567 - val_loss: 0.2330 - val_accuracy: 0.9429\n",
      "Epoch 540/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9593 - val_loss: 0.2199 - val_accuracy: 0.9390\n",
      "Epoch 541/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9601 - val_loss: 0.2687 - val_accuracy: 0.9444\n",
      "Epoch 542/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9618 - val_loss: 0.2396 - val_accuracy: 0.9452\n",
      "Epoch 543/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9650 - val_loss: 0.2337 - val_accuracy: 0.9437\n",
      "Epoch 544/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9596 - val_loss: 0.2423 - val_accuracy: 0.9491\n",
      "Epoch 545/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9655 - val_loss: 0.2523 - val_accuracy: 0.9413\n",
      "Epoch 546/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9569 - val_loss: 0.2906 - val_accuracy: 0.9499\n",
      "Epoch 547/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9600 - val_loss: 0.2602 - val_accuracy: 0.9452\n",
      "Epoch 548/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9608 - val_loss: 0.2483 - val_accuracy: 0.9452\n",
      "Epoch 549/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9591 - val_loss: 0.2776 - val_accuracy: 0.9460\n",
      "Epoch 550/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9640 - val_loss: 0.2922 - val_accuracy: 0.9476\n",
      "Epoch 551/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9684 - val_loss: 0.2592 - val_accuracy: 0.9397\n",
      "Epoch 552/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9644 - val_loss: 0.2632 - val_accuracy: 0.9413\n",
      "Epoch 553/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9614 - val_loss: 0.2627 - val_accuracy: 0.9452\n",
      "Epoch 554/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9574 - val_loss: 0.2398 - val_accuracy: 0.9460\n",
      "Epoch 555/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9655 - val_loss: 0.2722 - val_accuracy: 0.9452\n",
      "Epoch 556/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9626 - val_loss: 0.2752 - val_accuracy: 0.9452\n",
      "Epoch 557/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9595 - val_loss: 0.2214 - val_accuracy: 0.9366\n",
      "Epoch 558/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9616 - val_loss: 0.2482 - val_accuracy: 0.9484\n",
      "Epoch 559/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9566 - val_loss: 0.2863 - val_accuracy: 0.9444\n",
      "Epoch 560/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9533 - val_loss: 0.2583 - val_accuracy: 0.9452\n",
      "Epoch 561/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9647 - val_loss: 0.2828 - val_accuracy: 0.9413\n",
      "Epoch 562/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9578 - val_loss: 0.2862 - val_accuracy: 0.9468\n",
      "Epoch 563/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9634 - val_loss: 0.3045 - val_accuracy: 0.9437\n",
      "Epoch 564/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9616 - val_loss: 0.2691 - val_accuracy: 0.9429\n",
      "Epoch 565/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9638 - val_loss: 0.2325 - val_accuracy: 0.9397\n",
      "Epoch 566/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9613 - val_loss: 0.2813 - val_accuracy: 0.9429\n",
      "Epoch 567/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9575 - val_loss: 0.2774 - val_accuracy: 0.9444\n",
      "Epoch 568/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9642 - val_loss: 0.3537 - val_accuracy: 0.9452\n",
      "Epoch 569/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9566 - val_loss: 0.2804 - val_accuracy: 0.9343\n",
      "Epoch 570/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9656 - val_loss: 0.2546 - val_accuracy: 0.9468\n",
      "Epoch 571/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9579 - val_loss: 0.2675 - val_accuracy: 0.9390\n",
      "Epoch 572/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9599 - val_loss: 0.3089 - val_accuracy: 0.9444\n",
      "Epoch 573/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9624 - val_loss: 0.2655 - val_accuracy: 0.9437\n",
      "Epoch 574/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.9681 - val_loss: 0.2804 - val_accuracy: 0.9452\n",
      "Epoch 575/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9683 - val_loss: 0.2868 - val_accuracy: 0.9405\n",
      "Epoch 576/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9606 - val_loss: 0.2708 - val_accuracy: 0.9421\n",
      "Epoch 577/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.9638 - val_loss: 0.2795 - val_accuracy: 0.9468\n",
      "Epoch 578/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9628 - val_loss: 0.2761 - val_accuracy: 0.9437\n",
      "Epoch 579/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9645 - val_loss: 0.2437 - val_accuracy: 0.9366\n",
      "Epoch 580/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9631 - val_loss: 0.2551 - val_accuracy: 0.9437\n",
      "Epoch 581/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.9607 - val_loss: 0.2815 - val_accuracy: 0.9460\n",
      "Epoch 582/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9634 - val_loss: 0.2894 - val_accuracy: 0.9460\n",
      "Epoch 583/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9655 - val_loss: 0.3037 - val_accuracy: 0.9397\n",
      "Epoch 584/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9603 - val_loss: 0.2754 - val_accuracy: 0.9366\n",
      "Epoch 585/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9667 - val_loss: 0.2990 - val_accuracy: 0.9444\n",
      "Epoch 586/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9638 - val_loss: 0.2827 - val_accuracy: 0.9413\n",
      "Epoch 587/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0989 - accuracy: 0.9618 - val_loss: 0.2772 - val_accuracy: 0.9382\n",
      "Epoch 588/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9575 - val_loss: 0.2804 - val_accuracy: 0.9413\n",
      "Epoch 589/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9673 - val_loss: 0.2729 - val_accuracy: 0.9366\n",
      "Epoch 590/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0990 - accuracy: 0.9603 - val_loss: 0.3136 - val_accuracy: 0.9460\n",
      "Epoch 591/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9667 - val_loss: 0.2664 - val_accuracy: 0.9421\n",
      "Epoch 592/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9649 - val_loss: 0.2510 - val_accuracy: 0.9397\n",
      "Epoch 593/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9628 - val_loss: 0.2942 - val_accuracy: 0.9444\n",
      "Epoch 594/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9652 - val_loss: 0.2868 - val_accuracy: 0.9460\n",
      "Epoch 595/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9601 - val_loss: 0.3047 - val_accuracy: 0.9296\n",
      "Epoch 596/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9627 - val_loss: 0.2930 - val_accuracy: 0.9460\n",
      "Epoch 597/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9639 - val_loss: 0.3117 - val_accuracy: 0.9413\n",
      "Epoch 598/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9642 - val_loss: 0.2719 - val_accuracy: 0.9382\n",
      "Epoch 599/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9651 - val_loss: 0.2962 - val_accuracy: 0.9390\n",
      "Epoch 600/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9636 - val_loss: 0.3148 - val_accuracy: 0.9405\n",
      "Epoch 601/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9665 - val_loss: 0.3115 - val_accuracy: 0.9390\n",
      "Epoch 602/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9657 - val_loss: 0.3019 - val_accuracy: 0.9452\n",
      "Epoch 603/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9639 - val_loss: 0.3292 - val_accuracy: 0.9413\n",
      "Epoch 604/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9658 - val_loss: 0.3059 - val_accuracy: 0.9374\n",
      "Epoch 605/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9646 - val_loss: 0.2700 - val_accuracy: 0.9366\n",
      "Epoch 606/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9645 - val_loss: 0.3416 - val_accuracy: 0.9429\n",
      "Epoch 607/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9561 - val_loss: 0.3097 - val_accuracy: 0.9437\n",
      "Epoch 608/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9684 - val_loss: 0.3332 - val_accuracy: 0.9413\n",
      "Epoch 609/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9639 - val_loss: 0.3123 - val_accuracy: 0.9319\n",
      "Epoch 610/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9626 - val_loss: 0.3503 - val_accuracy: 0.9452\n",
      "Epoch 611/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9669 - val_loss: 0.3075 - val_accuracy: 0.9421\n",
      "Epoch 612/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9661 - val_loss: 0.3197 - val_accuracy: 0.9429\n",
      "Epoch 613/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9647 - val_loss: 0.3548 - val_accuracy: 0.9429\n",
      "Epoch 614/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9609 - val_loss: 0.3190 - val_accuracy: 0.9437\n",
      "Epoch 615/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9642 - val_loss: 0.3569 - val_accuracy: 0.9390\n",
      "Epoch 616/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9603 - val_loss: 0.2955 - val_accuracy: 0.9382\n",
      "Epoch 617/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9637 - val_loss: 0.3544 - val_accuracy: 0.9421\n",
      "Epoch 618/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9656 - val_loss: 0.3131 - val_accuracy: 0.9225\n",
      "Epoch 619/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9679 - val_loss: 0.2944 - val_accuracy: 0.9366\n",
      "Epoch 620/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9641 - val_loss: 0.3145 - val_accuracy: 0.9351\n",
      "Epoch 621/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9637 - val_loss: 0.3215 - val_accuracy: 0.9421\n",
      "Epoch 622/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9637 - val_loss: 0.3014 - val_accuracy: 0.9374\n",
      "Epoch 623/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9612 - val_loss: 0.3368 - val_accuracy: 0.9390\n",
      "Epoch 624/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9638 - val_loss: 0.3478 - val_accuracy: 0.9421\n",
      "Epoch 625/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9604 - val_loss: 0.3592 - val_accuracy: 0.9405\n",
      "Epoch 626/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9613 - val_loss: 0.3452 - val_accuracy: 0.9390\n",
      "Epoch 627/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9607 - val_loss: 0.3084 - val_accuracy: 0.9452\n",
      "Epoch 628/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9616 - val_loss: 0.3137 - val_accuracy: 0.9460\n",
      "Epoch 629/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9633 - val_loss: 0.3735 - val_accuracy: 0.9460\n",
      "Epoch 630/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9639 - val_loss: 0.3204 - val_accuracy: 0.9335\n",
      "Epoch 631/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9639 - val_loss: 0.3435 - val_accuracy: 0.9444\n",
      "Epoch 632/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9636 - val_loss: 0.3464 - val_accuracy: 0.9452\n",
      "Epoch 633/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9617 - val_loss: 0.3039 - val_accuracy: 0.9397\n",
      "Epoch 634/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9691 - val_loss: 0.3347 - val_accuracy: 0.9390\n",
      "Epoch 635/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9675 - val_loss: 0.3405 - val_accuracy: 0.9366\n",
      "Epoch 636/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9654 - val_loss: 0.3299 - val_accuracy: 0.9452\n",
      "Epoch 637/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9653 - val_loss: 0.3314 - val_accuracy: 0.9343\n",
      "Epoch 638/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9630 - val_loss: 0.3174 - val_accuracy: 0.9390\n",
      "Epoch 639/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9614 - val_loss: 0.3579 - val_accuracy: 0.9366\n",
      "Epoch 640/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9682 - val_loss: 0.3211 - val_accuracy: 0.9405\n",
      "Epoch 641/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9674 - val_loss: 0.3072 - val_accuracy: 0.9288\n",
      "Epoch 642/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9661 - val_loss: 0.3201 - val_accuracy: 0.9366\n",
      "Epoch 643/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9644 - val_loss: 0.3957 - val_accuracy: 0.9429\n",
      "Epoch 644/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9684 - val_loss: 0.3703 - val_accuracy: 0.9351\n",
      "Epoch 645/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9700 - val_loss: 0.3159 - val_accuracy: 0.9405\n",
      "Epoch 646/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9622 - val_loss: 0.3085 - val_accuracy: 0.9421\n",
      "Epoch 647/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9676 - val_loss: 0.3133 - val_accuracy: 0.9374\n",
      "Epoch 648/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9668 - val_loss: 0.3457 - val_accuracy: 0.9374\n",
      "Epoch 649/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9603 - val_loss: 0.3383 - val_accuracy: 0.9390\n",
      "Epoch 650/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.96 - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9651 - val_loss: 0.3321 - val_accuracy: 0.9444\n",
      "Epoch 651/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9636 - val_loss: 0.3061 - val_accuracy: 0.9413\n",
      "Epoch 652/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9690 - val_loss: 0.3474 - val_accuracy: 0.9366\n",
      "Epoch 653/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9660 - val_loss: 0.3533 - val_accuracy: 0.9429\n",
      "Epoch 654/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9677 - val_loss: 0.3573 - val_accuracy: 0.9327\n",
      "Epoch 655/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9675 - val_loss: 0.3415 - val_accuracy: 0.9421\n",
      "Epoch 656/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9687 - val_loss: 0.3101 - val_accuracy: 0.9327\n",
      "Epoch 657/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9680 - val_loss: 0.3622 - val_accuracy: 0.9343\n",
      "Epoch 658/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9715 - val_loss: 0.3122 - val_accuracy: 0.9366\n",
      "Epoch 659/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9676 - val_loss: 0.3456 - val_accuracy: 0.9366\n",
      "Epoch 660/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9689 - val_loss: 0.3627 - val_accuracy: 0.9351\n",
      "Epoch 661/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9682 - val_loss: 0.3616 - val_accuracy: 0.9327\n",
      "Epoch 662/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9654 - val_loss: 0.4057 - val_accuracy: 0.9390\n",
      "Epoch 663/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9681 - val_loss: 0.3201 - val_accuracy: 0.9351\n",
      "Epoch 664/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9695 - val_loss: 0.3735 - val_accuracy: 0.9405\n",
      "Epoch 665/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9671 - val_loss: 0.4098 - val_accuracy: 0.9429\n",
      "Epoch 666/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9713 - val_loss: 0.3197 - val_accuracy: 0.9421\n",
      "Epoch 667/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9676 - val_loss: 0.4108 - val_accuracy: 0.9351\n",
      "Epoch 668/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0885 - accuracy: 0.9646 - val_loss: 0.3450 - val_accuracy: 0.9343\n",
      "Epoch 669/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9707 - val_loss: 0.3908 - val_accuracy: 0.9366\n",
      "Epoch 670/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9740 - val_loss: 0.3925 - val_accuracy: 0.9366\n",
      "Epoch 671/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9612 - val_loss: 0.3490 - val_accuracy: 0.9358\n",
      "Epoch 672/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9658 - val_loss: 0.3554 - val_accuracy: 0.9358\n",
      "Epoch 673/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.9657 - val_loss: 0.3426 - val_accuracy: 0.9374\n",
      "Epoch 674/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9705 - val_loss: 0.4027 - val_accuracy: 0.9374\n",
      "Epoch 675/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9691 - val_loss: 0.3849 - val_accuracy: 0.9343\n",
      "Epoch 676/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0689 - accuracy: 0.9740 - val_loss: 0.4089 - val_accuracy: 0.9249\n",
      "Epoch 677/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9704 - val_loss: 0.3572 - val_accuracy: 0.9413\n",
      "Epoch 678/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9696 - val_loss: 0.4115 - val_accuracy: 0.9311\n",
      "Epoch 679/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9687 - val_loss: 0.3754 - val_accuracy: 0.9429\n",
      "Epoch 680/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9657 - val_loss: 0.3429 - val_accuracy: 0.9311\n",
      "Epoch 681/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9716 - val_loss: 0.3974 - val_accuracy: 0.9413\n",
      "Epoch 682/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.9713 - val_loss: 0.3546 - val_accuracy: 0.9272\n",
      "Epoch 683/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9695 - val_loss: 0.3878 - val_accuracy: 0.9476\n",
      "Epoch 684/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9634 - val_loss: 0.3892 - val_accuracy: 0.9358\n",
      "Epoch 685/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9679 - val_loss: 0.4360 - val_accuracy: 0.9335\n",
      "Epoch 686/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9678 - val_loss: 0.4085 - val_accuracy: 0.9311\n",
      "Epoch 687/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9691 - val_loss: 0.3958 - val_accuracy: 0.9429\n",
      "Epoch 688/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9684 - val_loss: 0.3839 - val_accuracy: 0.9335\n",
      "Epoch 689/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9688 - val_loss: 0.3550 - val_accuracy: 0.9397\n",
      "Epoch 690/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9699 - val_loss: 0.3618 - val_accuracy: 0.9351\n",
      "Epoch 691/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9628 - val_loss: 0.3787 - val_accuracy: 0.9311\n",
      "Epoch 692/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9696 - val_loss: 0.3850 - val_accuracy: 0.9429\n",
      "Epoch 693/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9694 - val_loss: 0.3674 - val_accuracy: 0.9335\n",
      "Epoch 694/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9666 - val_loss: 0.3790 - val_accuracy: 0.9390\n",
      "Epoch 695/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9718 - val_loss: 0.3909 - val_accuracy: 0.9233\n",
      "Epoch 696/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9669 - val_loss: 0.3708 - val_accuracy: 0.9421\n",
      "Epoch 697/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9690 - val_loss: 0.3794 - val_accuracy: 0.9351\n",
      "Epoch 698/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9687 - val_loss: 0.3934 - val_accuracy: 0.9280\n",
      "Epoch 699/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9695 - val_loss: 0.3610 - val_accuracy: 0.9272\n",
      "Epoch 700/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9727 - val_loss: 0.4246 - val_accuracy: 0.9311\n",
      "Epoch 701/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9681 - val_loss: 0.3922 - val_accuracy: 0.9249\n",
      "Epoch 702/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9713 - val_loss: 0.3915 - val_accuracy: 0.9264\n",
      "Epoch 703/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9757 - val_loss: 0.4049 - val_accuracy: 0.9296\n",
      "Epoch 704/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9741 - val_loss: 0.4158 - val_accuracy: 0.9366\n",
      "Epoch 705/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9689 - val_loss: 0.3366 - val_accuracy: 0.9366\n",
      "Epoch 706/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9715 - val_loss: 0.4354 - val_accuracy: 0.9257\n",
      "Epoch 707/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9687 - val_loss: 0.4061 - val_accuracy: 0.9421\n",
      "Epoch 708/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9690 - val_loss: 0.3755 - val_accuracy: 0.9335\n",
      "Epoch 709/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 0.9731 - val_loss: 0.4115 - val_accuracy: 0.9327\n",
      "Epoch 710/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9714 - val_loss: 0.3997 - val_accuracy: 0.9374\n",
      "Epoch 711/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9728 - val_loss: 0.3924 - val_accuracy: 0.9382\n",
      "Epoch 712/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9706 - val_loss: 0.4365 - val_accuracy: 0.9280\n",
      "Epoch 713/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9671 - val_loss: 0.4384 - val_accuracy: 0.9233\n",
      "Epoch 714/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9737 - val_loss: 0.3984 - val_accuracy: 0.9225\n",
      "Epoch 715/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9705 - val_loss: 0.4127 - val_accuracy: 0.9335\n",
      "Epoch 716/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9739 - val_loss: 0.4711 - val_accuracy: 0.9280\n",
      "Epoch 717/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9751 - val_loss: 0.4379 - val_accuracy: 0.9304\n",
      "Epoch 718/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9716 - val_loss: 0.4168 - val_accuracy: 0.9288\n",
      "Epoch 719/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9748 - val_loss: 0.4361 - val_accuracy: 0.9351\n",
      "Epoch 720/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 0.9758 - val_loss: 0.4464 - val_accuracy: 0.9405\n",
      "Epoch 721/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9702 - val_loss: 0.3987 - val_accuracy: 0.9327\n",
      "Epoch 722/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9721 - val_loss: 0.4333 - val_accuracy: 0.9374\n",
      "Epoch 723/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9714 - val_loss: 0.4282 - val_accuracy: 0.9264\n",
      "Epoch 724/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9743 - val_loss: 0.3842 - val_accuracy: 0.9202\n",
      "Epoch 725/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9740 - val_loss: 0.4616 - val_accuracy: 0.9233\n",
      "Epoch 726/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0753 - accuracy: 0.9701 - val_loss: 0.3794 - val_accuracy: 0.9280\n",
      "Epoch 727/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9739 - val_loss: 0.4709 - val_accuracy: 0.9319\n",
      "Epoch 728/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9688 - val_loss: 0.4353 - val_accuracy: 0.9319\n",
      "Epoch 729/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9763 - val_loss: 0.4181 - val_accuracy: 0.9311\n",
      "Epoch 730/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9730 - val_loss: 0.4624 - val_accuracy: 0.9351\n",
      "Epoch 731/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0617 - accuracy: 0.9760 - val_loss: 0.4407 - val_accuracy: 0.9296\n",
      "Epoch 732/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 0.9768 - val_loss: 0.4156 - val_accuracy: 0.9296\n",
      "Epoch 733/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9740 - val_loss: 0.4564 - val_accuracy: 0.9343\n",
      "Epoch 734/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9736 - val_loss: 0.4261 - val_accuracy: 0.9241\n",
      "Epoch 735/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9731 - val_loss: 0.3984 - val_accuracy: 0.9366\n",
      "Epoch 736/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9723 - val_loss: 0.4943 - val_accuracy: 0.9241\n",
      "Epoch 737/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9762 - val_loss: 0.4517 - val_accuracy: 0.9382\n",
      "Epoch 738/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9746 - val_loss: 0.4287 - val_accuracy: 0.9374\n",
      "Epoch 739/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9737 - val_loss: 0.4613 - val_accuracy: 0.9257\n",
      "Epoch 740/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9746 - val_loss: 0.4106 - val_accuracy: 0.9288\n",
      "Epoch 741/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9766 - val_loss: 0.4198 - val_accuracy: 0.9272\n",
      "Epoch 742/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9703 - val_loss: 0.4003 - val_accuracy: 0.9327\n",
      "Epoch 743/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9729 - val_loss: 0.4261 - val_accuracy: 0.9351\n",
      "Epoch 744/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9783 - val_loss: 0.3998 - val_accuracy: 0.9171\n",
      "Epoch 745/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9699 - val_loss: 0.5280 - val_accuracy: 0.9327\n",
      "Epoch 746/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9748 - val_loss: 0.4258 - val_accuracy: 0.9264\n",
      "Epoch 747/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9746 - val_loss: 0.4381 - val_accuracy: 0.9241\n",
      "Epoch 748/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9749 - val_loss: 0.3944 - val_accuracy: 0.9288\n",
      "Epoch 749/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9760 - val_loss: 0.4641 - val_accuracy: 0.9304\n",
      "Epoch 750/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9764 - val_loss: 0.4655 - val_accuracy: 0.9280\n",
      "Epoch 751/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9765 - val_loss: 0.4211 - val_accuracy: 0.9327\n",
      "Epoch 752/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9743 - val_loss: 0.4458 - val_accuracy: 0.9327\n",
      "Epoch 753/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9737 - val_loss: 0.4485 - val_accuracy: 0.9304\n",
      "Epoch 754/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9770 - val_loss: 0.4797 - val_accuracy: 0.9366\n",
      "Epoch 755/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9776 - val_loss: 0.4550 - val_accuracy: 0.9288\n",
      "Epoch 756/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9754 - val_loss: 0.4255 - val_accuracy: 0.9351\n",
      "Epoch 757/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9756 - val_loss: 0.4459 - val_accuracy: 0.9100\n",
      "Epoch 758/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9774 - val_loss: 0.4407 - val_accuracy: 0.9366\n",
      "Epoch 759/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9733 - val_loss: 0.4531 - val_accuracy: 0.9233\n",
      "Epoch 760/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9724 - val_loss: 0.4126 - val_accuracy: 0.9327\n",
      "Epoch 761/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9798 - val_loss: 0.4845 - val_accuracy: 0.9272\n",
      "Epoch 762/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9764 - val_loss: 0.4522 - val_accuracy: 0.9288\n",
      "Epoch 763/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9752 - val_loss: 0.4904 - val_accuracy: 0.9296\n",
      "Epoch 764/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9754 - val_loss: 0.4857 - val_accuracy: 0.9264\n",
      "Epoch 765/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9727 - val_loss: 0.4770 - val_accuracy: 0.9264\n",
      "Epoch 766/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9763 - val_loss: 0.4272 - val_accuracy: 0.9225\n",
      "Epoch 767/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9804 - val_loss: 0.5089 - val_accuracy: 0.9186\n",
      "Epoch 768/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9748 - val_loss: 0.4490 - val_accuracy: 0.9304\n",
      "Epoch 769/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9754 - val_loss: 0.5155 - val_accuracy: 0.9210\n",
      "Epoch 770/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9768 - val_loss: 0.4575 - val_accuracy: 0.9233\n",
      "Epoch 771/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9786 - val_loss: 0.4729 - val_accuracy: 0.9210\n",
      "Epoch 772/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9761 - val_loss: 0.5455 - val_accuracy: 0.9405\n",
      "Epoch 773/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9755 - val_loss: 0.5109 - val_accuracy: 0.9304\n",
      "Epoch 774/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9790 - val_loss: 0.4058 - val_accuracy: 0.9264\n",
      "Epoch 775/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9704 - val_loss: 0.4997 - val_accuracy: 0.9296\n",
      "Epoch 776/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9842 - val_loss: 0.4941 - val_accuracy: 0.9249\n",
      "Epoch 777/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9804 - val_loss: 0.4800 - val_accuracy: 0.9210\n",
      "Epoch 778/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9821 - val_loss: 0.5061 - val_accuracy: 0.9163\n",
      "Epoch 779/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9826 - val_loss: 0.4706 - val_accuracy: 0.9233\n",
      "Epoch 780/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9772 - val_loss: 0.4734 - val_accuracy: 0.9311\n",
      "Epoch 781/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9761 - val_loss: 0.5193 - val_accuracy: 0.9155\n",
      "Epoch 782/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9763 - val_loss: 0.5291 - val_accuracy: 0.9147\n",
      "Epoch 783/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9772 - val_loss: 0.5146 - val_accuracy: 0.9311\n",
      "Epoch 784/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9781 - val_loss: 0.5904 - val_accuracy: 0.9202\n",
      "Epoch 785/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9773 - val_loss: 0.4438 - val_accuracy: 0.9210\n",
      "Epoch 786/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9740 - val_loss: 0.4784 - val_accuracy: 0.9194\n",
      "Epoch 787/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9760 - val_loss: 0.4868 - val_accuracy: 0.9218\n",
      "Epoch 788/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9782 - val_loss: 0.4968 - val_accuracy: 0.9304\n",
      "Epoch 789/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9812 - val_loss: 0.5279 - val_accuracy: 0.9108\n",
      "Epoch 790/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9802 - val_loss: 0.4896 - val_accuracy: 0.9288\n",
      "Epoch 791/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9763 - val_loss: 0.4849 - val_accuracy: 0.9139\n",
      "Epoch 792/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9810 - val_loss: 0.5655 - val_accuracy: 0.9218\n",
      "Epoch 793/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0518 - accuracy: 0.9787 - val_loss: 0.5119 - val_accuracy: 0.9225\n",
      "Epoch 794/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9800 - val_loss: 0.4868 - val_accuracy: 0.9358\n",
      "Epoch 795/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0518 - accuracy: 0.9809 - val_loss: 0.5222 - val_accuracy: 0.9311\n",
      "Epoch 796/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9765 - val_loss: 0.5327 - val_accuracy: 0.9163\n",
      "Epoch 797/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9767 - val_loss: 0.5091 - val_accuracy: 0.9225\n",
      "Epoch 798/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9772 - val_loss: 0.4784 - val_accuracy: 0.9272\n",
      "Epoch 799/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9794 - val_loss: 0.5267 - val_accuracy: 0.9280\n",
      "Epoch 800/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9821 - val_loss: 0.5223 - val_accuracy: 0.9233\n",
      "Epoch 801/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9774 - val_loss: 0.5402 - val_accuracy: 0.9296\n",
      "Epoch 802/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9775 - val_loss: 0.5163 - val_accuracy: 0.9210\n",
      "Epoch 803/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9777 - val_loss: 0.5432 - val_accuracy: 0.9241\n",
      "Epoch 804/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9777 - val_loss: 0.5250 - val_accuracy: 0.9272\n",
      "Epoch 805/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9855 - val_loss: 0.5218 - val_accuracy: 0.9280\n",
      "Epoch 806/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9800 - val_loss: 0.5206 - val_accuracy: 0.9257\n",
      "Epoch 807/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9791 - val_loss: 0.5099 - val_accuracy: 0.9257\n",
      "Epoch 808/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9767 - val_loss: 0.4969 - val_accuracy: 0.9280\n",
      "Epoch 809/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9794 - val_loss: 0.5156 - val_accuracy: 0.9264\n",
      "Epoch 810/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9825 - val_loss: 0.5100 - val_accuracy: 0.9249\n",
      "Epoch 811/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9816 - val_loss: 0.5256 - val_accuracy: 0.9171\n",
      "Epoch 812/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9784 - val_loss: 0.5061 - val_accuracy: 0.9296\n",
      "Epoch 813/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9730 - val_loss: 0.5311 - val_accuracy: 0.9264\n",
      "Epoch 814/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9833 - val_loss: 0.5157 - val_accuracy: 0.9233\n",
      "Epoch 815/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9779 - val_loss: 0.5550 - val_accuracy: 0.9288\n",
      "Epoch 816/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9788 - val_loss: 0.4917 - val_accuracy: 0.9264\n",
      "Epoch 817/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9838 - val_loss: 0.4990 - val_accuracy: 0.9288\n",
      "Epoch 818/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9774 - val_loss: 0.5366 - val_accuracy: 0.9272\n",
      "Epoch 819/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9791 - val_loss: 0.5497 - val_accuracy: 0.9296\n",
      "Epoch 820/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9832 - val_loss: 0.5029 - val_accuracy: 0.9178\n",
      "Epoch 821/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9819 - val_loss: 0.5204 - val_accuracy: 0.9233\n",
      "Epoch 822/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9846 - val_loss: 0.5416 - val_accuracy: 0.9163\n",
      "Epoch 823/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9869 - val_loss: 0.4994 - val_accuracy: 0.9233\n",
      "Epoch 824/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9788 - val_loss: 0.5214 - val_accuracy: 0.9194\n",
      "Epoch 825/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9750 - val_loss: 0.5431 - val_accuracy: 0.9210\n",
      "Epoch 826/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0455 - accuracy: 0.9841 - val_loss: 0.4908 - val_accuracy: 0.9288\n",
      "Epoch 827/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9724 - val_loss: 0.5455 - val_accuracy: 0.9233\n",
      "Epoch 828/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9804 - val_loss: 0.5410 - val_accuracy: 0.9218\n",
      "Epoch 829/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9822 - val_loss: 0.5356 - val_accuracy: 0.9218\n",
      "Epoch 830/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9839 - val_loss: 0.5698 - val_accuracy: 0.9280\n",
      "Epoch 831/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9778 - val_loss: 0.5264 - val_accuracy: 0.9155\n",
      "Epoch 832/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9812 - val_loss: 0.5958 - val_accuracy: 0.9218\n",
      "Epoch 833/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 0.5263 - val_accuracy: 0.9178\n",
      "Epoch 834/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9853 - val_loss: 0.5558 - val_accuracy: 0.9225\n",
      "Epoch 835/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9809 - val_loss: 0.5643 - val_accuracy: 0.9186\n",
      "Epoch 836/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9839 - val_loss: 0.5978 - val_accuracy: 0.9288\n",
      "Epoch 837/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9820 - val_loss: 0.5805 - val_accuracy: 0.9272\n",
      "Epoch 838/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9817 - val_loss: 0.5158 - val_accuracy: 0.9288\n",
      "Epoch 839/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9812 - val_loss: 0.5707 - val_accuracy: 0.9280\n",
      "Epoch 840/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9784 - val_loss: 0.5703 - val_accuracy: 0.9272\n",
      "Epoch 841/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9813 - val_loss: 0.5954 - val_accuracy: 0.9304\n",
      "Epoch 842/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9778 - val_loss: 0.5656 - val_accuracy: 0.9131\n",
      "Epoch 843/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9831 - val_loss: 0.5803 - val_accuracy: 0.9186\n",
      "Epoch 844/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9804 - val_loss: 0.5951 - val_accuracy: 0.9272\n",
      "Epoch 845/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0462 - accuracy: 0.9793 - val_loss: 0.5797 - val_accuracy: 0.9296\n",
      "Epoch 846/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9830 - val_loss: 0.5755 - val_accuracy: 0.9178\n",
      "Epoch 847/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9856 - val_loss: 0.5886 - val_accuracy: 0.9139\n",
      "Epoch 848/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9817 - val_loss: 0.5953 - val_accuracy: 0.9131\n",
      "Epoch 849/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9811 - val_loss: 0.5861 - val_accuracy: 0.9178\n",
      "Epoch 850/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9836 - val_loss: 0.5529 - val_accuracy: 0.9233\n",
      "Epoch 851/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9811 - val_loss: 0.5084 - val_accuracy: 0.9171\n",
      "Epoch 852/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9840 - val_loss: 0.5783 - val_accuracy: 0.9272\n",
      "Epoch 853/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0453 - accuracy: 0.9808 - val_loss: 0.5889 - val_accuracy: 0.9163\n",
      "Epoch 854/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9834 - val_loss: 0.6026 - val_accuracy: 0.9147\n",
      "Epoch 855/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9856 - val_loss: 0.5593 - val_accuracy: 0.9241\n",
      "Epoch 856/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9821 - val_loss: 0.5304 - val_accuracy: 0.9178\n",
      "Epoch 857/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9836 - val_loss: 0.5919 - val_accuracy: 0.9225\n",
      "Epoch 858/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9777 - val_loss: 0.5838 - val_accuracy: 0.9218\n",
      "Epoch 859/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9842 - val_loss: 0.5717 - val_accuracy: 0.9225\n",
      "Epoch 860/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9868 - val_loss: 0.5768 - val_accuracy: 0.9272\n",
      "Epoch 861/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9816 - val_loss: 0.5425 - val_accuracy: 0.9108\n",
      "Epoch 862/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9821 - val_loss: 0.5483 - val_accuracy: 0.9225\n",
      "Epoch 863/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9849 - val_loss: 0.5800 - val_accuracy: 0.9280\n",
      "Epoch 864/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0540 - accuracy: 0.9789 - val_loss: 0.5673 - val_accuracy: 0.9225\n",
      "Epoch 865/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9823 - val_loss: 0.5287 - val_accuracy: 0.9210\n",
      "Epoch 866/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9825 - val_loss: 0.5698 - val_accuracy: 0.9171\n",
      "Epoch 867/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9801 - val_loss: 0.6088 - val_accuracy: 0.9272\n",
      "Epoch 868/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9788 - val_loss: 0.5917 - val_accuracy: 0.9272\n",
      "Epoch 869/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9844 - val_loss: 0.5726 - val_accuracy: 0.9194\n",
      "Epoch 870/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9849 - val_loss: 0.5721 - val_accuracy: 0.9194\n",
      "Epoch 871/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9828 - val_loss: 0.6363 - val_accuracy: 0.9194\n",
      "Epoch 872/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9880 - val_loss: 0.6155 - val_accuracy: 0.9218\n",
      "Epoch 873/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.6279 - val_accuracy: 0.9116\n",
      "Epoch 874/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.9869 - val_loss: 0.6276 - val_accuracy: 0.9163\n",
      "Epoch 875/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9853 - val_loss: 0.6444 - val_accuracy: 0.9257\n",
      "Epoch 876/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.6415 - val_accuracy: 0.9178\n",
      "Epoch 877/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9810 - val_loss: 0.6019 - val_accuracy: 0.9186\n",
      "Epoch 878/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9834 - val_loss: 0.6223 - val_accuracy: 0.9108\n",
      "Epoch 879/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9877 - val_loss: 0.6013 - val_accuracy: 0.9124\n",
      "Epoch 880/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9850 - val_loss: 0.6550 - val_accuracy: 0.9163\n",
      "Epoch 881/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9866 - val_loss: 0.6622 - val_accuracy: 0.9272\n",
      "Epoch 882/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9857 - val_loss: 0.6242 - val_accuracy: 0.9155\n",
      "Epoch 883/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9811 - val_loss: 0.6142 - val_accuracy: 0.9225\n",
      "Epoch 884/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9829 - val_loss: 0.6391 - val_accuracy: 0.9249\n",
      "Epoch 885/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9838 - val_loss: 0.6262 - val_accuracy: 0.9178\n",
      "Epoch 886/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9842 - val_loss: 0.5778 - val_accuracy: 0.9178\n",
      "Epoch 887/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9839 - val_loss: 0.6389 - val_accuracy: 0.9202\n",
      "Epoch 888/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9830 - val_loss: 0.6656 - val_accuracy: 0.9038\n",
      "Epoch 889/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9841 - val_loss: 0.6605 - val_accuracy: 0.9061\n",
      "Epoch 890/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9853 - val_loss: 0.6079 - val_accuracy: 0.9249\n",
      "Epoch 891/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9787 - val_loss: 0.6828 - val_accuracy: 0.9139\n",
      "Epoch 892/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9843 - val_loss: 0.5832 - val_accuracy: 0.9124\n",
      "Epoch 893/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9853 - val_loss: 0.6435 - val_accuracy: 0.9163\n",
      "Epoch 894/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9875 - val_loss: 0.6678 - val_accuracy: 0.9131\n",
      "Epoch 895/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9802 - val_loss: 0.6436 - val_accuracy: 0.9264\n",
      "Epoch 896/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9869 - val_loss: 0.6841 - val_accuracy: 0.9241\n",
      "Epoch 897/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9876 - val_loss: 0.7444 - val_accuracy: 0.9147\n",
      "Epoch 898/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9829 - val_loss: 0.6096 - val_accuracy: 0.9155\n",
      "Epoch 899/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9834 - val_loss: 0.6418 - val_accuracy: 0.9092\n",
      "Epoch 900/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9895 - val_loss: 0.6242 - val_accuracy: 0.9225\n",
      "Epoch 901/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9879 - val_loss: 0.6580 - val_accuracy: 0.9210\n",
      "Epoch 902/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9853 - val_loss: 0.6689 - val_accuracy: 0.9155\n",
      "Epoch 903/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9838 - val_loss: 0.6534 - val_accuracy: 0.9210\n",
      "Epoch 904/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9885 - val_loss: 0.6823 - val_accuracy: 0.9241\n",
      "Epoch 905/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9855 - val_loss: 0.6496 - val_accuracy: 0.9202\n",
      "Epoch 906/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9884 - val_loss: 0.6924 - val_accuracy: 0.9178\n",
      "Epoch 907/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9868 - val_loss: 0.6460 - val_accuracy: 0.9163\n",
      "Epoch 908/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9841 - val_loss: 0.6352 - val_accuracy: 0.9194\n",
      "Epoch 909/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9884 - val_loss: 0.6908 - val_accuracy: 0.9194\n",
      "Epoch 910/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9879 - val_loss: 0.6977 - val_accuracy: 0.9186\n",
      "Epoch 911/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9859 - val_loss: 0.6952 - val_accuracy: 0.9155\n",
      "Epoch 912/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.6791 - val_accuracy: 0.9202\n",
      "Epoch 913/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.7147 - val_accuracy: 0.9218\n",
      "Epoch 914/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9869 - val_loss: 0.6971 - val_accuracy: 0.9210\n",
      "Epoch 915/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.7471 - val_accuracy: 0.9264\n",
      "Epoch 916/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9892 - val_loss: 0.7369 - val_accuracy: 0.9155\n",
      "Epoch 917/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9863 - val_loss: 0.7073 - val_accuracy: 0.9210\n",
      "Epoch 918/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 0.7239 - val_accuracy: 0.9124\n",
      "Epoch 919/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9913 - val_loss: 0.6945 - val_accuracy: 0.9155\n",
      "Epoch 920/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9854 - val_loss: 0.6756 - val_accuracy: 0.9178\n",
      "Epoch 921/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 0.6689 - val_accuracy: 0.9249\n",
      "Epoch 922/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9883 - val_loss: 0.6981 - val_accuracy: 0.9186\n",
      "Epoch 923/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9848 - val_loss: 0.6742 - val_accuracy: 0.9139\n",
      "Epoch 924/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9893 - val_loss: 0.7863 - val_accuracy: 0.9178\n",
      "Epoch 925/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9870 - val_loss: 0.7167 - val_accuracy: 0.9225\n",
      "Epoch 926/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9896 - val_loss: 0.7182 - val_accuracy: 0.9202\n",
      "Epoch 927/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.7219 - val_accuracy: 0.9163\n",
      "Epoch 928/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9902 - val_loss: 0.7032 - val_accuracy: 0.9202\n",
      "Epoch 929/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9902 - val_loss: 0.7290 - val_accuracy: 0.9131\n",
      "Epoch 930/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9898 - val_loss: 0.6880 - val_accuracy: 0.9124\n",
      "Epoch 931/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.99 - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.6520 - val_accuracy: 0.9139\n",
      "Epoch 932/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.7674 - val_accuracy: 0.9155\n",
      "Epoch 933/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9892 - val_loss: 0.7069 - val_accuracy: 0.9139\n",
      "Epoch 934/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9912 - val_loss: 0.6798 - val_accuracy: 0.9163\n",
      "Epoch 935/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9907 - val_loss: 0.6682 - val_accuracy: 0.9155\n",
      "Epoch 936/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9870 - val_loss: 0.6558 - val_accuracy: 0.9147\n",
      "Epoch 937/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.7305 - val_accuracy: 0.9116\n",
      "Epoch 938/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9890 - val_loss: 0.7394 - val_accuracy: 0.9155\n",
      "Epoch 939/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9895 - val_loss: 0.7299 - val_accuracy: 0.9092\n",
      "Epoch 940/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9889 - val_loss: 0.7356 - val_accuracy: 0.9186\n",
      "Epoch 941/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9847 - val_loss: 0.7775 - val_accuracy: 0.9085\n",
      "Epoch 942/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9906 - val_loss: 0.8242 - val_accuracy: 0.9171\n",
      "Epoch 943/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9843 - val_loss: 0.6918 - val_accuracy: 0.9069\n",
      "Epoch 944/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9894 - val_loss: 0.6906 - val_accuracy: 0.9155\n",
      "Epoch 945/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9907 - val_loss: 0.7197 - val_accuracy: 0.9194\n",
      "Epoch 946/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.7175 - val_accuracy: 0.9178\n",
      "Epoch 947/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9896 - val_loss: 0.6838 - val_accuracy: 0.9218\n",
      "Epoch 948/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9908 - val_loss: 0.7059 - val_accuracy: 0.9225\n",
      "Epoch 949/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.6966 - val_accuracy: 0.9178\n",
      "Epoch 950/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9903 - val_loss: 0.7663 - val_accuracy: 0.9077\n",
      "Epoch 951/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 0.7452 - val_accuracy: 0.9178\n",
      "Epoch 952/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9860 - val_loss: 0.7425 - val_accuracy: 0.9194\n",
      "Epoch 953/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9906 - val_loss: 0.7207 - val_accuracy: 0.9053\n",
      "Epoch 954/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.7349 - val_accuracy: 0.9139\n",
      "Epoch 955/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.7454 - val_accuracy: 0.9233\n",
      "Epoch 956/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9913 - val_loss: 0.7563 - val_accuracy: 0.9202\n",
      "Epoch 957/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.7267 - val_accuracy: 0.9210\n",
      "Epoch 958/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9856 - val_loss: 0.7726 - val_accuracy: 0.9257\n",
      "Epoch 959/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9903 - val_loss: 0.7528 - val_accuracy: 0.9163\n",
      "Epoch 960/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9918 - val_loss: 0.7741 - val_accuracy: 0.9210\n",
      "Epoch 961/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9883 - val_loss: 0.8311 - val_accuracy: 0.9225\n",
      "Epoch 962/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9908 - val_loss: 0.8000 - val_accuracy: 0.9194\n",
      "Epoch 963/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9873 - val_loss: 0.7098 - val_accuracy: 0.9218\n",
      "Epoch 964/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.7934 - val_accuracy: 0.9131\n",
      "Epoch 965/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9868 - val_loss: 0.7171 - val_accuracy: 0.9139\n",
      "Epoch 966/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.8094 - val_accuracy: 0.9163\n",
      "Epoch 967/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9912 - val_loss: 0.7675 - val_accuracy: 0.9155\n",
      "Epoch 968/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9918 - val_loss: 0.6935 - val_accuracy: 0.9186\n",
      "Epoch 969/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.7523 - val_accuracy: 0.9225\n",
      "Epoch 970/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9878 - val_loss: 0.7385 - val_accuracy: 0.9218\n",
      "Epoch 971/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9905 - val_loss: 0.8658 - val_accuracy: 0.9155\n",
      "Epoch 972/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9893 - val_loss: 0.7574 - val_accuracy: 0.9147\n",
      "Epoch 973/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9901 - val_loss: 0.7338 - val_accuracy: 0.9171\n",
      "Epoch 974/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9878 - val_loss: 0.7863 - val_accuracy: 0.9225\n",
      "Epoch 975/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9913 - val_loss: 0.8119 - val_accuracy: 0.9131\n",
      "Epoch 976/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9916 - val_loss: 0.8194 - val_accuracy: 0.9131\n",
      "Epoch 977/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.8122 - val_accuracy: 0.9186\n",
      "Epoch 978/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9921 - val_loss: 0.8347 - val_accuracy: 0.9186\n",
      "Epoch 979/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9919 - val_loss: 0.7415 - val_accuracy: 0.9202\n",
      "Epoch 980/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.8019 - val_accuracy: 0.9124\n",
      "Epoch 981/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9890 - val_loss: 0.7872 - val_accuracy: 0.9178\n",
      "Epoch 982/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9900 - val_loss: 0.8267 - val_accuracy: 0.9155\n",
      "Epoch 983/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.7998 - val_accuracy: 0.9147\n",
      "Epoch 984/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.8040 - val_accuracy: 0.9092\n",
      "Epoch 985/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9909 - val_loss: 0.8207 - val_accuracy: 0.9100\n",
      "Epoch 986/1000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.8237 - val_accuracy: 0.9194\n",
      "Epoch 987/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 0.7647 - val_accuracy: 0.9178\n",
      "Epoch 988/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9885 - val_loss: 0.8587 - val_accuracy: 0.9139\n",
      "Epoch 989/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 0.8350 - val_accuracy: 0.9194\n",
      "Epoch 990/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9890 - val_loss: 0.8088 - val_accuracy: 0.9131\n",
      "Epoch 991/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.7610 - val_accuracy: 0.9155\n",
      "Epoch 992/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.8127 - val_accuracy: 0.9233\n",
      "Epoch 993/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.8343 - val_accuracy: 0.9100\n",
      "Epoch 994/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9910 - val_loss: 0.9102 - val_accuracy: 0.9139\n",
      "Epoch 995/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9922 - val_loss: 0.8168 - val_accuracy: 0.9202\n",
      "Epoch 996/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.8525 - val_accuracy: 0.9202\n",
      "Epoch 997/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9910 - val_loss: 0.7520 - val_accuracy: 0.9178\n",
      "Epoch 998/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.8098 - val_accuracy: 0.9131\n",
      "Epoch 999/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9923 - val_loss: 0.7902 - val_accuracy: 0.9116\n",
      "Epoch 1000/1000\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9912 - val_loss: 0.8209 - val_accuracy: 0.9139\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9522691965103149"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history4.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history4.history['accuracy'])\n",
    "plt.plot(history4.history['val_accuracy'])\n",
    "plt.title('model4 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history4.history['loss'])\n",
    "plt.plot(history4.history['val_loss'])\n",
    "plt.title('model4 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
